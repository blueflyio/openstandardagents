FROM node:20-alpine

# Install system dependencies including Python for data processing
RUN apk add --no-cache \
    wget \
    curl \
    bash \
    git \
    python3 \
    py3-pip \
    py3-pandas \
    py3-numpy

WORKDIR /app

# Copy package files
COPY package*.json ./

# Install root dependencies
RUN npm install || true

# Copy source code
COPY . .

# Install and build the CLI package
WORKDIR /app/src/cli
RUN npm install && npm run build

# Return to app root
WORKDIR /app

# Create data agent startup script
RUN cat > /app/start-data-agent.sh << 'EOF'
#!/bin/bash
echo "ðŸ“Š Starting OSSA Data Processing Agent v0.1.8..."

# Start the data processing agent service
node -e "
const express = require('express');
const fs = require('fs');
const path = require('path');

const app = express();
app.use(express.json({ limit: '100mb' }));
app.use(express.urlencoded({ extended: true, limit: '100mb' }));

// Data processing state
const processingJobs = new Map();
const supportedFormats = ['json', 'csv', 'xml', 'yaml', 'txt'];

// Health endpoint
app.get('/health', (req, res) => {
  res.json({
    service: 'data-agent',
    status: 'healthy',
    version: '0.1.8',
    agent_type: 'data',
    active_jobs: processingJobs.size,
    supported_formats: supportedFormats,
    timestamp: new Date().toISOString()
  });
});

// Agent capabilities endpoint
app.get('/capabilities', (req, res) => {
  res.json({
    agent_type: 'data',
    capabilities: [
      'data_processing',
      'format_conversion',
      'data_validation',
      'batch_processing',
      'stream_processing',
      'data_analysis'
    ],
    supported_formats: supportedFormats,
    processing_modes: ['batch', 'stream', 'realtime'],
    endpoints: {
      process: '/process',
      convert: '/convert',
      validate: '/validate',
      analyze: '/analyze'
    }
  });
});

// Process data endpoint
app.post('/process', async (req, res) => {
  try {
    const { data, operation, format, options } = req.body;
    
    if (!data || !operation) {
      return res.status(400).json({ error: 'data and operation required' });
    }
    
    const jobId = 'job-' + Date.now();
    const job = {
      id: jobId,
      operation,
      format: format || 'json',
      status: 'processing',
      started_at: new Date().toISOString(),
      options: options || {}
    };
    
    processingJobs.set(jobId, job);
    
    // Simulate data processing
    setTimeout(async () => {
      try {
        let result;
        
        switch (operation) {
          case 'transform':
            result = { transformed: data, count: Array.isArray(data) ? data.length : 1 };
            break;
          case 'aggregate':
            result = { aggregated: true, summary: 'Data aggregated successfully' };
            break;
          case 'filter':
            result = { filtered: data, applied_filters: options.filters || [] };
            break;
          case 'sort':
            result = { sorted: data, sort_key: options.sortBy || 'default' };
            break;
          default:
            result = { processed: data, operation };
        }
        
        job.status = 'completed';
        job.completed_at = new Date().toISOString();
        job.result = result;
        processingJobs.set(jobId, job);
        
      } catch (error) {
        job.status = 'failed';
        job.error = error.message;
        job.failed_at = new Date().toISOString();
        processingJobs.set(jobId, job);
      }
    }, 2000);
    
    res.json({
      status: 'accepted',
      job_id: jobId,
      estimated_duration: '2-5 seconds',
      timestamp: new Date().toISOString()
    });
  } catch (error) {
    res.status(500).json({
      status: 'error',
      error: error.message,
      timestamp: new Date().toISOString()
    });
  }
});

// Get job status
app.get('/jobs/:id', (req, res) => {
  const job = processingJobs.get(req.params.id);
  if (!job) {
    return res.status(404).json({ error: 'Job not found' });
  }
  res.json(job);
});

// List all jobs
app.get('/jobs', (req, res) => {
  const jobs = Array.from(processingJobs.values());
  const status = req.query.status;
  
  let filteredJobs = jobs;
  if (status) {
    filteredJobs = jobs.filter(job => job.status === status);
  }
  
  res.json({
    jobs: filteredJobs,
    total: filteredJobs.length,
    timestamp: new Date().toISOString()
  });
});

// Convert data format endpoint
app.post('/convert', async (req, res) => {
  try {
    const { data, from_format, to_format } = req.body;
    
    if (!data || !from_format || !to_format) {
      return res.status(400).json({ error: 'data, from_format, and to_format required' });
    }
    
    // Mock format conversion
    const converted = {
      original_format: from_format,
      target_format: to_format,
      data: data,
      converted_at: new Date().toISOString()
    };
    
    res.json({
      status: 'converted',
      result: converted,
      timestamp: new Date().toISOString()
    });
  } catch (error) {
    res.status(500).json({
      status: 'error',
      error: error.message,
      timestamp: new Date().toISOString()
    });
  }
});

// Validate data endpoint
app.post('/validate', async (req, res) => {
  try {
    const { data, schema, rules } = req.body;
    
    if (!data) {
      return res.status(400).json({ error: 'data required' });
    }
    
    // Mock validation
    const validation = {
      valid: true,
      errors: [],
      warnings: [],
      data_type: typeof data,
      schema_applied: schema ? 'yes' : 'no',
      rules_applied: rules ? rules.length : 0,
      validated_at: new Date().toISOString()
    };
    
    res.json({
      status: 'validated',
      result: validation,
      timestamp: new Date().toISOString()
    });
  } catch (error) {
    res.status(500).json({
      status: 'error',
      error: error.message,
      timestamp: new Date().toISOString()
    });
  }
});

// Analyze data endpoint
app.post('/analyze', async (req, res) => {
  try {
    const { data, analysis_type } = req.body;
    
    if (!data) {
      return res.status(400).json({ error: 'data required' });
    }
    
    // Mock data analysis
    const analysis = {
      type: analysis_type || 'basic',
      data_size: JSON.stringify(data).length,
      data_type: typeof data,
      is_array: Array.isArray(data),
      element_count: Array.isArray(data) ? data.length : 1,
      analysis_completed: true,
      analyzed_at: new Date().toISOString()
    };
    
    if (Array.isArray(data) && data.length > 0) {
      analysis.sample = data.slice(0, 3);
      analysis.unique_keys = data[0] && typeof data[0] === 'object' ? Object.keys(data[0]) : [];
    }
    
    res.json({
      status: 'analyzed',
      result: analysis,
      timestamp: new Date().toISOString()
    });
  } catch (error) {
    res.status(500).json({
      status: 'error',
      error: error.message,
      timestamp: new Date().toISOString()
    });
  }
});

const port = process.env.SERVICE_PORT || 3007;
app.listen(port, '0.0.0.0', () => {
  console.log('âœ… Data Processing Agent running on port ' + port);
});
"

EOF

# Make startup script executable
RUN chmod +x /app/start-data-agent.sh

# Create data directory
RUN mkdir -p /app/data

# Expose port
EXPOSE 3007

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
  CMD curl -f http://localhost:3007/health || exit 1

# Start data agent service
CMD ["/app/start-data-agent.sh"]