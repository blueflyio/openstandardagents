# NIST AI Risk Management Framework (AI RMF 1.0) Compliance Template
# For OSSA v0.1.3 Agent Compliance Framework

nist_ai_rmf:
  version: "1.0"
  framework_date: "2023-01-26"
  implementation_date: "2025-01-01"
  
  # GOVERN Function
  govern:
    description: "Establish policies, procedures, and practices for trustworthy AI"
    
    governance_structure:
      ai_governance_board:
        chair: "Chief AI Officer"
        members:
          - "CEO"
          - "CTO"
          - "Legal Counsel"
          - "Risk Manager"
          - "Ethics Officer"
        meeting_frequency: "monthly"
      
      working_groups:
        - name: "AI Ethics Committee"
          focus: "Ethical AI development and deployment"
          members: 5
        
        - name: "AI Risk Committee"
          focus: "Risk identification and mitigation"
          members: 7

    policies_procedures:
      - id: "GOVERN-1.1"
        title: "AI Risk Management Policy"
        description: "Comprehensive policy for managing AI risks"
        owner: "Risk Manager"
        review_cycle: "annual"
        status: "approved"
      
      - id: "GOVERN-1.2" 
        title: "AI Development Standards"
        description: "Standards for responsible AI development"
        owner: "Chief AI Officer"
        review_cycle: "bi-annual"
        status: "approved"
      
      - id: "GOVERN-1.3"
        title: "Data Governance for AI"
        description: "Data management policies for AI systems"
        owner: "Data Protection Officer"
        review_cycle: "annual"
        status: "approved"

    organizational_integration:
      business_processes:
        - "Product development lifecycle"
        - "Risk management process"
        - "Compliance monitoring"
        - "Vendor management"
      
      decision_frameworks:
        - "AI project approval process"
        - "Risk tolerance thresholds"
        - "Ethics review criteria"
        - "Performance acceptance criteria"

  # MAP Function  
  map:
    description: "Identify and categorize AI risks in context"
    
    ai_system_categorization:
      system_type: "Conversational AI Agent"
      risk_level: "Limited Risk"  # Minimal | Limited | High | Unacceptable
      application_domain: "Enterprise Automation"
      
      impact_assessment:
        individuals: "medium"
        organizations: "medium"
        society: "low"
        environment: "low"
      
      characteristics:
        - "Text-based interaction"
        - "Task automation"
        - "Data analysis"
        - "Decision support"
        - "Multi-framework integration"

    context_mapping:
      stakeholders:
        primary:
          - name: "End Users"
            interests: ["Reliability", "Privacy", "Usability"]
            influence: "high"
          
          - name: "System Administrators"
            interests: ["Security", "Performance", "Maintainability"]
            influence: "high"
        
        secondary:
          - name: "Regulators"
            interests: ["Compliance", "Transparency", "Safety"]
            influence: "medium"
          
          - name: "Data Subjects"
            interests: ["Privacy", "Fairness", "Rights"]
            influence: "medium"

      use_cases:
        - id: "UC-001"
          description: "Automated customer service"
          criticality: "medium"
          human_oversight: "minimal"
        
        - id: "UC-002"
          description: "Data analysis and reporting"
          criticality: "high"
          human_oversight: "moderate"
        
        - id: "UC-003"
          description: "Process automation"
          criticality: "medium"
          human_oversight: "minimal"

    risk_identification:
      technical_risks:
        - id: "MAP-T-001"
          category: "Model Performance"
          description: "Degraded model accuracy over time"
          likelihood: "medium"
          impact: "medium"
          detection_method: "Performance monitoring"
        
        - id: "MAP-T-002" 
          category: "Data Quality"
          description: "Poor quality or biased training data"
          likelihood: "medium"
          impact: "high"
          detection_method: "Data validation"
        
        - id: "MAP-T-003"
          category: "System Integration"
          description: "Failures in framework integration"
          likelihood: "low"
          impact: "medium"
          detection_method: "Integration testing"

      societal_risks:
        - id: "MAP-S-001"
          category: "Fairness"
          description: "Discriminatory outcomes for protected groups"
          likelihood: "low"
          impact: "high"
          detection_method: "Bias testing"
        
        - id: "MAP-S-002"
          category: "Privacy"
          description: "Unauthorized data exposure"
          likelihood: "low"
          impact: "high" 
          detection_method: "Privacy audits"

      human_ai_risks:
        - id: "MAP-H-001"
          category: "Over-reliance"
          description: "Users over-depending on AI recommendations"
          likelihood: "medium"
          impact: "medium"
          detection_method: "Usage monitoring"

  # MEASURE Function
  measure:
    description: "Analyze, assess, benchmark, and monitor AI risks"
    
    measurement_framework:
      metrics_categories:
        - "Performance metrics"
        - "Fairness metrics" 
        - "Privacy metrics"
        - "Security metrics"
        - "Reliability metrics"
        - "Transparency metrics"

    performance_measurement:
      accuracy_metrics:
        - name: "Overall Accuracy"
          target: "> 95%"
          measurement_frequency: "daily"
          alert_threshold: "< 90%"
        
        - name: "Task Completion Rate"
          target: "> 98%"
          measurement_frequency: "real-time"
          alert_threshold: "< 95%"
        
        - name: "Response Relevance"
          target: "> 90%"
          measurement_frequency: "weekly"
          alert_threshold: "< 85%"

      reliability_metrics:
        - name: "System Availability"
          target: "> 99.9%"
          measurement_frequency: "real-time"
          alert_threshold: "< 99.5%"
        
        - name: "Mean Time to Recovery"
          target: "< 5 minutes"
          measurement_frequency: "per-incident"
          alert_threshold: "> 15 minutes"

    fairness_assessment:
      protected_attributes:
        - "Age"
        - "Gender"
        - "Race/Ethnicity"
        - "Geographic location"
      
      fairness_metrics:
        - name: "Demographic Parity"
          calculation: "Statistical parity across groups"
          target: "> 0.8"
          frequency: "monthly"
        
        - name: "Equal Opportunity"
          calculation: "True positive rate equality"
          target: "> 0.9"
          frequency: "monthly"
        
        - name: "Equalized Odds"
          calculation: "TPR and FPR equality across groups"
          target: "> 0.85"
          frequency: "monthly"

    security_monitoring:
      security_metrics:
        - name: "Authentication Success Rate"
          target: "100%"
          measurement_frequency: "real-time"
        
        - name: "Authorization Violations"
          target: "0"
          measurement_frequency: "real-time"
        
        - name: "Data Encryption Coverage"
          target: "100%"
          measurement_frequency: "daily"

    monitoring_systems:
      automated_monitoring:
        - "Real-time performance dashboards"
        - "Automated alert systems"
        - "Anomaly detection"
        - "Trend analysis"
      
      manual_assessments:
        - "Monthly bias reviews"
        - "Quarterly security audits"
        - "Annual comprehensive assessments"

  # MANAGE Function
  manage:
    description: "Allocate resources to address identified AI risks"
    
    risk_response_strategies:
      high_priority_risks:
        - risk_id: "MAP-T-002"
          strategy: "Mitigate"
          actions:
            - "Implement data validation pipeline"
            - "Regular bias testing"
            - "Diverse data sourcing"
          owner: "Data Engineering Team"
          timeline: "30 days"
        
        - risk_id: "MAP-S-001"
          strategy: "Mitigate"
          actions:
            - "Implement fairness constraints"
            - "Regular fairness audits"
            - "Bias detection algorithms"
          owner: "AI Ethics Team"
          timeline: "60 days"

      medium_priority_risks:
        - risk_id: "MAP-T-001"
          strategy: "Monitor and Mitigate"
          actions:
            - "Enhanced monitoring"
            - "Automated retraining triggers"
            - "Performance thresholds"
          owner: "ML Operations Team"
          timeline: "45 days"

    incident_response:
      response_team:
        - "Incident Commander"
        - "Technical Lead"
        - "Legal Counsel"
        - "Communications Manager"
      
      response_procedures:
        severity_1:
          description: "Critical system failure or major bias incident"
          response_time: "< 15 minutes"
          escalation: "C-level executives"
          communication: "Immediate stakeholder notification"
        
        severity_2:
          description: "Performance degradation or minor bias"
          response_time: "< 2 hours"
          escalation: "Department heads"
          communication: "Daily status updates"
        
        severity_3:
          description: "Minor issues or warnings"
          response_time: "< 24 hours"
          escalation: "Team leads"
          communication: "Weekly summaries"

    continuous_improvement:
      feedback_loops:
        - "User feedback collection"
        - "Performance monitoring"
        - "Audit findings"
        - "Incident lessons learned"
      
      improvement_process:
        - "Quarterly risk reassessment"
        - "Annual framework review"
        - "Continuous metric refinement"
        - "Process optimization"

    resource_allocation:
      risk_management_budget:
        total_allocation: "15% of AI budget"
        breakdown:
          monitoring_tools: "40%"
          compliance_activities: "25%"
          training_education: "20%"
          incident_response: "15%

      personnel_assignments:
        dedicated_roles:
          - "AI Risk Manager (1.0 FTE)"
          - "AI Ethics Specialist (0.5 FTE)"
          - "Compliance Analyst (0.5 FTE)"
        
        cross_functional_involvement:
          - "All developers: 10% time for AI safety"
          - "QA team: 25% time for AI testing"
          - "Security team: 15% time for AI security"

    third_party_management:
      vendor_assessments:
        - "AI framework providers"
        - "Data providers"
        - "Cloud service providers"
        - "Monitoring tool vendors"
      
      contractual_requirements:
        - "Compliance with AI standards"
        - "Data protection requirements"
        - "Audit rights and access"
        - "Incident notification procedures"

  # Cross-Function Integration
  integration:
    govern_map_integration:
      - "Risk appetite alignment with identified risks"
      - "Policy updates based on risk mapping"
      - "Stakeholder communication of risk profile"

    map_measure_integration:
      - "Risk-based measurement priorities"
      - "Context-specific metric selection"
      - "Measurement validation against risks"

    measure_manage_integration:
      - "Measurement-driven risk response"
      - "Resource allocation based on metrics"
      - "Continuous measurement refinement"

    manage_govern_integration:
      - "Governance updates from management experience"
      - "Policy refinement from incident learning"
      - "Resource planning for governance activities"

  # Implementation Timeline
  implementation_phases:
    phase_1:
      duration: "Months 1-3"
      focus: "Foundation setup"
      deliverables:
        - "Governance structure"
        - "Initial risk mapping"
        - "Basic measurement framework"
    
    phase_2:
      duration: "Months 4-6"
      focus: "Core implementation"
      deliverables:
        - "Comprehensive monitoring"
        - "Risk management processes"
        - "Incident response procedures"
    
    phase_3:
      duration: "Months 7-12"
      focus: "Optimization and maturity"
      deliverables:
        - "Advanced analytics"
        - "Automated risk management"
        - "Continuous improvement processes"