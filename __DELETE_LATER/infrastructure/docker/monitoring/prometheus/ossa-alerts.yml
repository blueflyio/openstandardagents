# OSSA Production Alerts - Prometheus Rules
groups:
  - name: ossa.critical
    rules:
    # Service Health Alerts
    - alert: OSSAServiceDown
      expr: up{job="ossa-api"} == 0
      for: 30s
      labels:
        severity: critical
      annotations:
        summary: "OSSA API service is down"
        description: "OSSA service at ossa.ossa.orb.local is not responding"

    # Agent System Alerts
    - alert: AgentRegistryOverloaded
      expr: ossa_agent_registry_connections > 9000
      for: 2m
      labels:
        severity: warning
      annotations:
        summary: "Agent registry approaching capacity limit"
        description: "{{ $value }} concurrent connections (limit: 10,000)"

    - alert: AgentFailureRateHigh
      expr: rate(ossa_agent_failures_total[5m]) > 0.1
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "High agent failure rate detected"
        description: "Agent failure rate: {{ $value }}/min"

    # VORTEX Token System Alerts
    - alert: VORTEXTokenExchangeLatency
      expr: histogram_quantile(0.99, ossa_vortex_token_exchange_duration_seconds) > 0.1
      for: 2m
      labels:
        severity: warning
      annotations:
        summary: "VORTEX token exchange latency high"
        description: "P99 latency: {{ $value }}s (target: <100ms)"

    - alert: VORTEXCacheMissRateHigh
      expr: rate(ossa_vortex_cache_misses_total[5m]) / rate(ossa_vortex_cache_requests_total[5m]) > 0.3
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "VORTEX cache miss rate too high"
        description: "Cache miss rate: {{ $value }}% (target: <20%)"

    # 360° Feedback Loop Alerts
    - alert: FeedbackLoopIterationsExceeded
      expr: ossa_feedback_loop_iterations > 3
      for: 1m
      labels:
        severity: warning
      annotations:
        summary: "Feedback loop exceeding max iterations"
        description: "{{ $value }} iterations (limit: 3)"

    - alert: FeedbackLoopStalled
      expr: increase(ossa_feedback_loop_completed_total[10m]) == 0 and on() up{job="ossa-api"} == 1
      for: 10m
      labels:
        severity: critical
      annotations:
        summary: "360° feedback loop appears stalled"
        description: "No completed feedback loops in 10 minutes"

    # Token Efficiency Alerts
    - alert: TokenReductionBelowTarget
      expr: ossa_token_reduction_percentage < 60
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "Token reduction below target"
        description: "Current reduction: {{ $value }}% (target: 60-82%)"

    - alert: TokenBudgetExhausted
      expr: ossa_token_budget_utilization > 0.9
      for: 1m
      labels:
        severity: critical
      annotations:
        summary: "Token budget near exhaustion"
        description: "Budget utilization: {{ $value }}%"

    # Circuit Breaker Alerts
    - alert: CircuitBreakerTripped
      expr: increase(ossa_circuit_breaker_trips_total[1m]) > 0
      for: 0s
      labels:
        severity: warning
      annotations:
        summary: "Circuit breaker tripped"
        description: "Circuit breaker {{ $labels.breaker_name }} has opened"

    # Memory System Alerts
    - alert: ACTAMemoryCoherenceFailure
      expr: rate(ossa_memory_coherence_failures_total[5m]) > 0.01
      for: 2m
      labels:
        severity: critical
      annotations:
        summary: "ACTA memory coherence failures detected"
        description: "Memory coherence failure rate: {{ $value }}/min"

    # Security Alerts
    - alert: TrustScoreBelowThreshold
      expr: ossa_agent_trust_score < 0.7
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "Agent trust score below threshold"
        description: "Agent {{ $labels.agent_id }} trust score: {{ $value }}"

    - alert: SecurityIncidentDetected
      expr: increase(ossa_security_incidents_total[1m]) > 0
      for: 0s
      labels:
        severity: critical
      annotations:
        summary: "Security incident detected"
        description: "Security incident type: {{ $labels.incident_type }}"

    # Performance Alerts
    - alert: OrchestrationLatencyHigh
      expr: histogram_quantile(0.95, ossa_orchestration_duration_seconds) > 5.0
      for: 3m
      labels:
        severity: warning
      annotations:
        summary: "High orchestration latency"
        description: "P95 orchestration time: {{ $value }}s"

    # OpenAPI Generator Alerts
    - alert: SDKGenerationFailures
      expr: rate(ossa_openapi_sdk_generation_failures_total[5m]) > 0.05
      for: 2m
      labels:
        severity: warning
      annotations:
        summary: "SDK generation failure rate high"
        description: "SDK generation failure rate: {{ $value }}/min"

  - name: ossa.sla
    rules:
    # SLA Monitoring
    - alert: SLAUptimeBreach
      expr: avg_over_time(up{job="ossa-api"}[24h]) < 0.9997
      for: 1m
      labels:
        severity: critical
      annotations:
        summary: "SLA uptime target breached"
        description: "24h uptime: {{ $value }}% (target: 99.97%)"

    - alert: SLAResponseTimeBreach
      expr: histogram_quantile(0.99, ossa_http_request_duration_seconds{job="ossa-api"}) > 1.0
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "API response time SLA breach"
        description: "P99 response time: {{ $value }}s (target: <1s)"