# Runner Maintenance Jobs
# Automated maintenance, cleanup, optimization

maintain:runner-cleanup:
  stage: monitor
  image: bitnami/kubectl:latest
  script:
    - |
      echo "Cleaning up runner resources..."
      
      # Clean up completed jobs older than 24 hours
      kubectl get jobs -n gitlab-runner -o json | \
        jq -r '.items[] | select(.status.completionTime != null) | select((.status.completionTime | fromdateiso8601) < (now - 86400)) | .metadata.name' | \
        while read job; do
          echo "Deleting old job: $job"
          kubectl delete job $job -n gitlab-runner || true
        done
      
      # Clean up failed pods older than 1 hour
      kubectl get pods -n gitlab-runner -o json | \
        jq -r '.items[] | select(.status.phase == "Failed") | select((.metadata.creationTimestamp | fromdateiso8601) < (now - 3600)) | .metadata.name' | \
        while read pod; do
          echo "Deleting failed pod: $pod"
          kubectl delete pod $pod -n gitlab-runner || true
        done
      
      echo "Cleanup complete"
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"
      when: always
    - if: $CLEANUP_RUNNERS == "true"
      when: manual
  allow_failure: true

maintain:runner-optimization:
  stage: monitor
  image: bitnami/kubectl:latest
  script:
    - |
      echo "Optimizing runner resources..."
      
      # Analyze resource usage
      kubectl top pods -n gitlab-runner --containers
      
      # Suggest optimizations
      echo ""
      echo "Optimization suggestions:"
      kubectl get pods -n gitlab-runner -o json | \
        jq -r '.items[] | "\(.metadata.name): CPU=\(.spec.containers[0].resources.requests.cpu // "none"), Memory=\(.spec.containers[0].resources.requests.memory // "none")"'
      
      # Right-size based on actual usage (if metrics available)
      # This would integrate with VPA or custom logic
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"
      when: always
  allow_failure: true
