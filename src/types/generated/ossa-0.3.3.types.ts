/* eslint-disable */
/**
 * This file was automatically generated by json-schema-to-typescript.
 * DO NOT MODIFY IT BY HAND. Instead, modify the source JSONSchema file,
 * and run json-schema-to-typescript to regenerate this file.
 */

/**
 * Open Standard for Scalable AI Agents (OSSA) v0.3.3 - Unified Task Schema with Access Tiers & Separation of Duties. Supports Agent (agentic loops with LLM), Task (deterministic workflow steps), and Workflow (composition of Tasks and Agents) kinds. Includes Agent-to-Agent Messaging Extension and Access Control Tiers for privilege separation.
 */
export type OSSAV033ManifestSchema = {
  [k: string]: unknown;
} & {
  /**
   * OSSA API version (v0.3.3+ supports Task and Workflow kinds)
   */
  apiVersion: string;
  /**
   * Resource type: Agent (agentic loops), Task (deterministic steps), or Workflow (composition)
   */
  kind: "Agent" | "Task" | "Workflow";
  metadata: Metadata;
  /**
   * Specification varies based on kind
   */
  spec?: {
    [k: string]: unknown;
  };
  /**
   * Framework-specific extensions
   */
  extensions?: {
    mcp?: MCPExtension;
    skills?: SkillsExtension;
    autogen?: AutoGenExtension;
    langflow?: LangFlowExtension;
    vercel_ai?: VercelAIExtension;
    openai_assistants?: OpenAIAssistantsExtension;
    langchain?: LangChainExtension;
    openai_swarm?: OpenAISwarmExtension;
    agents_md?: AgentsMdExtension;
    dify?: DifyExtension;
    crewai?: CrewAIExtension;
    bedrock?: BedrockAgentsExtension;
    semanticKernel?: SemanticKernelExtension;
    llamaindex?: LlamaIndexExtension;
    [k: string]: unknown;
  };
  runtime?: RuntimeBinding;
  [k: string]: unknown;
};

export interface Metadata {
  /**
   * Resource identifier (DNS-1123 subdomain format for Kubernetes compatibility)
   */
  name: string;
  /**
   * Semantic version (semver 2.0.0)
   */
  version?: string;
  /**
   * Human-readable description
   */
  description?: string;
  /**
   * Key-value labels for organization and filtering
   */
  labels?: {
    [k: string]: string;
  };
  /**
   * Arbitrary metadata for tooling
   */
  annotations?: {
    [k: string]: string;
  };
}
/**
 * Model Context Protocol (MCP) extension for agents - supports tools, resources, and prompts
 */
export interface MCPExtension {
  /**
   * Whether MCP is enabled for this agent
   */
  enabled?: boolean;
  /**
   * MCP server transport mechanism
   */
  server_type?: "stdio" | "http" | "sse";
  /**
   * Name of the MCP server
   */
  server_name?: string;
  /**
   * MCP tools (functions/actions the agent can invoke)
   */
  tools?: MCPTool[];
  /**
   * MCP resources (read-only context/data sources)
   */
  resources?: MCPResource[];
  /**
   * MCP prompts (templated workflows and interactions)
   */
  prompts?: MCPPrompt[];
}
/**
 * MCP tool definition - actions/functions the agent can invoke
 */
export interface MCPTool {
  /**
   * Unique tool name
   */
  name: string;
  /**
   * Human-readable description of what the tool does
   */
  description?: string;
  input_schema?: JSONSchemaDefinition;
  inputSchema?: JSONSchemaDefinition1;
  [k: string]: unknown;
}
/**
 * JSON Schema for tool input parameters (snake_case)
 */
export interface JSONSchemaDefinition {
  type?: "object" | "array" | "string" | "number" | "integer" | "boolean" | "null";
  properties?: {
    [k: string]: unknown;
  };
  required?: string[];
  items?: {
    [k: string]: unknown;
  };
  additionalProperties?:
    | boolean
    | {
        [k: string]: unknown;
      };
  minItems?: 0;
  [k: string]: unknown;
}
/**
 * JSON Schema for tool input parameters (camelCase - MCP SDK convention)
 */
export interface JSONSchemaDefinition1 {
  type?: "object" | "array" | "string" | "number" | "integer" | "boolean" | "null";
  properties?: {
    [k: string]: unknown;
  };
  required?: string[];
  items?: {
    [k: string]: unknown;
  };
  additionalProperties?:
    | boolean
    | {
        [k: string]: unknown;
      };
  minItems?: 0;
  [k: string]: unknown;
}
/**
 * MCP resource definition - read-only context and data sources
 */
export interface MCPResource {
  /**
   * Unique resource identifier (URI)
   */
  uri: string;
  /**
   * Human-readable resource name
   */
  name: string;
  /**
   * Description of the resource and its contents
   */
  description?: string;
  /**
   * MIME type of the resource content
   */
  mimeType?: string;
  /**
   * Additional resource metadata
   */
  metadata?: {
    [k: string]: unknown;
  };
}
/**
 * MCP prompt definition - templated messages and workflows
 */
export interface MCPPrompt {
  /**
   * Unique prompt identifier
   */
  name: string;
  /**
   * Human-readable description of the prompt purpose
   */
  description?: string;
  /**
   * Template arguments that can be substituted
   */
  arguments?: MCPPromptArgument[];
}
/**
 * Argument definition for MCP prompts
 */
export interface MCPPromptArgument {
  /**
   * Argument name
   */
  name: string;
  /**
   * Description of what this argument represents
   */
  description?: string;
  /**
   * Whether this argument is required
   */
  required?: boolean;
}
/**
 * Anthropic/AgentSkills.io compatibility extension - enables OSSA agents to be packaged as Skills
 */
export interface SkillsExtension {
  /**
   * Enable Skills format export/import for this agent
   */
  enabled?: boolean;
  /**
   * Pre-approved tools list (maps to spec.capabilities). Matches Skills allowed-tools field.
   */
  allowedTools?: string[];
  /**
   * Compatible AI platforms/environments
   */
  platforms?: string[];
  /**
   * License for the skill (e.g., Apache-2.0, MIT, GPL-2.0-or-later)
   */
  license?: string;
  /**
   * Token budget for progressive disclosure stages
   */
  progressiveDisclosure?: {
    /**
     * Max tokens for metadata stage (name + description)
     */
    metadataTokens?: number;
    /**
     * Max tokens for instructions stage (full SKILL.md body)
     */
    instructionsTokens?: number;
    [k: string]: unknown;
  };
  /**
   * Skills directory structure mapping
   */
  directories?: {
    /**
     * Path to on-demand documentation
     */
    references?: string;
    /**
     * Path to static resources
     */
    assets?: string;
    [k: string]: unknown;
  };
  [k: string]: unknown;
}
/**
 * Microsoft AutoGen multi-agent framework extension for OSSA v0.3.3 - supports ConversableAgent, AssistantAgent, UserProxyAgent, GroupChat, and nested delegation patterns
 */
export interface AutoGenExtension {
  /**
   * AutoGen agent class type - determines base behavior and capabilities
   */
  agent_type?:
    | "conversable_agent"
    | "assistant_agent"
    | "user_proxy_agent"
    | "group_chat_manager"
    | "teachable_agent"
    | "reasoning_agent"
    | "captain_agent"
    | "custom_agent";
  /**
   * LLM configuration for the agent (mirrors AutoGen's llm_config)
   */
  llm_config?: {
    /**
     * List of LLM configurations (model, api_key reference, base_url)
     */
    config_list?: {
      /**
       * Model identifier (e.g., gpt-4, claude-3-opus)
       */
      model?: string;
      /**
       * Environment variable containing API key (never store keys directly)
       */
      api_key_env?: string;
      /**
       * Custom API endpoint (for Azure, local models, etc.)
       */
      base_url?: string;
      /**
       * API provider type
       */
      api_type?: "openai" | "azure" | "anthropic" | "ollama" | "litellm";
      /**
       * API version (required for Azure)
       */
      api_version?: string;
      [k: string]: unknown;
    }[];
    /**
     * Sampling temperature
     */
    temperature?: number;
    /**
     * Request timeout in seconds
     */
    timeout?: number;
    /**
     * Seed for response caching (null disables caching)
     */
    cache_seed?: number | null;
    [k: string]: unknown;
  };
  /**
   * When to request human input: ALWAYS (after every response), NEVER (fully autonomous), TERMINATE (on termination conditions)
   */
  human_input_mode?: "ALWAYS" | "NEVER" | "TERMINATE";
  /**
   * Code execution configuration or false to disable
   */
  code_execution_config?:
    | {
        /**
         * Working directory for code execution
         */
        work_dir?: string;
        /**
         * Docker image for sandboxed execution (true, false, or image name)
         */
        use_docker?: boolean | string;
        /**
         * Code execution timeout in seconds
         */
        timeout?: number;
        /**
         * Number of messages to scan for code blocks
         */
        last_n_messages?: number;
        /**
         * Type of code executor to use
         */
        executor_type?: "local_command_line" | "docker_command_line" | "jupyter" | "azure_container_instance";
        /**
         * Languages allowed for code execution
         */
        allowed_languages?: ("python" | "bash" | "shell" | "javascript" | "powershell")[];
        [k: string]: unknown;
      }
    | false;
  /**
   * Maximum auto-replies before requiring human input
   */
  max_consecutive_auto_reply?: number;
  /**
   * Conversation termination settings
   */
  termination_config?: {
    /**
     * Python lambda or function reference to check for termination
     */
    is_termination_msg?: string;
    /**
     * Keywords that trigger conversation termination
     */
    termination_keywords?: string[];
    /**
     * Maximum conversation turns before termination
     */
    max_turns?: number;
    [k: string]: unknown;
  };
  /**
   * GroupChat configuration for multi-agent orchestration
   */
  group_chat_config?: {
    /**
     * References to OSSA agents participating in group chat
     */
    agents?: string[];
    /**
     * Maximum conversation rounds
     */
    max_round?: number;
    /**
     * Name of the admin agent
     */
    admin_name?: string;
    /**
     * Method for selecting next speaker
     */
    speaker_selection_method?: "auto" | "manual" | "random" | "round_robin" | "custom";
    /**
     * Reference to custom speaker selection function
     */
    custom_speaker_selection_func?: string;
    /**
     * Allow same speaker consecutive turns (true/false or list of agent names)
     */
    allow_repeat_speaker?: boolean | string[];
    /**
     * Send agent introductions at conversation start
     */
    send_introductions?: boolean;
    [k: string]: unknown;
  };
  /**
   * Mapping of function names to implementations (module.function or class.method)
   */
  function_map?: {
    [k: string]: string;
  };
  /**
   * Functions registered for LLM to call (tool definitions)
   */
  register_for_llm?: {
    /**
     * Function name
     */
    name: string;
    /**
     * Function description for LLM
     */
    description?: string;
    parameters?: JSONSchemaDefinition2;
    [k: string]: unknown;
  }[];
  /**
   * Function names that this agent can execute
   */
  register_for_execution?: string[];
  /**
   * Configuration for nested agent conversations (delegation)
   */
  nested_chat_config?: {
    /**
     * Enable nested chat delegation
     */
    enabled?: boolean;
    /**
     * Agents that can be delegated to
     */
    inner_agents?: {
      /**
       * Reference to inner OSSA agent
       */
      agent_ref?: string;
      /**
       * Trigger condition (regex pattern or keyword)
       */
      trigger?: string;
      /**
       * Maximum turns for nested conversation
       */
      max_turns?: number;
      [k: string]: unknown;
    }[];
    /**
     * Function to transform messages between outer/inner chats
     */
    message_transformer?: string;
    [k: string]: unknown;
  };
  /**
   * System message/prompt for the agent (maps to OSSA spec.instructions)
   */
  system_message?: string;
  /**
   * Short description for speaker selection in group chat
   */
  description?: string;
  /**
   * Configuration for TeachableAgent learning capabilities
   */
  teachability_config?: {
    /**
     * Enable teachability/learning
     */
    enabled?: boolean;
    /**
     * Logging verbosity level
     */
    verbosity?: number;
    /**
     * Reset teachability database on start
     */
    reset_db?: boolean;
    /**
     * Path to teachability database directory
     */
    path_to_db_dir?: string;
    /**
     * Similarity threshold for memory recall
     */
    recall_threshold?: number;
    [k: string]: unknown;
  };
  [k: string]: unknown;
}
/**
 * Function parameter schema
 */
export interface JSONSchemaDefinition2 {
  type?: "object" | "array" | "string" | "number" | "integer" | "boolean" | "null";
  properties?: {
    [k: string]: unknown;
  };
  required?: string[];
  items?: {
    [k: string]: unknown;
  };
  additionalProperties?:
    | boolean
    | {
        [k: string]: unknown;
      };
  minItems?: 0;
  [k: string]: unknown;
}
/**
 * LangFlow visual flow builder integration - enables bidirectional mapping between LangFlow flows and OSSA manifests
 */
export interface LangFlowExtension {
  /**
   * LangFlow flow UUID (from flow URL or API)
   */
  flow_id: string;
  /**
   * LangFlow component mappings to OSSA capabilities
   */
  components?: {
    /**
     * LangFlow node ID (format: ComponentType-UUID)
     */
    node_id: string;
    /**
     * LangFlow component type
     */
    component_type:
      | "ChatInput"
      | "ChatOutput"
      | "TextInput"
      | "TextOutput"
      | "OpenAIModel"
      | "AnthropicModel"
      | "OllamaModel"
      | "Agent"
      | "Tool"
      | "VectorStore"
      | "Retriever"
      | "Memory"
      | "Prompt"
      | "Parser"
      | "Chain"
      | "Embeddings"
      | "Document"
      | "Custom";
    /**
     * Mapped OSSA capability identifier
     */
    ossa_capability?: string;
    /**
     * Component-specific configuration
     */
    config?: {
      [k: string]: unknown;
    };
  }[];
  /**
   * Runtime parameter overrides for flow execution. Keys are parameter names or component IDs.
   */
  tweaks?: {
    [k: string]:
      | string
      | number
      | boolean
      | {
          [k: string]: unknown;
        };
  };
  /**
   * LangFlow API configuration
   */
  api_endpoint?: {
    /**
     * LangFlow server base URL
     */
    base_url: string;
    /**
     * Authentication method
     */
    auth_method?: "api_key" | "bearer_token" | "none";
    /**
     * Environment variable containing API key
     */
    api_key_env?: string;
    /**
     * Custom endpoint name (if configured in LangFlow)
     */
    custom_endpoint?: string;
    /**
     * API request timeout in seconds
     */
    timeout_seconds?: number;
  };
  /**
   * Flow execution mode: sync (blocking), async (non-blocking), stream (SSE), batch (parallel)
   */
  execution_mode?: "sync" | "async" | "stream" | "batch";
  /**
   * Map OSSA input_schema fields to LangFlow inputs
   */
  input_mapping?: {
    /**
     * Component IDs to receive input
     */
    target_components?: string[];
    /**
     * Map OSSA input fields to component parameters
     */
    field_mappings?: {
      [k: string]: {
        /**
         * Target component ID
         */
        component: string;
        /**
         * Component parameter name
         */
        parameter: string;
      };
    };
  };
  /**
   * Map LangFlow outputs to OSSA output_schema
   */
  output_mapping?: {
    /**
     * Component IDs to extract output from
     */
    source_components?: string[];
    /**
     * Map component outputs to OSSA output fields
     */
    field_mappings?: {
      [k: string]: {
        /**
         * Source component ID
         */
        component: string;
        /**
         * Component output field name
         */
        output_field?: string;
      };
    };
  };
  /**
   * Map flow variables to OSSA state
   */
  state_persistence?: {
    /**
     * Memory component ID for conversation history
     */
    memory_component?: string;
    /**
     * Input field containing session identifier
     */
    session_id_field?: string;
    /**
     * Persist outputs across invocations
     */
    persist_outputs?: boolean;
  };
  /**
   * OpenAPI specification for flow endpoints
   */
  openapi_spec?: {
    /**
     * Enable OpenAPI spec generation/discovery
     */
    enabled?: boolean;
    /**
     * URL to generated OpenAPI spec
     */
    spec_url?: string;
    /**
     * Generate Zod validation schemas from OpenAPI
     */
    zod_schema?: boolean;
  };
  /**
   * Runtime validation configuration
   */
  validation?: {
    /**
     * Validate inputs against OSSA input_schema
     */
    validate_inputs?: boolean;
    /**
     * Validate outputs against OSSA output_schema
     */
    validate_outputs?: boolean;
    /**
     * Use Zod for runtime validation
     */
    zod_runtime?: boolean;
    /**
     * Validate against OpenAPI spec
     */
    openapi_validation?: boolean;
  };
}
/**
 * Vercel AI SDK extension for web AI applications - enables seamless integration with Next.js/React using useChat, useCompletion, useAssistant, and streamUI
 */
export interface VercelAIExtension {
  /**
   * LLM provider configuration (maps to OSSA spec.llm)
   */
  provider?: {
    /**
     * Provider identifier
     */
    name?:
      | "openai"
      | "anthropic"
      | "google"
      | "mistral"
      | "groq"
      | "azure"
      | "amazon-bedrock"
      | "cohere"
      | "fireworks"
      | "custom";
    /**
     * Model identifier (e.g., gpt-4o, claude-3-5-sonnet)
     */
    model?: string;
    /**
     * Custom API endpoint for OpenAI-compatible providers
     */
    base_url?: string;
    /**
     * Environment variable containing API key
     */
    api_key_env?: string;
    /**
     * Custom headers for API requests
     */
    headers?: {
      [k: string]: string;
    };
  };
  /**
   * Streaming protocol: data (AI SDK format), text (plain), sse (Server-Sent Events)
   */
  stream_protocol?: "data" | "text" | "sse";
  /**
   * React component bindings for generative UI with streamUI
   */
  ui_components?: {
    /**
     * Enable generative UI with streamUI
     */
    enabled?: boolean;
    /**
     * Component mappings for streamUI
     */
    components?: {
      /**
       * Component identifier for tool calls
       */
      name: string;
      /**
       * React component path (e.g., @/components/ui/Weather)
       */
      render: string;
      /**
       * JSON Schema for component props
       */
      props_schema?: {
        [k: string]: unknown;
      };
    }[];
    /**
     * Component to show during generation
     */
    loading_component?: string;
    /**
     * Component to show on errors
     */
    error_component?: string;
  };
  /**
   * AI state management configuration (maps to OSSA spec.state)
   */
  state_config?: {
    /**
     * Server-side AI state configuration
     */
    ai_state?: {
      /**
       * JSON/Zod schema for AI state
       */
      schema?: {
        [k: string]: unknown;
      };
      /**
       * Initial AI state values
       */
      initial?: {
        [k: string]: unknown;
      };
      /**
       * Persist AI state across sessions
       */
      persist?: boolean;
    };
    /**
     * Client-side UI state configuration
     */
    ui_state?: {
      /**
       * JSON/Zod schema for UI state
       */
      schema?: {
        [k: string]: unknown;
      };
      /**
       * Sync UI state from AI state changes
       */
      sync_with_ai_state?: boolean;
    };
    /**
     * Server Actions for state mutations
     */
    actions?: {
      /**
       * Server action name
       */
      name: string;
      /**
       * Server action handler path
       */
      handler: string;
      /**
       * JSON Schema for action input
       */
      input_schema?: {
        [k: string]: unknown;
      };
    }[];
  };
  /**
   * React hook bindings for Vercel AI SDK
   */
  hooks?: {
    /**
     * useChat hook configuration (maps to OSSA Agent kind)
     */
    use_chat?: {
      /**
       * Enable useChat hook
       */
      enabled?: boolean;
      /**
       * API endpoint for chat
       */
      api_endpoint?: string;
      /**
       * Maximum messages to keep in memory
       */
      max_messages?: number;
      /**
       * Initial conversation messages
       */
      initial_messages?: {
        role: "user" | "assistant" | "system";
        content: string;
      }[];
    };
    /**
     * useCompletion hook configuration (maps to OSSA Task kind)
     */
    use_completion?: {
      /**
       * Enable useCompletion hook
       */
      enabled?: boolean;
      /**
       * API endpoint for completion
       */
      api_endpoint?: string;
      /**
       * Streaming mode
       */
      stream_mode?: "stream" | "complete";
    };
    /**
     * useAssistant hook configuration (OpenAI Assistants API)
     */
    use_assistant?: {
      /**
       * Enable useAssistant hook
       */
      enabled?: boolean;
      /**
       * OpenAI Assistant ID
       */
      assistant_id?: string;
      /**
       * Thread persistence strategy
       */
      thread_persistence?: "session" | "database" | "none";
    };
  };
  /**
   * Tool calling configuration (maps to OSSA capabilities/tools)
   */
  tool_calling?: {
    /**
     * Tool calling mode
     */
    mode?: "auto" | "required" | "none";
    /**
     * Maximum agentic loop steps (maps to OSSA spec.autonomy.max_iterations)
     */
    max_steps?: number;
    /**
     * Tool definitions
     */
    tools?: {
      /**
       * Tool name
       */
      name: string;
      /**
       * Tool description for LLM
       */
      description: string;
      /**
       * Zod/JSON schema for tool parameters
       */
      parameters?: {
        [k: string]: unknown;
      };
      /**
       * Handler function path (e.g., @/lib/actions/orders#lookupOrder)
       */
      execute?: string;
      /**
       * Require human confirmation before execution
       */
      confirmation?: boolean;
    }[];
    /**
     * Allow parallel tool execution
     */
    parallel_tool_calls?: boolean;
  };
  /**
   * Structured output configuration (maps to OSSA spec.output)
   */
  output_schema?: {
    /**
     * Enable structured output with generateObject/streamObject
     */
    enabled?: boolean;
    /**
     * Zod/JSON schema for structured output
     */
    schema?: {
      [k: string]: unknown;
    };
    /**
     * Output generation mode
     */
    mode?: "json" | "tool" | "auto";
    /**
     * Allow partial objects during streaming
     */
    partial?: boolean;
  };
}
/**
 * OpenAI Assistants API integration extension - enables bidirectional mapping between OSSA agents and OpenAI Assistants
 */
export interface OpenAIAssistantsExtension {
  /**
   * OpenAI Assistant ID (e.g., asst_abc123)
   */
  assistant_id?: string;
  /**
   * OpenAI model to use for this assistant
   */
  model?:
    | "gpt-4o"
    | "gpt-4o-mini"
    | "gpt-4-turbo"
    | "gpt-4-turbo-preview"
    | "gpt-4"
    | "gpt-3.5-turbo"
    | "gpt-3.5-turbo-16k";
  /**
   * System instructions for the assistant (maps to spec.prompts.system)
   */
  instructions?: string;
  /**
   * OpenAI tools configuration
   */
  tools?: OpenAIAssistantTool[];
  /**
   * Resources for tools (file_search, code_interpreter)
   */
  tool_resources?: {
    code_interpreter?: {
      /**
       * File IDs for code interpreter (max 20)
       *
       * @maxItems 20
       */
      file_ids?:
        | []
        | [string]
        | [string, string]
        | [string, string, string]
        | [string, string, string, string]
        | [string, string, string, string, string]
        | [string, string, string, string, string, string]
        | [string, string, string, string, string, string, string]
        | [string, string, string, string, string, string, string, string]
        | [string, string, string, string, string, string, string, string, string]
        | [string, string, string, string, string, string, string, string, string, string]
        | [string, string, string, string, string, string, string, string, string, string, string]
        | [string, string, string, string, string, string, string, string, string, string, string, string]
        | [string, string, string, string, string, string, string, string, string, string, string, string, string]
        | [
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string
          ]
        | [
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string
          ]
        | [
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string
          ]
        | [
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string
          ]
        | [
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string
          ]
        | [
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string
          ]
        | [
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string,
            string
          ];
    };
    file_search?: {
      /**
       * Vector store IDs for file search (max 1)
       *
       * @maxItems 1
       */
      vector_store_ids?: [] | [string];
    };
  };
  /**
   * Legacy file IDs (deprecated, use tool_resources)
   */
  file_ids?: string[];
  /**
   * Thread configuration for conversation state
   */
  thread_config?: {
    /**
     * Automatically create threads for new conversations
     */
    auto_create?: boolean;
    /**
     * Thread retention period in days
     */
    retention_days?: number;
    /**
     * JSON Schema for thread metadata
     */
    metadata_schema?: {
      [k: string]: unknown;
    };
    /**
     * Initial messages to populate new threads
     */
    initial_messages?: OpenAIAssistantMessage[];
  };
  /**
   * Run execution configuration
   */
  run_config?: {
    /**
     * Maximum prompt tokens per run
     */
    max_prompt_tokens?: number;
    /**
     * Maximum completion tokens per run
     */
    max_completion_tokens?: number;
    truncation_strategy?: {
      type?: "auto" | "last_messages";
      /**
       * Number of recent messages to keep
       */
      last_messages?: number;
    };
    /**
     * Response format configuration
     */
    response_format?:
      | ("auto" | "text")
      | {
          type?: "json_object" | "json_schema";
          /**
           * JSON Schema for structured output
           */
          json_schema?: {
            [k: string]: unknown;
          };
        };
    /**
     * Allow parallel tool execution
     */
    parallel_tool_calls?: boolean;
    /**
     * Run execution timeout
     */
    timeout_seconds?: number;
  };
  /**
   * SSE streaming configuration
   */
  streaming?: {
    /**
     * Enable streaming responses
     */
    enabled?: boolean;
    /**
     * Events to stream
     */
    events?: (
      | "thread.created"
      | "thread.run.created"
      | "thread.run.queued"
      | "thread.run.in_progress"
      | "thread.run.requires_action"
      | "thread.run.completed"
      | "thread.run.incomplete"
      | "thread.run.failed"
      | "thread.run.cancelling"
      | "thread.run.cancelled"
      | "thread.run.expired"
      | "thread.run.step.created"
      | "thread.run.step.in_progress"
      | "thread.run.step.delta"
      | "thread.run.step.completed"
      | "thread.run.step.expired"
      | "thread.message.created"
      | "thread.message.in_progress"
      | "thread.message.delta"
      | "thread.message.completed"
      | "thread.message.incomplete"
      | "error"
      | "done"
    )[];
    /**
     * SSE buffer size in bytes
     */
    buffer_size?: number;
  };
  /**
   * OpenAI API configuration
   */
  api_config?: {
    /**
     * OpenAI API base URL
     */
    base_url?: string;
    /**
     * OpenAI API version
     */
    api_version?: string;
    /**
     * OpenAI organization ID
     */
    organization_id?: string;
    /**
     * OpenAI project ID
     */
    project_id?: string;
    /**
     * API request timeout in milliseconds
     */
    timeout_ms?: number;
    retry?: {
      /**
       * Maximum retry attempts
       */
      max_retries?: number;
      /**
       * Backoff multiplier for retries
       */
      backoff_factor?: number;
    };
  };
  /**
   * Run steps and observability configuration
   */
  observability?: {
    /**
     * Enable run step tracing
     */
    trace_run_steps?: boolean;
    /**
     * Step types to trace
     */
    step_types?: ("message_creation" | "tool_calls")[];
    /**
     * Include token usage in traces
     */
    include_usage?: boolean;
    /**
     * OpenTelemetry exporter type
     */
    otel_exporter?: "otlp" | "console" | "none";
  };
}
/**
 * OpenAI Assistant tool definition
 */
export interface OpenAIAssistantTool {
  /**
   * Tool type
   */
  type: "code_interpreter" | "file_search" | "function";
  /**
   * Function tool definition (when type=function)
   */
  function?: {
    /**
     * Function name
     */
    name: string;
    /**
     * Function description
     */
    description?: string;
    /**
     * JSON Schema for function parameters
     */
    parameters?: {
      [k: string]: unknown;
    };
    /**
     * Enable strict mode for structured outputs
     */
    strict?: boolean;
  };
}
/**
 * OpenAI Assistant message definition
 */
export interface OpenAIAssistantMessage {
  /**
   * Message role
   */
  role: "user" | "assistant";
  /**
   * Message content
   */
  content: string | OpenAIAssistantContentPart[];
  /**
   * File attachments
   */
  attachments?: {
    /**
     * File ID to attach
     */
    file_id?: string;
    tools?: {
      type?: "code_interpreter" | "file_search";
    }[];
  }[];
  /**
   * Message metadata (max 16 key-value pairs)
   */
  metadata?: {
    [k: string]: string;
  };
}
/**
 * Content part for multimodal messages
 */
export interface OpenAIAssistantContentPart {
  /**
   * Content part type
   */
  type: "text" | "image_url" | "image_file";
  /**
   * Text content (when type=text)
   */
  text?: string;
  /**
   * Image URL (when type=image_url)
   */
  image_url?: {
    /**
     * Image URL
     */
    url?: string;
    /**
     * Image detail level
     */
    detail?: "auto" | "low" | "high";
  };
  /**
   * Image file (when type=image_file)
   */
  image_file?: {
    /**
     * File ID of the image
     */
    file_id?: string;
    /**
     * Image detail level
     */
    detail?: "auto" | "low" | "high";
  };
}
/**
 * LangChain/LangGraph integration extension for OSSA v0.3.3. Provides bidirectional mapping between LangChain constructs (LCEL chains, LangGraph state machines, agents, memory, callbacks) and OSSA primitives.
 */
export interface LangChainExtension {
  /**
   * Enable LangChain extension
   */
  enabled?: boolean;
  /**
   * LangChain version compatibility (e.g., 0.3.0)
   */
  version?: string;
  /**
   * LCEL chain definitions mapped to OSSA constructs
   */
  chains?: LangChainChainConfig[];
  /**
   * LangGraph state machine definitions
   */
  graphs?: LangGraphConfig[];
  /**
   * Memory backend type for stateful interactions
   */
  memory_type?:
    | "conversation_buffer"
    | "conversation_buffer_window"
    | "conversation_summary"
    | "vector_store"
    | "entity"
    | "combined"
    | "none";
  /**
   * Memory-specific configuration
   */
  memory_config?: {
    /**
     * Maximum tokens for memory buffer
     */
    max_token_limit?: number;
    /**
     * Window size for conversation_buffer_window
     */
    k?: number;
    /**
     * Vector store configuration for vector_store memory type
     */
    vector_store?: {
      /**
       * Vector store backend type
       */
      type?: "chroma" | "qdrant" | "pinecone" | "weaviate" | "milvus" | "pgvector" | "faiss";
      /**
       * Collection/index name in the vector store
       */
      collection_name?: string;
      /**
       * Embedding model for vectorization
       */
      embedding_model?: string;
      /**
       * Connection string reference (use env var)
       */
      connection_string?: string;
      [k: string]: unknown;
    };
    [k: string]: unknown;
  };
  /**
   * LangChain callback handlers mapped to OSSA observability
   */
  callbacks?: LangChainCallbackConfig[];
  /**
   * Global RunnableConfig settings for all runnables
   */
  runnable_config?: {
    /**
     * Maximum concurrent runnable executions
     */
    max_concurrency?: number;
    /**
     * Maximum recursion depth for nested runnables
     */
    recursion_limit?: number;
    /**
     * Tags for filtering callbacks
     */
    tags?: string[];
    /**
     * Arbitrary metadata passed to callbacks
     */
    metadata?: {
      [k: string]: unknown;
    };
    /**
     * Configurable fields for runtime configuration
     */
    configurable?: {
      [k: string]: unknown;
    };
    [k: string]: unknown;
  };
  /**
   * LangChain agent architecture type
   */
  agent_type?:
    | "react"
    | "openai_functions"
    | "openai_tools"
    | "xml"
    | "structured_chat"
    | "tool_calling"
    | "langgraph_react"
    | "custom";
  /**
   * Agent-type-specific configuration
   */
  agent_config?: {
    /**
     * Whether to handle parsing errors gracefully
     */
    handle_parsing_errors?: boolean;
    /**
     * Maximum agent iterations
     */
    max_iterations?: number;
    /**
     * Method for early stopping
     */
    early_stopping_method?: "force" | "generate";
    /**
     * Whether to return intermediate agent steps
     */
    return_intermediate_steps?: boolean;
    /**
     * Keep only last N intermediate steps
     */
    trim_intermediate_steps?: number;
    [k: string]: unknown;
  };
  [k: string]: unknown;
}
/**
 * LCEL chain configuration for LangChain integration
 */
export interface LangChainChainConfig {
  /**
   * Chain identifier
   */
  name: string;
  /**
   * Chain type
   */
  type:
    | "llm"
    | "prompt_template"
    | "retrieval"
    | "stuff_documents"
    | "map_reduce"
    | "refine"
    | "map_rerank"
    | "conversational_retrieval"
    | "sql_database"
    | "api"
    | "transformation"
    | "sequential"
    | "router"
    | "custom";
  /**
   * LCEL expression string (e.g., 'prompt | llm | parser')
   */
  lcel_expression?: string;
  /**
   * Chain components for sequential chains
   */
  components?: {
    /**
     * Component type
     */
    type?: "prompt" | "llm" | "parser" | "retriever" | "tool" | "function" | "passthrough" | "itemgetter";
    /**
     * Reference to component definition
     */
    ref?: string;
    /**
     * Component-specific configuration
     */
    config?: {
      [k: string]: unknown;
    };
    [k: string]: unknown;
  }[];
  input_schema?: JSONSchemaDefinition3;
  output_schema?: JSONSchemaDefinition4;
  /**
   * Fallback chain configuration
   */
  fallback?: {
    /**
     * Reference to fallback chain
     */
    chain_ref?: string;
    /**
     * Exception types that trigger fallback
     */
    exceptions?: string[];
    [k: string]: unknown;
  };
  /**
   * Batch processing configuration
   */
  batch_config?: {
    /**
     * Maximum concurrent batch executions
     */
    max_concurrency?: number;
    /**
     * Whether to return exceptions in batch results
     */
    return_exceptions?: boolean;
    [k: string]: unknown;
  };
  [k: string]: unknown;
}
/**
 * JSON Schema for chain input
 */
export interface JSONSchemaDefinition3 {
  type?: "object" | "array" | "string" | "number" | "integer" | "boolean" | "null";
  properties?: {
    [k: string]: unknown;
  };
  required?: string[];
  items?: {
    [k: string]: unknown;
  };
  additionalProperties?:
    | boolean
    | {
        [k: string]: unknown;
      };
  minItems?: 0;
  [k: string]: unknown;
}
/**
 * JSON Schema for chain output
 */
export interface JSONSchemaDefinition4 {
  type?: "object" | "array" | "string" | "number" | "integer" | "boolean" | "null";
  properties?: {
    [k: string]: unknown;
  };
  required?: string[];
  items?: {
    [k: string]: unknown;
  };
  additionalProperties?:
    | boolean
    | {
        [k: string]: unknown;
      };
  minItems?: 0;
  [k: string]: unknown;
}
/**
 * LangGraph state machine configuration
 */
export interface LangGraphConfig {
  /**
   * Graph identifier
   */
  name: string;
  state_schema?: JSONSchemaDefinition5;
  /**
   * Graph nodes
   */
  nodes: {
    /**
     * Node identifier
     */
    id: string;
    /**
     * Node type
     */
    type: "agent" | "tool" | "function" | "subgraph" | "passthrough" | "conditional" | "human_in_loop";
    /**
     * Handler function/class reference
     */
    handler?: string;
    /**
     * Reference to OSSA Task or Agent manifest
     */
    ossa_ref?: string;
    [k: string]: unknown;
  }[];
  /**
   * Graph edges (transitions)
   */
  edges?: {
    /**
     * Source node ID or START
     */
    from: string;
    /**
     * Target node ID or END
     */
    to: string;
    /**
     * Condition function reference for conditional edges
     */
    condition?: string;
    /**
     * Map of condition values to target nodes
     */
    condition_map?: {
      [k: string]: string;
    };
    [k: string]: unknown;
  }[];
  /**
   * Entry point node ID
   */
  entrypoint?: string;
  /**
   * State persistence configuration (MemorySaver, SqliteSaver, etc.)
   */
  checkpointer?: {
    /**
     * Checkpointer backend type
     */
    type?: "memory" | "sqlite" | "postgres" | "redis";
    /**
     * Connection string for persistent checkpointers
     */
    connection_string?: string;
    [k: string]: unknown;
  };
  /**
   * Nodes to interrupt before (human-in-the-loop)
   */
  interrupt_before?: string[];
  /**
   * Nodes to interrupt after
   */
  interrupt_after?: string[];
  [k: string]: unknown;
}
/**
 * TypedDict/Pydantic state schema
 */
export interface JSONSchemaDefinition5 {
  type?: "object" | "array" | "string" | "number" | "integer" | "boolean" | "null";
  properties?: {
    [k: string]: unknown;
  };
  required?: string[];
  items?: {
    [k: string]: unknown;
  };
  additionalProperties?:
    | boolean
    | {
        [k: string]: unknown;
      };
  minItems?: 0;
  [k: string]: unknown;
}
/**
 * LangChain callback handler configuration
 */
export interface LangChainCallbackConfig {
  /**
   * Callback handler type
   */
  type:
    | "langchain_tracer"
    | "langsmith"
    | "stdout"
    | "file"
    | "opentelemetry"
    | "phoenix"
    | "wandb"
    | "mlflow"
    | "custom";
  /**
   * Handler-specific configuration
   */
  config?: {
    [k: string]: unknown;
  };
  /**
   * Events to handle (empty = all events)
   */
  events?: (
    | "on_llm_start"
    | "on_llm_end"
    | "on_llm_error"
    | "on_chain_start"
    | "on_chain_end"
    | "on_chain_error"
    | "on_tool_start"
    | "on_tool_end"
    | "on_tool_error"
    | "on_agent_action"
    | "on_agent_finish"
    | "on_retriever_start"
    | "on_retriever_end"
    | "on_text"
    | "on_retry"
  )[];
  [k: string]: unknown;
}
/**
 * OpenAI Swarm multi-agent framework extension - enables OSSA agents to operate within Swarm's handoff-based orchestration model
 */
export interface OpenAISwarmExtension {
  /**
   * Enable Swarm compatibility mode
   */
  enabled?: boolean;
  /**
   * Swarm agent definitions for multi-agent manifests
   */
  agents?: SwarmAgentConfig[];
  handoff_config?: SwarmHandoffConfig;
  context_variables?: SwarmContextVariables;
  run_config?: SwarmRunConfig;
  [k: string]: unknown;
}
/**
 * Swarm agent configuration within an OSSA manifest
 */
export interface SwarmAgentConfig {
  /**
   * Agent name identifier
   */
  name: string;
  /**
   * Whether this is the primary/entry agent
   */
  is_primary?: boolean;
  /**
   * Whether this agent routes to other agents
   */
  is_router?: boolean;
  /**
   * Name of the routing function for router agents
   */
  routing_function?: string;
  /**
   * Override the default model for this agent
   */
  model_override?: string;
  /**
   * Tool selection strategy
   */
  tool_choice?: "auto" | "none" | "required";
  /**
   * Enable parallel tool execution
   */
  parallel_tool_calls?: boolean;
  [k: string]: unknown;
}
/**
 * Handoff behavior configuration
 */
export interface SwarmHandoffConfig {
  /**
   * Handoff strategy: function_return (Swarm-native), workflow_transition (OSSA workflow), explicit (manual)
   */
  strategy?: "function_return" | "workflow_transition" | "explicit";
  /**
   * Preserve context variables during handoff
   */
  preserve_context?: boolean;
  /**
   * Allow agents to hand off in cycles
   */
  allow_cycles?: boolean;
  /**
   * Maximum number of handoffs per session
   */
  max_handoffs?: number;
  /**
   * Explicit handoff definitions
   */
  handoffs?: {
    /**
     * Function name that triggers the handoff
     */
    function: string;
    /**
     * Target agent to hand off to
     */
    target_agent: string;
    /**
     * Conditions that trigger this handoff
     */
    conditions?: {
      /**
       * Condition type
       */
      type:
        | "explicit_request"
        | "capability_mismatch"
        | "billing_keyword_detected"
        | "technical_issue_detected"
        | "custom";
      /**
       * Custom condition expression
       */
      expression?: string;
      [k: string]: unknown;
    }[];
    [k: string]: unknown;
  }[];
  [k: string]: unknown;
}
/**
 * Shared context variable definitions
 */
export interface SwarmContextVariables {
  /**
   * Mapping of Swarm context variable names to OSSA state paths
   */
  mapping?: {
    [k: string]: string;
  };
  /**
   * How context variables propagate between agents
   */
  propagation?: "all_agents" | "handoff_only" | "none";
  /**
   * Whether agents can modify context variables
   */
  mutability?: "read_only" | "read_write";
  /**
   * Context variable lifecycle configuration
   */
  lifecycle?: {
    /**
     * Inherit context variables on agent handoff
     */
    inherit_on_handoff?: boolean;
    /**
     * Strategy for merging context variable updates
     */
    merge_strategy?: "shallow_merge" | "deep_merge" | "replace";
    /**
     * Clear context variables when session completes
     */
    clear_on_complete?: boolean;
    [k: string]: unknown;
  };
  [k: string]: unknown;
}
/**
 * Run loop configuration
 */
export interface SwarmRunConfig {
  /**
   * Maximum conversation turns (maps to spec.behavior.maxIterations)
   */
  max_turns?: number;
  /**
   * Whether to execute tool calls
   */
  execute_tools?: boolean;
  /**
   * Enable streaming responses
   */
  stream?: boolean;
  /**
   * Enable debug mode
   */
  debug?: boolean;
  /**
   * Enable dynamic instruction generation from context
   */
  dynamic_instructions?: boolean;
  /**
   * Source for agent instructions
   */
  instruction_source?: "system_prompt" | "system_prompt_template" | "external";
  /**
   * Lifecycle hooks for run events
   */
  lifecycle?: {
    /**
     * Handler called when run starts
     */
    on_start?: string;
    /**
     * Handler called on each turn
     */
    on_turn?: string;
    /**
     * Handler called on agent handoff
     */
    on_handoff?: string;
    /**
     * Handler called when run completes
     */
    on_complete?: string;
    /**
     * Handler called on error
     */
    on_error?: string;
    [k: string]: unknown;
  };
  /**
   * Tool execution configuration
   */
  tool_execution?: {
    /**
     * Execute tools in parallel when possible
     */
    parallel?: boolean;
    /**
     * Timeout per tool execution in seconds
     */
    timeout_per_tool?: number;
    /**
     * Retry failed tool calls
     */
    retry_on_failure?: boolean;
    /**
     * Maximum retry attempts
     */
    max_retries?: number;
    [k: string]: unknown;
  };
  /**
   * Result and output handling configuration
   */
  result_handling?: {
    /**
     * Parse Result objects for agent handoff
     */
    parse_agent_handoff?: boolean;
    /**
     * Apply context variable updates from results
     */
    apply_context_updates?: boolean;
    /**
     * JSONPath mapping for result fields
     */
    output_mapping?: {
      [k: string]: string;
    };
    [k: string]: unknown;
  };
  [k: string]: unknown;
}
/**
 * Agents.md extension for bidirectional markdown/OSSA conversion - enables generation, parsing, synchronization, and validation between AGENTS.md files and OSSA manifests
 */
export interface AgentsMdExtension {
  /**
   * Enable agents_md extension
   */
  enabled?: boolean;
  /**
   * Path to AGENTS.md file (relative to repository root)
   */
  file_path?: string;
  /**
   * Auto-generate AGENTS.md from manifest
   */
  generate?: boolean;
  /**
   * Auto-discover agents from AGENTS.md sections
   */
  auto_discover?: boolean;
  /**
   * Section-level configuration for AGENTS.md
   */
  sections?: {
    dev_environment?: AgentsMdSection;
    testing?: AgentsMdSection;
    pr_instructions?: AgentsMdSection;
    code_style?: AgentsMdSection;
    security?: AgentsMdSection;
    architecture?: AgentsMdSection;
    /**
     * Additional custom sections beyond the predefined ones. Use this array for any custom section names.
     */
    custom?: AgentsMdSection[];
  };
  /**
   * Synchronization configuration
   */
  sync?: {
    /**
     * Regenerate AGENTS.md when manifest changes
     */
    on_manifest_change?: boolean;
    /**
     * Include generation comments in output
     */
    include_comments?: boolean;
    /**
     * Preserve custom sections not mapped to manifest
     */
    preserve_custom?: boolean;
    /**
     * Watch for file changes
     */
    watch?: boolean;
  };
  /**
   * Explicit mapping between OSSA and agents.md
   */
  mapping?: {
    /**
     * Map spec.tools to Development Environment section
     */
    tools_to_dev_environment?: boolean;
    /**
     * Map spec.constraints to Testing section
     */
    constraints_to_testing?: boolean;
    /**
     * Map spec.autonomy to PR Instructions section
     */
    autonomy_to_pr_instructions?: boolean;
    /**
     * Map spec.safety to Security section
     */
    safety_to_security?: boolean;
    /**
     * Map spec.role to Overview section
     */
    role_to_overview?: boolean;
  };
  /**
   * Generate Cursor-compatible content
   */
  cursor_integration?: boolean;
  /**
   * Include OSSA metadata in generated AGENTS.md
   */
  include_metadata?: boolean;
}
/**
 * Configuration for an individual AGENTS.md section
 */
export interface AgentsMdSection {
  /**
   * Whether this section is enabled
   */
  enabled?: boolean;
  /**
   * OSSA manifest path to derive content from
   */
  source?: string;
  /**
   * Custom markdown content for this section
   */
  custom?: string;
  /**
   * Content to append after auto-generated content
   */
  append?: string;
  /**
   * Content to prepend before auto-generated content
   */
  prepend?: string;
  /**
   * Override default section title
   */
  title?: string;
  /**
   * Format string for section title
   */
  title_format?: string;
}
/**
 * Dify LLMOps platform integration for OSSA agents. Supports Chat, Completion, Agent, and Workflow app types with bidirectional mapping.
 */
export interface DifyExtension {
  /**
   * Dify application type: chat (conversational), completion (single-shot), agent (autonomous with tools), workflow (DAG-based)
   */
  app_type: "chat" | "completion" | "agent" | "workflow";
  /**
   * Dify application UUID for API operations
   */
  app_id?: string;
  /**
   * Dify Knowledge/Dataset UUIDs for RAG retrieval
   */
  dataset_ids?: string[];
  /**
   * Dify workflow configuration for workflow app type
   */
  workflow_config?: {
    /**
     * Workflow DAG definition with nodes and edges
     */
    graph?: {
      nodes?: {
        /**
         * Unique node identifier
         */
        id: string;
        /**
         * Dify workflow node type
         */
        type:
          | "start"
          | "end"
          | "llm"
          | "knowledge-retrieval"
          | "code"
          | "template"
          | "http-request"
          | "tool"
          | "if-else"
          | "iterator"
          | "parameter-extractor"
          | "variable-aggregator"
          | "answer"
          | "human-review";
        /**
         * Node-specific configuration data
         */
        data?: {
          [k: string]: unknown;
        };
        /**
         * Visual position in workflow editor
         */
        position?: {
          x?: number;
          y?: number;
          [k: string]: unknown;
        };
        [k: string]: unknown;
      }[];
      edges?: {
        /**
         * Source node ID
         */
        source: string;
        /**
         * Target node ID
         */
        target: string;
        /**
         * Edge condition for branching
         */
        condition?: boolean | string;
        [k: string]: unknown;
      }[];
    };
    /**
     * Workflow input variable definitions
     */
    variables?: {
      [k: string]: {
        /**
         * Dify variable type
         */
        type?: "text" | "paragraph" | "select" | "number" | "file" | "file-list";
        /**
         * Maximum length for text variables
         */
        max_length?: number;
        /**
         * Default value
         */
        default?: {
          [k: string]: unknown;
        };
        /**
         * Options for select type
         */
        options?: string[];
        required?: boolean;
        [k: string]: unknown;
      };
    };
    /**
     * Names of workflow output variables
     */
    output_variables?: string[];
  };
  /**
   * Dify API integration settings
   */
  api_config?: {
    /**
     * Dify API base URL
     */
    base_url?: string;
    /**
     * Environment variable name containing API key
     */
    api_key_ref?: string;
    /**
     * Vault-based API key reference
     */
    api_key_secret?: {
      /**
       * Vault secret path
       */
      vault_path?: string;
      key?: string;
      [k: string]: unknown;
    };
    rate_limits?: {
      requests_per_minute?: number;
      tokens_per_minute?: number;
      concurrent_requests?: number;
      [k: string]: unknown;
    };
    retry?: {
      max_attempts?: number;
      backoff?: "fixed" | "exponential" | "linear";
      initial_delay_ms?: number;
      max_delay_ms?: number;
      [k: string]: unknown;
    };
    timeout_seconds?: number;
    /**
     * Path to OpenAPI spec for tool generation
     */
    openapi_spec?: string;
  };
  /**
   * Dify conversation/messaging settings for chat app type
   */
  conversation_config?: {
    persistence?: {
      enabled?: boolean;
      ttl_hours?: number;
      max_messages?: number;
      [k: string]: unknown;
    };
    /**
     * Conversation-scoped variable types
     */
    variables?: {
      [k: string]: string;
    };
    suggested_questions?: {
      enabled?: boolean;
      max_suggestions?: number;
      [k: string]: unknown;
    };
    streaming?: {
      enabled?: boolean;
      /**
       * Token chunk size for streaming
       */
      chunk_size?: number;
      [k: string]: unknown;
    };
    memory?: {
      type?: "buffer" | "buffer_window" | "summary" | "conversation_kg";
      window_size?: number;
      summary_enabled?: boolean;
      [k: string]: unknown;
    };
  };
  /**
   * Dify annotation and observability settings
   */
  annotation_config?: {
    feedback?: {
      enabled?: boolean;
      types?: ("like" | "dislike" | "regenerate" | "report_error")[];
      [k: string]: unknown;
    };
    thought_logging?: {
      enabled?: boolean;
      detail_level?: "minimal" | "standard" | "comprehensive";
      [k: string]: unknown;
    };
    usage_tracking?: {
      enabled?: boolean;
      export_format?: "prometheus" | "opentelemetry" | "json";
      labels?: {
        [k: string]: string;
      };
      [k: string]: unknown;
    };
    log_export?: {
      enabled?: boolean;
      destination?: "opentelemetry" | "elasticsearch" | "loki";
      endpoint?: string;
      [k: string]: unknown;
    };
    annotation_storage?: {
      enabled?: boolean;
      format?: "jsonl" | "parquet" | "csv";
      /**
       * Storage path with template variables
       */
      path?: string;
      [k: string]: unknown;
    };
    citation_tracking?: {
      enabled?: boolean;
      format?: "inline" | "footnote" | "endnote";
      [k: string]: unknown;
    };
  };
  /**
   * RAG retrieval configuration for datasets
   */
  retrieval_config?: {
    mode?: "semantic" | "keyword" | "hybrid";
    top_k?: number;
    score_threshold?: number;
    /**
     * Reranking model identifier
     */
    rerank_model?: string;
    chunking?: {
      mode?: "automatic" | "custom";
      max_tokens?: number;
      overlap_tokens?: number;
      [k: string]: unknown;
    };
    embedding?: {
      /**
       * Embedding model identifier
       */
      model?: string;
      /**
       * Embedding provider
       */
      provider?: string;
      /**
       * Embedding vector dimensions
       */
      dimensions?: number;
      [k: string]: unknown;
    };
  };
  /**
   * Mapping of OSSA tool names to Dify tool identifiers
   */
  tool_mapping?: {
    [k: string]: string;
  };
}
/**
 * CrewAI multi-agent orchestration framework extension for OSSA v0.3.3. Provides bidirectional mapping between CrewAI crews, agents, tasks, processes, and OSSA primitives including workflows, agents, tasks, delegation, memory, and observability.
 */
export interface CrewAIExtension {
  /**
   * Name of the CrewAI crew (DNS-1123 compatible)
   */
  crew_name?: string;
  /**
   * CrewAI agents mapped to OSSA agents
   */
  agents?: CrewAIAgentConfig[];
  /**
   * CrewAI tasks mapped to OSSA workflow steps
   */
  tasks?: CrewAITaskConfig[];
  /**
   * Process execution pattern - maps to OSSA workflow step ordering
   */
  process_type?: "sequential" | "hierarchical" | "consensual";
  /**
   * Enable agent-to-agent delegation
   */
  delegation_enabled?: boolean;
  memory_config?: CrewAIMemoryConfig;
  /**
   * LLM configuration for hierarchical manager (when process_type=hierarchical)
   */
  manager_llm?: {
    provider?: "openai" | "anthropic" | "google" | "azure" | "ollama" | "groq" | "together" | "fireworks";
    model?: string;
    temperature?: number;
    [k: string]: unknown;
  };
  /**
   * Maximum requests per minute for rate limiting
   */
  max_rpm?: number;
  /**
   * Share telemetry data with CrewAI platform
   */
  share_crew?: boolean;
  callbacks?: CrewAICallbacksConfig;
  /**
   * Enable verbose logging
   */
  verbose?: boolean;
  /**
   * Primary language for agent interactions
   */
  language?: string;
  /**
   * Path to output log file
   */
  output_log_file?: string;
  /**
   * Enable planning phase before execution
   */
  planning?: boolean;
  /**
   * LLM configuration for planning (if different from default)
   */
  planning_llm?: {
    provider?: string;
    model?: string;
    [k: string]: unknown;
  };
  [k: string]: unknown;
}
/**
 * CrewAI agent configuration mapped to OSSA Agent
 */
export interface CrewAIAgentConfig {
  /**
   * Agent's role/persona (e.g., 'Senior Research Analyst')
   */
  role: string;
  /**
   * Agent's primary objective
   */
  goal: string;
  /**
   * Background context for the agent persona
   */
  backstory?: string;
  /**
   * LLM configuration for this agent
   */
  llm?: {
    provider?: "openai" | "anthropic" | "google" | "azure" | "ollama" | "groq" | "together" | "fireworks";
    model?: string;
    temperature?: number;
    [k: string]: unknown;
  };
  /**
   * Tools available to this agent (capability names)
   */
  tools?: string[];
  /**
   * Can this agent delegate to others
   */
  allow_delegation?: boolean;
  /**
   * Maximum reasoning iterations
   */
  max_iter?: number;
  /**
   * Rate limit for this agent
   */
  max_rpm?: number;
  /**
   * Maximum execution time in seconds
   */
  max_execution_time?: number;
  /**
   * Enable verbose logging
   */
  verbose?: boolean;
  /**
   * Enable response caching
   */
  cache?: boolean;
  /**
   * Custom system prompt template
   */
  system_template?: string;
  /**
   * Custom prompt template
   */
  prompt_template?: string;
  /**
   * Custom response template
   */
  response_template?: string;
  /**
   * Allow code execution capability
   */
  allow_code_execution?: boolean;
  /**
   * Code execution security mode
   */
  code_execution_mode?: "safe" | "unsafe";
  /**
   * Reference to OSSA Agent manifest file
   */
  ossa_agent_ref?: string;
  [k: string]: unknown;
}
/**
 * CrewAI task configuration mapped to OSSA Task/WorkflowStep
 */
export interface CrewAITaskConfig {
  /**
   * Detailed task description
   */
  description: string;
  /**
   * Agent role assigned to this task
   */
  agent: string;
  /**
   * Description of expected output format
   */
  expected_output?: string;
  /**
   * Specific tools for this task
   */
  tools?: string[];
  /**
   * References to other tasks providing context
   */
  context?: string[];
  /**
   * Execute asynchronously
   */
  async_execution?: boolean;
  /**
   * JSON schema for structured output
   */
  output_json?: {
    [k: string]: unknown;
  };
  /**
   * Pydantic model class name for validation
   */
  output_pydantic?: string;
  /**
   * File path for output
   */
  output_file?: string;
  /**
   * Require human input before completion
   */
  human_input?: boolean;
  /**
   * Custom output converter class
   */
  converter_cls?: string;
  /**
   * Reference to OSSA Task manifest file
   */
  ossa_task_ref?: string;
  [k: string]: unknown;
}
/**
 * Memory system configuration
 */
export interface CrewAIMemoryConfig {
  /**
   * Enable memory system
   */
  enabled?: boolean;
  /**
   * Short-term memory (within session)
   */
  short_term?: {
    provider?: "rag" | "simple" | "custom";
    embedder?: {
      provider?: "openai" | "cohere" | "google" | "huggingface";
      model?: string;
      config?: {
        [k: string]: unknown;
      };
      [k: string]: unknown;
    };
    [k: string]: unknown;
  };
  /**
   * Long-term memory (persistent)
   */
  long_term?: {
    provider?: "rag" | "sqlite" | "custom";
    storage?: {
      type?: "chroma" | "qdrant" | "pinecone" | "weaviate" | "pgvector" | "milvus" | "faiss";
      /**
       * Connection string or path
       */
      connection?: string;
      [k: string]: unknown;
    };
    [k: string]: unknown;
  };
  /**
   * Entity memory (extracted entities)
   */
  entity?: {
    enabled?: boolean;
    provider?: "rag" | "spacy" | "custom";
    [k: string]: unknown;
  };
  /**
   * Contextual memory (RAG-based)
   */
  contextual?: {
    enabled?: boolean;
    retriever?: {
      /**
       * Number of results to retrieve
       */
      k?: number;
      /**
       * Similarity threshold
       */
      threshold?: number;
      [k: string]: unknown;
    };
    [k: string]: unknown;
  };
  [k: string]: unknown;
}
/**
 * Callback hooks for observability integration
 */
export interface CrewAICallbacksConfig {
  /**
   * Step completion callback
   */
  on_step?: {
    /**
     * Handler function/class reference
     */
    handler?: string;
    /**
     * Export to OpenTelemetry
     */
    otel_export?: boolean;
    /**
     * Include step output in trace
     */
    include_output?: boolean;
    [k: string]: unknown;
  };
  /**
   * Task completion callback
   */
  on_task?: {
    handler?: string;
    otel_export?: boolean;
    include_output?: boolean;
    [k: string]: unknown;
  };
  /**
   * Crew start callback
   */
  on_crew_start?: {
    handler?: string;
    otel_export?: boolean;
    [k: string]: unknown;
  };
  /**
   * Crew completion callback
   */
  on_crew_end?: {
    handler?: string;
    otel_export?: boolean;
    include_final_output?: boolean;
    [k: string]: unknown;
  };
  /**
   * Agent action callback
   */
  on_agent_action?: {
    handler?: string;
    otel_export?: boolean;
    [k: string]: unknown;
  };
  /**
   * Tool usage callback
   */
  on_tool_use?: {
    handler?: string;
    otel_export?: boolean;
    track_latency?: boolean;
    [k: string]: unknown;
  };
  [k: string]: unknown;
}
/**
 * AWS Bedrock Agents extension for OSSA v0.3.3 - supports Amazon Bedrock Agents for building, testing, and deploying conversational AI agents
 */
export interface BedrockAgentsExtension {
  /**
   * Bedrock Agent ID (10 alphanumeric characters)
   */
  agent_id?: string;
  /**
   * Agent alias ID for versioning (TSTALIASID for draft)
   */
  agent_alias_id?: string;
  /**
   * Bedrock foundation model ID
   */
  foundation_model?:
    | "anthropic.claude-3-5-sonnet-20241022-v2:0"
    | "anthropic.claude-3-5-haiku-20241022-v1:0"
    | "anthropic.claude-3-sonnet-20240229-v1:0"
    | "anthropic.claude-3-haiku-20240307-v1:0"
    | "anthropic.claude-3-opus-20240229-v1:0"
    | "amazon.titan-text-premier-v1:0"
    | "amazon.titan-text-express-v1"
    | "amazon.titan-text-lite-v1"
    | "meta.llama3-1-70b-instruct-v1:0"
    | "meta.llama3-1-8b-instruct-v1:0"
    | "cohere.command-r-plus-v1:0"
    | "cohere.command-r-v1:0";
  /**
   * Agent instructions (system prompt) - max 4000 characters
   */
  instruction?: string;
  /**
   * Session timeout in seconds
   */
  idle_session_ttl_in_seconds?: number;
  /**
   * Knowledge bases attached to the agent
   */
  knowledge_base_configurations?: {
    /**
     * Knowledge Base ID
     */
    knowledge_base_id: string;
    /**
     * Description of when to query this knowledge base
     */
    description?: string;
    retrieval_configuration?: {
      vector_search_configuration?: {
        number_of_results?: number;
        override_search_type?: "HYBRID" | "SEMANTIC";
        [k: string]: unknown;
      };
      [k: string]: unknown;
    };
    [k: string]: unknown;
  }[];
  /**
   * Action groups for the agent (Lambda functions, OpenAPI schemas)
   */
  action_groups?: {
    /**
     * Action group name
     */
    action_group_name: string;
    /**
     * Description of when to use this action group
     */
    description?: string;
    action_group_executor?: {
      /**
       * Lambda function ARN
       */
      lambda?: string;
      /**
       * Return control to calling application
       */
      custom_control?: "RETURN_CONTROL";
      [k: string]: unknown;
    };
    /**
     * OpenAPI schema for the action group
     */
    api_schema?: {
      s3?: {
        s3_bucket_name?: string;
        s3_object_key?: string;
        [k: string]: unknown;
      };
      /**
       * Inline OpenAPI schema (YAML or JSON)
       */
      payload?: string;
      [k: string]: unknown;
    };
    /**
     * Function definitions for code interpreter
     */
    function_schema?: {
      functions?: {
        name: string;
        description?: string;
        parameters?: {
          [k: string]: {
            type?: string;
            description?: string;
            required?: boolean;
            [k: string]: unknown;
          };
        };
        [k: string]: unknown;
      }[];
      [k: string]: unknown;
    };
    /**
     * Built-in action group type
     */
    parent_action_group_signature?: "AMAZON.UserInput" | "AMAZON.CodeInterpreter";
    [k: string]: unknown;
  }[];
  /**
   * Bedrock Guardrails configuration
   */
  guardrail_configuration?: {
    /**
     * Guardrail ID or ARN
     */
    guardrail_identifier?: string;
    /**
     * Guardrail version
     */
    guardrail_version?: string;
    [k: string]: unknown;
  };
  /**
   * Custom prompt templates
   */
  prompt_override_configuration?: {
    /**
     * Lambda ARN for prompt processing
     */
    override_lambda?: string;
    prompt_configurations?: {
      prompt_type?: "PRE_PROCESSING" | "ORCHESTRATION" | "POST_PROCESSING" | "KNOWLEDGE_BASE_RESPONSE_GENERATION";
      prompt_creation_mode?: "DEFAULT" | "OVERRIDDEN";
      /**
       * Custom prompt template
       */
      base_prompt_template?: string;
      inference_configuration?: {
        temperature?: number;
        top_p?: number;
        top_k?: number;
        maximum_length?: number;
        stop_sequences?: string[];
        [k: string]: unknown;
      };
      [k: string]: unknown;
    }[];
    [k: string]: unknown;
  };
  /**
   * Agent memory/state configuration
   */
  memory_configuration?: {
    /**
     * Memory types to enable
     */
    enabled_memory_types?: "SESSION_SUMMARY"[];
    /**
     * Days to retain memory
     */
    storage_days?: number;
    [k: string]: unknown;
  };
  /**
   * KMS key ARN for encryption
   */
  customer_encryption_key_arn?: string;
  /**
   * AWS resource tags
   */
  tags?: {
    [k: string]: string;
  };
  [k: string]: unknown;
}
/**
 * Microsoft Semantic Kernel integration extension for OSSA v0.3.3. Provides bidirectional mapping between Semantic Kernel constructs (Kernel, Plugins, Functions, Planners, Memory, Connectors, Filters, Agents) and OSSA primitives.
 */
export interface SemanticKernelExtension {
  /**
   * Enable Semantic Kernel runtime integration
   */
  enabled?: boolean;
  /**
   * Semantic Kernel plugins to load (native, semantic, OpenAPI, gRPC)
   */
  plugins?: SemanticKernelPlugin[];
  /**
   * Planner strategy for goal decomposition and task orchestration
   */
  planner_type?: "sequential" | "stepwise" | "action" | "handlebars" | "function_calling" | "none";
  /**
   * Planner-specific configuration options
   */
  planner_options?: {
    /**
     * Maximum planner iterations
     */
    max_iterations?: number;
    /**
     * Maximum tokens for planner operations
     */
    max_tokens?: number;
    /**
     * Allow looping in plans (stepwise planner)
     */
    allow_loops?: boolean;
    /**
     * Plugin names to exclude from planning
     */
    excluded_plugins?: string[];
    /**
     * Function names to exclude from planning (format: PluginName.FunctionName)
     */
    excluded_functions?: string[];
    /**
     * Semantic memory configuration for planners
     */
    semantic_memory_config?: {
      /**
       * Minimum relevance score for memory retrieval
       */
      relevance_threshold?: number;
      /**
       * Maximum memory results to retrieve
       */
      max_results?: number;
    };
  };
  memory_store?: SemanticKernelMemoryStore;
  connectors?: SemanticKernelConnectors;
  filters?: SemanticKernelFilters;
  /**
   * Semantic Kernel Agent configuration (ChatCompletionAgent, OpenAIAssistantAgent)
   */
  agent_config?: {
    /**
     * Agent implementation type
     */
    type?: "chat_completion" | "openai_assistant" | "azure_assistant";
    /**
     * Agent system instructions (alternative to spec.role)
     */
    instructions?: string;
    /**
     * Agent display name
     */
    name?: string;
    /**
     * Agent description
     */
    description?: string;
    execution_settings?: {
      /**
       * Maximum agent loop iterations
       */
      max_iterations?: number;
      /**
       * Enable code interpreter (OpenAI Assistants)
       */
      enable_code_interpreter?: boolean;
      /**
       * Enable file search (OpenAI Assistants)
       */
      enable_file_search?: boolean;
      /**
       * Tool selection mode
       */
      tool_choice?: "auto" | "required" | "none";
    };
  };
  /**
   * OpenTelemetry configuration for Semantic Kernel
   */
  telemetry?: {
    /**
     * Enable telemetry collection
     */
    enabled?: boolean;
    /**
     * OpenTelemetry activity source name
     */
    activity_source_name?: string;
    /**
     * OpenTelemetry meter name
     */
    meter_name?: string;
    /**
     * Log function invocations
     */
    log_function_invocations?: boolean;
    /**
     * Log prompt template content (caution: may contain sensitive data)
     */
    log_prompt_template_content?: boolean;
    /**
     * Log function results (caution: may contain sensitive data)
     */
    log_function_results?: boolean;
  };
}
/**
 * Semantic Kernel plugin definition
 */
export interface SemanticKernelPlugin {
  /**
   * Plugin name (unique identifier)
   */
  name: string;
  /**
   * Plugin type: native (C#/Python class), semantic (prompt-based), openapi (OpenAPI spec), grpc (gRPC service)
   */
  type?: "native" | "semantic" | "openapi" | "grpc";
  /**
   * Plugin source: assembly name, directory path, or URL
   */
  source?: string;
  /**
   * Functions provided by this plugin
   */
  functions?: {
    /**
     * Function name
     */
    name: string;
    /**
     * Human-readable function description
     */
    description?: string;
    /**
     * Function parameters (JSON Schema)
     */
    parameters?: {
      [k: string]: unknown;
    };
    /**
     * Return type (string, number, object, etc.)
     */
    returnType?: string;
  }[];
  /**
   * Authentication for OpenAPI/gRPC plugins
   */
  authentication?: {
    type?: "none" | "bearer" | "api_key" | "oauth2" | "basic";
    /**
     * Reference to secret containing authentication token
     */
    token_ref?: string;
    /**
     * Custom header name for API key auth
     */
    header_name?: string;
  };
}
/**
 * Semantic memory store configuration
 */
export interface SemanticKernelMemoryStore {
  /**
   * Memory store backend type
   */
  type?: "volatile" | "azure_cognitive_search" | "qdrant" | "chroma" | "pinecone" | "redis" | "postgres" | "sqlite";
  /**
   * Collection/index name for the memory store
   */
  collection?: string;
  /**
   * Connection configuration
   */
  connection?: {
    /**
     * Service endpoint URL
     */
    endpoint?: string;
    /**
     * Reference to secret containing API key
     */
    api_key_ref?: string;
    /**
     * Backend-specific options
     */
    options?: {
      [k: string]: unknown;
    };
  };
}
/**
 * AI service connectors (chat completion, embeddings, image generation, audio)
 */
export interface SemanticKernelConnectors {
  chat_completion?: SemanticKernelServiceConnector;
  text_embedding?: SemanticKernelServiceConnector1;
  image_generation?: SemanticKernelServiceConnector2;
  audio_to_text?: SemanticKernelServiceConnector3;
  text_to_audio?: SemanticKernelServiceConnector4;
}
/**
 * Chat completion service connector
 */
export interface SemanticKernelServiceConnector {
  /**
   * Service identifier for dependency injection
   */
  service_id?: string;
  /**
   * AI service provider
   */
  provider?: "azure_openai" | "openai" | "huggingface" | "ollama" | "anthropic" | "google" | "mistral";
  /**
   * Model identifier (e.g., gpt-4, text-embedding-ada-002)
   */
  model_id?: string;
  /**
   * Service endpoint URL
   */
  endpoint?: string;
  /**
   * Reference to secret containing API key
   */
  api_key_ref?: string;
  /**
   * Azure OpenAI deployment name
   */
  deployment_name?: string;
  /**
   * Embedding vector dimensions (for embedding models)
   */
  dimensions?: number;
  /**
   * Provider-specific options
   */
  options?: {
    /**
     * Sampling temperature
     */
    temperature?: number;
    /**
     * Maximum tokens to generate
     */
    max_tokens?: number;
    /**
     * Nucleus sampling parameter
     */
    top_p?: number;
    [k: string]: unknown;
  };
}
/**
 * Text embedding service connector
 */
export interface SemanticKernelServiceConnector1 {
  /**
   * Service identifier for dependency injection
   */
  service_id?: string;
  /**
   * AI service provider
   */
  provider?: "azure_openai" | "openai" | "huggingface" | "ollama" | "anthropic" | "google" | "mistral";
  /**
   * Model identifier (e.g., gpt-4, text-embedding-ada-002)
   */
  model_id?: string;
  /**
   * Service endpoint URL
   */
  endpoint?: string;
  /**
   * Reference to secret containing API key
   */
  api_key_ref?: string;
  /**
   * Azure OpenAI deployment name
   */
  deployment_name?: string;
  /**
   * Embedding vector dimensions (for embedding models)
   */
  dimensions?: number;
  /**
   * Provider-specific options
   */
  options?: {
    /**
     * Sampling temperature
     */
    temperature?: number;
    /**
     * Maximum tokens to generate
     */
    max_tokens?: number;
    /**
     * Nucleus sampling parameter
     */
    top_p?: number;
    [k: string]: unknown;
  };
}
/**
 * Image generation service connector
 */
export interface SemanticKernelServiceConnector2 {
  /**
   * Service identifier for dependency injection
   */
  service_id?: string;
  /**
   * AI service provider
   */
  provider?: "azure_openai" | "openai" | "huggingface" | "ollama" | "anthropic" | "google" | "mistral";
  /**
   * Model identifier (e.g., gpt-4, text-embedding-ada-002)
   */
  model_id?: string;
  /**
   * Service endpoint URL
   */
  endpoint?: string;
  /**
   * Reference to secret containing API key
   */
  api_key_ref?: string;
  /**
   * Azure OpenAI deployment name
   */
  deployment_name?: string;
  /**
   * Embedding vector dimensions (for embedding models)
   */
  dimensions?: number;
  /**
   * Provider-specific options
   */
  options?: {
    /**
     * Sampling temperature
     */
    temperature?: number;
    /**
     * Maximum tokens to generate
     */
    max_tokens?: number;
    /**
     * Nucleus sampling parameter
     */
    top_p?: number;
    [k: string]: unknown;
  };
}
/**
 * Audio to text (speech-to-text) service connector
 */
export interface SemanticKernelServiceConnector3 {
  /**
   * Service identifier for dependency injection
   */
  service_id?: string;
  /**
   * AI service provider
   */
  provider?: "azure_openai" | "openai" | "huggingface" | "ollama" | "anthropic" | "google" | "mistral";
  /**
   * Model identifier (e.g., gpt-4, text-embedding-ada-002)
   */
  model_id?: string;
  /**
   * Service endpoint URL
   */
  endpoint?: string;
  /**
   * Reference to secret containing API key
   */
  api_key_ref?: string;
  /**
   * Azure OpenAI deployment name
   */
  deployment_name?: string;
  /**
   * Embedding vector dimensions (for embedding models)
   */
  dimensions?: number;
  /**
   * Provider-specific options
   */
  options?: {
    /**
     * Sampling temperature
     */
    temperature?: number;
    /**
     * Maximum tokens to generate
     */
    max_tokens?: number;
    /**
     * Nucleus sampling parameter
     */
    top_p?: number;
    [k: string]: unknown;
  };
}
/**
 * Text to audio (text-to-speech) service connector
 */
export interface SemanticKernelServiceConnector4 {
  /**
   * Service identifier for dependency injection
   */
  service_id?: string;
  /**
   * AI service provider
   */
  provider?: "azure_openai" | "openai" | "huggingface" | "ollama" | "anthropic" | "google" | "mistral";
  /**
   * Model identifier (e.g., gpt-4, text-embedding-ada-002)
   */
  model_id?: string;
  /**
   * Service endpoint URL
   */
  endpoint?: string;
  /**
   * Reference to secret containing API key
   */
  api_key_ref?: string;
  /**
   * Azure OpenAI deployment name
   */
  deployment_name?: string;
  /**
   * Embedding vector dimensions (for embedding models)
   */
  dimensions?: number;
  /**
   * Provider-specific options
   */
  options?: {
    /**
     * Sampling temperature
     */
    temperature?: number;
    /**
     * Maximum tokens to generate
     */
    max_tokens?: number;
    /**
     * Nucleus sampling parameter
     */
    top_p?: number;
    [k: string]: unknown;
  };
}
/**
 * Function, prompt, and auto-invocation filters for safety and observability
 */
export interface SemanticKernelFilters {
  /**
   * Pre/post function execution filters
   */
  function_filters?: SemanticKernelFilter[];
  /**
   * Prompt rendering filters
   */
  prompt_filters?: SemanticKernelFilter[];
  /**
   * Auto function invocation filters
   */
  auto_invoke_filters?: SemanticKernelFilter[];
}
/**
 * Individual filter configuration
 */
export interface SemanticKernelFilter {
  /**
   * Filter name (unique identifier)
   */
  name: string;
  /**
   * Filter execution point
   */
  type?: "pre" | "post" | "both" | "pre_render" | "post_render";
  /**
   * Handler class reference (e.g., Namespace.ClassName)
   */
  handler: string;
  /**
   * Filter-specific configuration
   */
  config?: {
    [k: string]: unknown;
  };
  /**
   * Stop execution if filter matches (for auto-invoke filters)
   */
  terminate_on_match?: boolean;
}
/**
 * LlamaIndex extension for OSSA v0.3.3 - supports LlamaIndex agents, query engines, and data loaders
 */
export interface LlamaIndexExtension {
  /**
   * LlamaIndex agent type
   */
  agent_type?:
    | "openai_agent"
    | "react_agent"
    | "function_calling_agent"
    | "structured_planner_agent"
    | "introspective_agent"
    | "custom_agent";
  /**
   * LLM configuration
   */
  llm?: {
    /**
     * Model identifier
     */
    model?: string;
    temperature?: number;
    max_tokens?: number;
    /**
     * Environment variable for API key
     */
    api_key_env?: string;
    [k: string]: unknown;
  };
  /**
   * Embedding model configuration
   */
  embed_model?: {
    /**
     * Embedding model name
     */
    model_name?: string;
    api_key_env?: string;
    [k: string]: unknown;
  };
  /**
   * Vector store configuration
   */
  vector_store?: {
    type?: "simple" | "chroma" | "pinecone" | "qdrant" | "weaviate" | "milvus" | "pgvector";
    /**
     * Environment variable for connection
     */
    connection_string_env?: string;
    collection_name?: string;
    [k: string]: unknown;
  };
  /**
   * Type of index to use
   */
  index_type?:
    | "vector_store_index"
    | "summary_index"
    | "tree_index"
    | "keyword_table_index"
    | "knowledge_graph_index"
    | "document_summary_index";
  /**
   * Query engine configuration
   */
  query_engine_config?: {
    similarity_top_k?: number;
    response_mode?: "refine" | "compact" | "tree_summarize" | "simple_summarize" | "no_text" | "accumulate";
    streaming?: boolean;
    [k: string]: unknown;
  };
  /**
   * Tools available to the agent
   */
  tools?: {
    name?: string;
    description?: string;
    tool_type?: "function_tool" | "query_engine_tool" | "retriever_tool" | "llama_hub_tool";
    /**
     * Reference to tool function
     */
    function_ref?: string;
    [k: string]: unknown;
  }[];
  /**
   * LlamaHub data loaders
   */
  data_loaders?: {
    /**
     * LlamaHub loader identifier
     */
    loader_type?: string;
    config?: {
      [k: string]: unknown;
    };
    [k: string]: unknown;
  }[];
  /**
   * Agent memory configuration
   */
  memory?: {
    type?: "chat_memory_buffer" | "chat_summary_memory" | "vector_memory";
    token_limit?: number;
    [k: string]: unknown;
  };
  /**
   * Callback handlers
   */
  callbacks?: ("llama_debug" | "wandb" | "arize_phoenix" | "langfuse" | "openinference")[];
  /**
   * System prompt for the agent
   */
  system_prompt?: string;
  [k: string]: unknown;
}
/**
 * Runtime-specific capability bindings (for Task and Workflow kinds)
 */
export interface RuntimeBinding {
  /**
   * Primary runtime type
   */
  type?:
    | "unified"
    | "google-a2a"
    | "gitlab-duo"
    | "ossa-mesh"
    | "mcp"
    | "local"
    | "drupal"
    | "symfony_messenger"
    | "kagent"
    | "temporal"
    | "node";
  /**
   * List of compatible runtimes
   */
  supports?: (
    | "google-a2a"
    | "gitlab-duo"
    | "ossa-mesh"
    | "mcp"
    | "local-execution"
    | "kubernetes"
    | "serverless"
    | "lambda"
    | "cloudflare-workers"
    | "drupal"
    | "symfony"
  )[];
  /**
   * Message transport for async runtimes
   */
  transport?: string;
  scheduling?: SchedulingConfig;
  resource_limits?: ResourceLimits;
  /**
   * External runtime extensions
   */
  extensions?: RuntimeExtension[];
  /**
   * Map of capability names to runtime-specific handlers
   */
  bindings?: {
    [k: string]: {
      /**
       * Handler class/function (e.g., 'Drupal\node\NodeQuery::getList')
       */
      handler?: string;
      /**
       * MCP server name for MCP-based bindings
       */
      mcp_server?: string;
      /**
       * Tool name within MCP server
       */
      tool?: string;
      /**
       * Additional binding configuration
       */
      config?: {
        [k: string]: unknown;
      };
    };
  };
  kubernetes?: KubernetesConfig;
}
/**
 * Agent scheduling configuration
 */
export interface SchedulingConfig {
  /**
   * Scheduling strategy
   */
  strategy?: "fair" | "priority" | "deadline" | "cost-optimized";
  /**
   * Execution priority
   */
  priority?: "critical" | "high" | "normal" | "low" | "background";
  /**
   * Maximum concurrent executions
   */
  max_concurrent?: number;
  /**
   * Execution timeout in seconds
   */
  timeout_seconds?: number;
}
/**
 * Compute resource constraints
 */
export interface ResourceLimits {
  /**
   * Memory limit in megabytes
   */
  memory_mb?: number;
  /**
   * CPU limit in millicores (1000 = 1 CPU)
   */
  cpu_millicores?: number;
  /**
   * Requires GPU acceleration
   */
  gpu_required?: boolean;
  /**
   * Required GPU type (e.g., nvidia-a100, nvidia-h100)
   */
  gpu_type?: string;
}
/**
 * External runtime extension (A2A compatible)
 */
export interface RuntimeExtension {
  /**
   * Extension protocol type
   */
  type: "http" | "grpc" | "mcp" | "websocket" | "kafka" | "pubsub";
  /**
   * Extension name
   */
  name: string;
  /**
   * Extension endpoint URL
   */
  endpoint?: string;
  /**
   * Reference to credentials for authentication
   */
  credentials_ref?: string;
}
/**
 * Kubernetes-specific configuration (KAS-inspired)
 */
export interface KubernetesConfig {
  /**
   * Kubernetes namespace (DNS-1123 subdomain)
   */
  namespace?: string;
  /**
   * Kubernetes service account name
   */
  service_account?: string;
  /**
   * Kubernetes API server URL (similar to KAS private API URL)
   */
  api_server_url?: string;
  /**
   * Network family (KAS pattern: tcp, tcp4, tcp6)
   */
  network_family?: "tcp" | "tcp4" | "tcp6";
  /**
   * Health check endpoint URL
   */
  health_check_endpoint?: string;
  /**
   * Reference to Kubernetes ConfigMap
   */
  config_map_ref?: string;
  /**
   * Reference to Kubernetes Secret
   */
  secret_ref?: string;
  rbac?: {
    /**
     * Kubernetes Role name
     */
    role?: string;
    /**
     * Kubernetes ClusterRole name
     */
    cluster_role?: string;
    /**
     * Kubernetes RoleBinding name
     */
    role_binding?: string;
  };
}
