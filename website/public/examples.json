[
  {
    "name": "drupal-eca-mapping.yaml",
    "path": "adapters/drupal-eca-mapping.yaml",
    "content": "# Example: ECA (Event-Condition-Action) to OSSA Task Mapping\n# Demonstrates how Drupal ECA rules map to OSSA Task/Workflow manifests\napiVersion: ossa/v0.3.0\nkind: Task\nmetadata:\n  name: eca-content-published-notify\n  version: 1.0.0\n  description: Send notification when content is published (ECA rule mapping)\n  labels:\n    runtime: drupal\n    engine: eca\n    domain: content\n  annotations:\n    drupal.ossa.io/eca-model: content_published_notification\n    drupal.ossa.io/eca-version: \"1.0\"\n\nspec:\n  execution:\n    type: deterministic\n    runtime: drupal\n    entrypoint: \"Drupal\\\\ossa_adapter\\\\TaskHandler\\\\ECAHandler::execute\"\n    timeout_seconds: 30\n\n  # ECA Event → OSSA Trigger\n  triggers:\n    - type: event\n      source: drupal.entity\n      event: node.insert\n      filter:\n        bundle: article\n        status: 1  # Published\n    - type: event\n      source: drupal.entity\n      event: node.update\n      filter:\n        bundle: article\n        status: 1\n        _previous_status: 0  # Was unpublished\n\n  # ECA Conditions → OSSA Input Schema\n  input:\n    type: object\n    properties:\n      entity:\n        type: object\n        description: The Drupal node entity\n        properties:\n          nid:\n            type: integer\n          title:\n            type: string\n          bundle:\n            type: string\n          uid:\n            type: integer\n          status:\n            type: integer\n      user:\n        type: object\n        description: The user who triggered the action\n        properties:\n          uid:\n            type: integer\n          mail:\n            type: string\n          name:\n            type: string\n      event_type:\n        type: string\n        enum: [insert, update]\n    required:\n      - entity\n      - user\n\n  # ECA Actions → OSSA Capabilities\n  capabilities:\n    - send_email\n    - log_message\n    - create_entity\n    - queue_item\n\n  output:\n    type: object\n    properties:\n      notifications_sent:\n        type: integer\n      log_id:\n        type: string\n      success:\n        type: boolean\n\n  # Error handling\n  error_handling:\n    on_error: log_and_continue\n    fallback:\n      log_level: error\n      notify_admin: true\n\n  observability:\n    logging:\n      level: info\n    metrics:\n      enabled: true\n      custom_labels:\n        content_type: \"${{ input.entity.bundle }}\"\n        event_type: \"${{ input.event_type }}\"\n\n# Drupal-specific runtime bindings\nruntime:\n  type: drupal\n  bindings:\n    # Map OSSA capabilities to ECA plugins\n    send_email:\n      plugin: \"eca_mail:send\"\n      config:\n        to: \"admin@example.com\"\n        subject: \"Content Published: ${{ input.entity.title }}\"\n        body: |\n          A new article has been published:\n\n          Title: ${{ input.entity.title }}\n          Author: ${{ input.user.name }}\n          URL: /node/${{ input.entity.nid }}\n\n    log_message:\n      plugin: \"eca_log:message\"\n      config:\n        level: info\n        message: \"Content published notification sent for node ${{ input.entity.nid }}\"\n\n    create_entity:\n      plugin: \"eca_content:create_entity\"\n      config:\n        entity_type: notification\n        bundle: content_alert\n\n    queue_item:\n      plugin: \"eca_queue:add\"\n      config:\n        queue_name: content_notifications\n\n  # ECA-specific configuration\n  eca:\n    model_id: content_published_notification\n    event_plugins:\n      - eca_content:entity_insert\n      - eca_content:entity_update\n    condition_plugins:\n      - eca_content:entity_bundle\n      - eca_content:entity_field_value\n    action_plugins:\n      - eca_mail:send\n      - eca_log:message\n",
    "category": "Getting Started"
  },
  {
    "name": "drupal-eca-task.yaml",
    "path": "adapters/drupal-eca-task.yaml",
    "content": "apiVersion: ossa/v0.3.0\nkind: Task\nmetadata:\n  name: drupal-content-moderation\n  description: Content moderation workflow using Drupal ECA\n  labels:\n    drupal.module: eca\n    drupal.version: \"11.x\"\nspec:\n  steps:\n    - name: validate-content\n      action: drupal.eca.condition\n      inputs:\n        condition_type: entity_field_value\n        entity_type: node\n        field: moderation_state\n        operator: equals\n        value: draft\n    \n    - name: check-permissions\n      action: drupal.eca.condition\n      inputs:\n        condition_type: user_permission\n        permission: moderate content\n    \n    - name: update-state\n      action: drupal.eca.action\n      inputs:\n        action_type: entity_set_field_value\n        entity_type: node\n        field: moderation_state\n        value: published\n    \n    - name: notify-author\n      action: drupal.eca.action\n      inputs:\n        action_type: send_email\n        to: \"{{ entity.author.email }}\"\n        subject: \"Your content has been published\"\n        template: content_published\n\nruntime:\n  drupal:\n    module: eca\n    event: entity_presave\n    entity_type: node\n    bundle: article\n    priority: 100\n",
    "category": "Getting Started"
  },
  {
    "name": "drupal-flowdrop-mapping.yaml",
    "path": "adapters/drupal-flowdrop-mapping.yaml",
    "content": "# Example: FlowDrop Visual Workflow to OSSA Workflow Mapping\n# Demonstrates how Drupal FlowDrop diagrams map to OSSA Workflows\napiVersion: ossa/v0.3.0\nkind: Workflow\nmetadata:\n  name: flowdrop-user-registration\n  version: 1.0.0\n  description: User registration flow (FlowDrop diagram mapping)\n  labels:\n    runtime: drupal\n    engine: flowdrop\n    domain: user-management\n  annotations:\n    drupal.ossa.io/flowdrop-diagram: user_registration_v3\n    drupal.ossa.io/flowdrop-version: \"3.0\"\n    drupal.ossa.io/visual-editor: /admin/flowdrop/user_registration_v3\n\nspec:\n  # FlowDrop Start Node → OSSA Triggers\n  triggers:\n    - type: webhook\n      path: /flowdrop/register\n      method: POST\n      auth:\n        type: none  # Public registration\n    - type: api\n      endpoint: /api/user/register\n      method: POST\n\n  # FlowDrop Input Fields → OSSA Input Schema\n  inputs:\n    type: object\n    properties:\n      email:\n        type: string\n        format: email\n        description: User email address\n      username:\n        type: string\n        minLength: 3\n        maxLength: 60\n        pattern: \"^[a-zA-Z0-9_]+$\"\n      password:\n        type: string\n        minLength: 8\n        description: User password (will be hashed)\n      first_name:\n        type: string\n      last_name:\n        type: string\n      newsletter_opt_in:\n        type: boolean\n        default: false\n      terms_accepted:\n        type: boolean\n    required:\n      - email\n      - username\n      - password\n      - terms_accepted\n\n  # FlowDrop End Node → OSSA Output\n  outputs:\n    type: object\n    properties:\n      user_id:\n        type: integer\n      status:\n        type: string\n        enum: [created, pending_verification, failed]\n      verification_sent:\n        type: boolean\n      welcome_email_sent:\n        type: boolean\n      errors:\n        type: array\n        items:\n          type: object\n          properties:\n            field:\n              type: string\n            message:\n              type: string\n\n  # FlowDrop Nodes → OSSA Workflow Steps\n  steps:\n    # FlowDrop: Validate Node\n    - id: validate_input\n      kind: Task\n      name: Validate registration data\n      inline:\n        execution:\n          type: deterministic\n          runtime: drupal\n          entrypoint: \"Drupal\\\\flowdrop\\\\NodeHandler\\\\ValidateNode::execute\"\n        input:\n          type: object\n          properties:\n            schema:\n              type: object\n            data:\n              type: object\n        output:\n          type: object\n          properties:\n            valid:\n              type: boolean\n            errors:\n              type: array\n      input:\n        data:\n          email: \"${{ workflow.input.email }}\"\n          username: \"${{ workflow.input.username }}\"\n          terms_accepted: \"${{ workflow.input.terms_accepted }}\"\n\n    # FlowDrop: Condition Node (Terms Check)\n    - id: check_terms\n      kind: Task\n      name: Verify terms accepted\n      inline:\n        execution:\n          type: deterministic\n        output:\n          type: object\n          properties:\n            proceed:\n              type: boolean\n            error:\n              type: string\n      input:\n        terms_accepted: \"${{ workflow.input.terms_accepted }}\"\n      depends_on:\n        - validate_input\n\n    # FlowDrop: Database Query Node\n    - id: check_email_exists\n      kind: Task\n      name: Check if email already exists\n      condition: \"${{ steps.check_terms.output.proceed == true }}\"\n      inline:\n        execution:\n          type: deterministic\n          runtime: drupal\n          entrypoint: \"Drupal\\\\flowdrop\\\\NodeHandler\\\\DatabaseQuery::execute\"\n        input:\n          type: object\n          properties:\n            query:\n              type: string\n            parameters:\n              type: object\n        output:\n          type: object\n          properties:\n            exists:\n              type: boolean\n            user_id:\n              type: integer\n      input:\n        query: \"SELECT uid FROM users_field_data WHERE mail = :email\"\n        parameters:\n          email: \"${{ workflow.input.email }}\"\n      depends_on:\n        - check_terms\n\n    # FlowDrop: Database Query Node (Username)\n    - id: check_username_exists\n      kind: Task\n      name: Check if username already exists\n      condition: \"${{ steps.check_terms.output.proceed == true }}\"\n      inline:\n        execution:\n          type: deterministic\n          runtime: drupal\n          entrypoint: \"Drupal\\\\flowdrop\\\\NodeHandler\\\\DatabaseQuery::execute\"\n      input:\n        query: \"SELECT uid FROM users_field_data WHERE name = :username\"\n        parameters:\n          username: \"${{ workflow.input.username }}\"\n      depends_on:\n        - check_terms\n\n    # FlowDrop: Decision Node (Duplicate Check)\n    - id: check_duplicates\n      kind: Task\n      name: Evaluate duplicate check results\n      inline:\n        execution:\n          type: deterministic\n        output:\n          type: object\n          properties:\n            can_proceed:\n              type: boolean\n            duplicate_field:\n              type: string\n      input:\n        email_exists: \"${{ steps.check_email_exists.output.exists }}\"\n        username_exists: \"${{ steps.check_username_exists.output.exists }}\"\n      depends_on:\n        - check_email_exists\n        - check_username_exists\n\n    # FlowDrop: Error Response Node\n    - id: return_duplicate_error\n      kind: Task\n      name: Return duplicate error\n      condition: \"${{ steps.check_duplicates.output.can_proceed == false }}\"\n      inline:\n        execution:\n          type: deterministic\n        output:\n          type: object\n          properties:\n            status:\n              type: string\n            errors:\n              type: array\n      input:\n        duplicate_field: \"${{ steps.check_duplicates.output.duplicate_field }}\"\n      depends_on:\n        - check_duplicates\n\n    # FlowDrop: Create Entity Node\n    - id: create_user\n      kind: Task\n      name: Create user account\n      condition: \"${{ steps.check_duplicates.output.can_proceed == true }}\"\n      inline:\n        execution:\n          type: deterministic\n          runtime: drupal\n          entrypoint: \"Drupal\\\\flowdrop\\\\NodeHandler\\\\CreateEntity::execute\"\n        input:\n          type: object\n          properties:\n            entity_type:\n              type: string\n            bundle:\n              type: string\n            values:\n              type: object\n        output:\n          type: object\n          properties:\n            entity_id:\n              type: integer\n            uuid:\n              type: string\n      input:\n        entity_type: user\n        values:\n          name: \"${{ workflow.input.username }}\"\n          mail: \"${{ workflow.input.email }}\"\n          pass: \"${{ workflow.input.password }}\"\n          status: 0  # Blocked until verified\n          field_first_name: \"${{ workflow.input.first_name }}\"\n          field_last_name: \"${{ workflow.input.last_name }}\"\n          field_newsletter: \"${{ workflow.input.newsletter_opt_in }}\"\n      depends_on:\n        - check_duplicates\n\n    # FlowDrop: Generate Token Node\n    - id: generate_verification_token\n      kind: Task\n      name: Generate email verification token\n      condition: \"${{ steps.create_user.output.entity_id > 0 }}\"\n      inline:\n        execution:\n          type: deterministic\n          runtime: drupal\n          entrypoint: \"Drupal\\\\flowdrop\\\\NodeHandler\\\\TokenGenerator::execute\"\n        output:\n          type: object\n          properties:\n            token:\n              type: string\n            expires_at:\n              type: string\n      input:\n        user_id: \"${{ steps.create_user.output.entity_id }}\"\n        token_type: email_verification\n        expiry_hours: 24\n      depends_on:\n        - create_user\n\n    # FlowDrop: Send Email Node (Verification)\n    - id: send_verification_email\n      kind: Task\n      name: Send verification email\n      ref: ./tasks/send-email.yaml\n      input:\n        to: \"${{ workflow.input.email }}\"\n        template: email_verification\n        variables:\n          username: \"${{ workflow.input.username }}\"\n          verification_url: \"https://example.com/verify?token=${{ steps.generate_verification_token.output.token }}\"\n          expires_at: \"${{ steps.generate_verification_token.output.expires_at }}\"\n      depends_on:\n        - generate_verification_token\n\n    # FlowDrop: Send Email Node (Welcome) - Parallel\n    - id: send_welcome_email\n      kind: Task\n      name: Send welcome email\n      ref: ./tasks/send-email.yaml\n      input:\n        to: \"${{ workflow.input.email }}\"\n        template: welcome_new_user\n        variables:\n          username: \"${{ workflow.input.username }}\"\n          first_name: \"${{ workflow.input.first_name }}\"\n      depends_on:\n        - create_user\n      # Runs in parallel with verification email\n\n    # FlowDrop: Webhook Node (Optional: CRM Integration)\n    - id: sync_to_crm\n      kind: Task\n      name: Sync to CRM\n      condition: \"${{ workflow.input.newsletter_opt_in == true }}\"\n      inline:\n        execution:\n          type: deterministic\n          runtime: drupal\n          entrypoint: \"Drupal\\\\flowdrop\\\\NodeHandler\\\\WebhookCall::execute\"\n        input:\n          type: object\n          properties:\n            url:\n              type: string\n            method:\n              type: string\n            headers:\n              type: object\n            body:\n              type: object\n      input:\n        url: \"${CRM_WEBHOOK_URL}\"\n        method: POST\n        headers:\n          Content-Type: application/json\n          Authorization: \"Bearer ${CRM_API_KEY}\"\n        body:\n          email: \"${{ workflow.input.email }}\"\n          first_name: \"${{ workflow.input.first_name }}\"\n          last_name: \"${{ workflow.input.last_name }}\"\n          source: drupal_registration\n      depends_on:\n        - create_user\n\n    # FlowDrop: Log Node\n    - id: log_registration\n      kind: Task\n      name: Log successful registration\n      inline:\n        execution:\n          type: deterministic\n          runtime: drupal\n          entrypoint: \"Drupal\\\\flowdrop\\\\NodeHandler\\\\LogMessage::execute\"\n      input:\n        level: info\n        message: \"User registered: ${{ workflow.input.username }} (${{ workflow.input.email }})\"\n        context:\n          user_id: \"${{ steps.create_user.output.entity_id }}\"\n          newsletter: \"${{ workflow.input.newsletter_opt_in }}\"\n      depends_on:\n        - send_verification_email\n        - send_welcome_email\n\n    # FlowDrop: End Node\n    - id: return_success\n      kind: Task\n      name: Return success response\n      inline:\n        execution:\n          type: deterministic\n        output:\n          type: object\n          properties:\n            user_id:\n              type: integer\n            status:\n              type: string\n            verification_sent:\n              type: boolean\n            welcome_email_sent:\n              type: boolean\n      input:\n        user_id: \"${{ steps.create_user.output.entity_id }}\"\n        verification_sent: \"${{ steps.send_verification_email.output.sent }}\"\n        welcome_sent: \"${{ steps.send_welcome_email.output.sent }}\"\n      depends_on:\n        - log_registration\n\n  # Error handling\n  error_handling:\n    on_failure: rollback\n    rollback_steps:\n      - id: delete_partial_user\n        kind: Task\n        name: Delete partially created user\n        inline:\n          execution:\n            type: deterministic\n            runtime: drupal\n            entrypoint: \"Drupal\\\\flowdrop\\\\NodeHandler\\\\DeleteEntity::execute\"\n        input:\n          entity_type: user\n          entity_id: \"${{ steps.create_user.output.entity_id }}\"\n        condition: \"${{ steps.create_user.status == 'completed' }}\"\n\n  timeout_seconds: 60\n\n  observability:\n    logging:\n      level: info\n    metrics:\n      enabled: true\n      custom_labels:\n        registration_source: webhook\n        newsletter_opt_in: \"${{ workflow.input.newsletter_opt_in }}\"\n\n# Drupal FlowDrop-specific runtime bindings\nruntime:\n  type: drupal\n  bindings:\n    flowdrop:\n      diagram_id: user_registration_v3\n      visual_editor_path: /admin/flowdrop/user_registration_v3\n\n      # FlowDrop node type mappings\n      node_handlers:\n        validate:\n          class: \"Drupal\\\\flowdrop\\\\NodeHandler\\\\ValidateNode\"\n        database_query:\n          class: \"Drupal\\\\flowdrop\\\\NodeHandler\\\\DatabaseQuery\"\n        create_entity:\n          class: \"Drupal\\\\flowdrop\\\\NodeHandler\\\\CreateEntity\"\n        send_email:\n          class: \"Drupal\\\\flowdrop\\\\NodeHandler\\\\SendEmail\"\n        webhook:\n          class: \"Drupal\\\\flowdrop\\\\NodeHandler\\\\WebhookCall\"\n        decision:\n          class: \"Drupal\\\\flowdrop\\\\NodeHandler\\\\DecisionNode\"\n        log:\n          class: \"Drupal\\\\flowdrop\\\\NodeHandler\\\\LogMessage\"\n\n      # Canvas position metadata (for visual editor sync)\n      canvas:\n        validate_input: { x: 100, y: 50 }\n        check_terms: { x: 100, y: 150 }\n        check_email_exists: { x: 50, y: 250 }\n        check_username_exists: { x: 200, y: 250 }\n        check_duplicates: { x: 125, y: 350 }\n        create_user: { x: 200, y: 450 }\n        return_duplicate_error: { x: 50, y: 450 }\n        generate_verification_token: { x: 200, y: 550 }\n        send_verification_email: { x: 150, y: 650 }\n        send_welcome_email: { x: 300, y: 550 }\n        sync_to_crm: { x: 400, y: 550 }\n        log_registration: { x: 200, y: 750 }\n        return_success: { x: 200, y: 850 }\n",
    "category": "Getting Started"
  },
  {
    "name": "drupal-maestro-mapping.yaml",
    "path": "adapters/drupal-maestro-mapping.yaml",
    "content": "# Example: Maestro Business Process to OSSA Workflow Mapping\n# Demonstrates how Drupal Maestro templates map to OSSA Workflows\napiVersion: ossa/v0.3.0\nkind: Workflow\nmetadata:\n  name: maestro-content-approval\n  version: 1.0.0\n  description: Content approval workflow (Maestro template mapping)\n  labels:\n    runtime: drupal\n    engine: maestro\n    domain: content-management\n  annotations:\n    drupal.ossa.io/maestro-template: content_approval_v2\n    drupal.ossa.io/maestro-version: \"2.1.0\"\n\nspec:\n  # Maestro Process Initiation → OSSA Triggers\n  triggers:\n    - type: event\n      source: drupal.entity\n      event: node.presave\n      filter:\n        moderation_state: needs_review\n    - type: api\n      endpoint: /api/workflows/content-approval/start\n      method: POST\n\n  # Maestro Process Variables → OSSA Input\n  inputs:\n    type: object\n    properties:\n      node_id:\n        type: integer\n        description: The Drupal node ID\n      node_type:\n        type: string\n        description: Content type (bundle)\n      author_uid:\n        type: integer\n        description: Content author user ID\n      reviewer_role:\n        type: string\n        default: content_reviewer\n        description: Role required for review\n      priority:\n        type: string\n        enum: [low, normal, high, urgent]\n        default: normal\n    required:\n      - node_id\n      - node_type\n      - author_uid\n\n  # Maestro Process Variables → OSSA Output\n  outputs:\n    type: object\n    properties:\n      final_status:\n        type: string\n        enum: [approved, rejected, revision_requested]\n      reviewer_id:\n        type: integer\n      review_date:\n        type: string\n        format: date-time\n      revision_count:\n        type: integer\n      total_duration_hours:\n        type: number\n\n  # Maestro Tasks → OSSA Workflow Steps\n  steps:\n    # Maestro: Set Process Variables\n    - id: initialize\n      kind: Task\n      name: Initialize workflow variables\n      inline:\n        execution:\n          type: deterministic\n          runtime: drupal\n          entrypoint: \"Drupal\\\\ossa_adapter\\\\TaskHandler\\\\MaestroSetVariables::execute\"\n        input:\n          type: object\n          properties:\n            variables:\n              type: object\n        output:\n          type: object\n          properties:\n            revision_count:\n              type: integer\n            started_at:\n              type: string\n      input:\n        variables:\n          revision_count: 0\n          started_at: \"${{ now() }}\"\n\n    # Maestro: Assign Task to Role\n    - id: assign_reviewer\n      kind: Task\n      name: Assign to content reviewer\n      ref: ./tasks/assign-to-role.yaml\n      input:\n        role: \"${{ workflow.input.reviewer_role }}\"\n        task_type: content_review\n        priority: \"${{ workflow.input.priority }}\"\n        entity_id: \"${{ workflow.input.node_id }}\"\n      depends_on:\n        - initialize\n\n    # Maestro: Notify Assignee\n    - id: notify_reviewer\n      kind: Task\n      name: Send review notification\n      ref: ./tasks/send-notification.yaml\n      input:\n        user_id: \"${{ steps.assign_reviewer.output.assigned_user_id }}\"\n        template: content_review_request\n        variables:\n          node_title: \"${{ steps.initialize.output.node_title }}\"\n          node_url: \"/node/${{ workflow.input.node_id }}\"\n          priority: \"${{ workflow.input.priority }}\"\n      depends_on:\n        - assign_reviewer\n\n    # Maestro: Interactive Task (Human Review)\n    - id: human_review\n      kind: Task\n      name: Content review decision\n      inline:\n        execution:\n          type: human\n          assignee: \"${{ steps.assign_reviewer.output.assigned_user_id }}\"\n          timeout_hours: 72\n          escalation:\n            after_hours: 48\n            to_role: senior_editor\n        input:\n          type: object\n          properties:\n            decision:\n              type: string\n              enum: [approve, reject, request_revision]\n            comments:\n              type: string\n            quality_score:\n              type: integer\n              minimum: 1\n              maximum: 5\n          required:\n            - decision\n        output:\n          type: object\n          properties:\n            decision:\n              type: string\n            comments:\n              type: string\n            quality_score:\n              type: integer\n            reviewed_at:\n              type: string\n            reviewer_id:\n              type: integer\n      depends_on:\n        - notify_reviewer\n\n    # Maestro: Exclusive Gateway (Decision Branch)\n    - id: process_decision\n      kind: Task\n      name: Route based on decision\n      inline:\n        execution:\n          type: deterministic\n          runtime: drupal\n        output:\n          type: object\n          properties:\n            branch:\n              type: string\n              enum: [approved, rejected, revision]\n      input:\n        decision: \"${{ steps.human_review.output.decision }}\"\n      depends_on:\n        - human_review\n\n    # Maestro: Update Entity (Approved Branch)\n    - id: publish_content\n      kind: Task\n      name: Publish approved content\n      ref: ./tasks/update-moderation-state.yaml\n      condition: \"${{ steps.process_decision.output.branch == 'approved' }}\"\n      input:\n        node_id: \"${{ workflow.input.node_id }}\"\n        new_state: published\n        log_message: \"Approved by reviewer\"\n      depends_on:\n        - process_decision\n\n    # Maestro: Notify Author (Approved)\n    - id: notify_author_approved\n      kind: Task\n      name: Notify author of approval\n      ref: ./tasks/send-notification.yaml\n      condition: \"${{ steps.process_decision.output.branch == 'approved' }}\"\n      input:\n        user_id: \"${{ workflow.input.author_uid }}\"\n        template: content_approved\n        variables:\n          node_title: \"${{ steps.initialize.output.node_title }}\"\n          reviewer_comments: \"${{ steps.human_review.output.comments }}\"\n      depends_on:\n        - publish_content\n\n    # Maestro: Update Entity (Rejected Branch)\n    - id: archive_content\n      kind: Task\n      name: Archive rejected content\n      ref: ./tasks/update-moderation-state.yaml\n      condition: \"${{ steps.process_decision.output.branch == 'rejected' }}\"\n      input:\n        node_id: \"${{ workflow.input.node_id }}\"\n        new_state: archived\n        log_message: \"Rejected: ${{ steps.human_review.output.comments }}\"\n      depends_on:\n        - process_decision\n\n    # Maestro: Notify Author (Rejected)\n    - id: notify_author_rejected\n      kind: Task\n      name: Notify author of rejection\n      ref: ./tasks/send-notification.yaml\n      condition: \"${{ steps.process_decision.output.branch == 'rejected' }}\"\n      input:\n        user_id: \"${{ workflow.input.author_uid }}\"\n        template: content_rejected\n        variables:\n          node_title: \"${{ steps.initialize.output.node_title }}\"\n          rejection_reason: \"${{ steps.human_review.output.comments }}\"\n      depends_on:\n        - archive_content\n\n    # Maestro: Loop Back (Revision Branch)\n    - id: request_revision\n      kind: Task\n      name: Update for revision\n      ref: ./tasks/update-moderation-state.yaml\n      condition: \"${{ steps.process_decision.output.branch == 'revision' }}\"\n      input:\n        node_id: \"${{ workflow.input.node_id }}\"\n        new_state: draft\n        log_message: \"Revision requested: ${{ steps.human_review.output.comments }}\"\n      depends_on:\n        - process_decision\n\n    # Maestro: Notify Author (Revision)\n    - id: notify_author_revision\n      kind: Task\n      name: Notify author of revision request\n      ref: ./tasks/send-notification.yaml\n      condition: \"${{ steps.process_decision.output.branch == 'revision' }}\"\n      input:\n        user_id: \"${{ workflow.input.author_uid }}\"\n        template: content_revision_requested\n        variables:\n          node_title: \"${{ steps.initialize.output.node_title }}\"\n          revision_notes: \"${{ steps.human_review.output.comments }}\"\n          edit_url: \"/node/${{ workflow.input.node_id }}/edit\"\n      depends_on:\n        - request_revision\n\n    # Maestro: Wait for Resubmission (Loop)\n    - id: wait_resubmission\n      kind: Task\n      name: Wait for author to resubmit\n      condition: \"${{ steps.process_decision.output.branch == 'revision' }}\"\n      inline:\n        execution:\n          type: event_wait\n          timeout_hours: 168  # 7 days\n          event:\n            source: drupal.entity\n            type: node.update\n            filter:\n              nid: \"${{ workflow.input.node_id }}\"\n              moderation_state: needs_review\n      depends_on:\n        - notify_author_revision\n\n    # Maestro: Increment Counter and Loop\n    - id: increment_revision\n      kind: Task\n      name: Increment revision counter\n      condition: \"${{ steps.process_decision.output.branch == 'revision' }}\"\n      inline:\n        execution:\n          type: deterministic\n        output:\n          type: object\n          properties:\n            new_count:\n              type: integer\n      input:\n        current_count: \"${{ steps.initialize.output.revision_count }}\"\n      depends_on:\n        - wait_resubmission\n      # Note: In a full implementation, this would loop back to assign_reviewer\n\n  # Workflow-level error handling\n  error_handling:\n    on_failure: compensate\n    compensation_steps:\n      - id: notify_admin_failure\n        kind: Task\n        name: Notify admin of workflow failure\n        ref: ./tasks/send-notification.yaml\n        input:\n          user_id: 1  # Admin\n          template: workflow_failure\n          variables:\n            workflow_name: content-approval\n            node_id: \"${{ workflow.input.node_id }}\"\n            error: \"${{ workflow.error.message }}\"\n\n  # Workflow timeout\n  timeout_seconds: 604800  # 7 days\n\n  observability:\n    logging:\n      level: info\n      include_step_results: true\n    metrics:\n      enabled: true\n      custom_labels:\n        content_type: \"${{ workflow.input.node_type }}\"\n        priority: \"${{ workflow.input.priority }}\"\n\n# Drupal Maestro-specific runtime bindings\nruntime:\n  type: drupal\n  bindings:\n    maestro:\n      template_id: content_approval_v2\n      process_name: \"Content Approval\"\n      task_console_path: /admin/maestro/outstanding\n      initiator_variable: initiator_uid\n\n      # Maestro task type mappings\n      task_types:\n        human_review:\n          maestro_type: interactive\n          handler: MaestroInteractiveTask\n        assign_reviewer:\n          maestro_type: set_process_variable\n          handler: MaestroSetProcessVariable\n        notify_reviewer:\n          maestro_type: send_email\n          handler: MaestroSendEmail\n\n      # Variable mappings\n      variables:\n        revision_count:\n          type: integer\n          persist: true\n        assigned_reviewer:\n          type: entity_reference\n          target_type: user\n",
    "category": "Getting Started"
  },
  {
    "name": "mistral-agent.yaml",
    "path": "adapters/mistral-agent.yaml",
    "content": "apiVersion: ossa/v0.3.0\nkind: Agent\nmetadata:\n  name: mistral-code-assistant\n  version: 1.0.0\n  description: Code review and analysis assistant using Mistral Large\n  labels:\n    provider: mistral\n    purpose: code-review\n    language: multi\n\nspec:\n  role: |\n    You are an expert code reviewer and software architect.\n    You provide detailed, constructive feedback on code quality, performance, and best practices.\n    You can analyze code in multiple programming languages and suggest improvements.\n\n  llm:\n    provider: mistral\n    model: mistral-large-latest\n    temperature: 0.3\n    maxTokens: 4096\n\n  tools:\n    - type: function\n      name: analyze_complexity\n      capabilities:\n        - code-analysis\n        - complexity-metrics\n      config:\n        max_depth: 10\n        metrics:\n          - cyclomatic\n          - cognitive\n          - halstead\n\n    - type: function\n      name: check_security\n      capabilities:\n        - security-scan\n        - vulnerability-detection\n\nextensions:\n  mistral:\n    # Mistral-specific configuration\n    model: mistral-large-latest\n    api_key: ${MISTRAL_API_KEY}\n    temperature: 0.3\n    max_tokens: 4096\n    top_p: 0.95\n    random_seed: 42\n    safe_mode: false\n\n    # Define tools in Mistral format\n    tools:\n      - type: function\n        function:\n          name: analyze_complexity\n          description: Analyze code complexity and generate metrics\n          parameters:\n            type: object\n            properties:\n              code:\n                type: string\n                description: The code to analyze\n              language:\n                type: string\n                description: Programming language (e.g., javascript, python, java)\n                enum: [javascript, python, java, go, rust, typescript]\n              metrics:\n                type: array\n                items:\n                  type: string\n                description: Metrics to calculate\n            required:\n              - code\n              - language\n\n      - type: function\n        function:\n          name: check_security\n          description: Scan code for security vulnerabilities and best practice violations\n          parameters:\n            type: object\n            properties:\n              code:\n                type: string\n                description: The code to scan\n              language:\n                type: string\n                description: Programming language\n              severity_threshold:\n                type: string\n                enum: [low, medium, high, critical]\n                description: Minimum severity level to report\n            required:\n              - code\n              - language\n\n      - type: function\n        function:\n          name: suggest_refactoring\n          description: Suggest code refactoring opportunities\n          parameters:\n            type: object\n            properties:\n              code:\n                type: string\n                description: The code to analyze\n              language:\n                type: string\n                description: Programming language\n              focus:\n                type: array\n                items:\n                  type: string\n                description: Areas to focus on\n                enum:\n                  - performance\n                  - readability\n                  - maintainability\n                  - testability\n            required:\n              - code\n              - language\n\n  # Observability\n  observability:\n    enabled: true\n    metrics:\n      - token_usage\n      - latency\n      - tool_calls\n    traces:\n      provider: opentelemetry\n      endpoint: http://localhost:4318/v1/traces\n\n  # Rate limiting\n  ratelimit:\n    requests_per_minute: 60\n    tokens_per_minute: 100000\n\n  # Caching\n  cache:\n    enabled: true\n    ttl: 3600\n    strategy: semantic\n",
    "category": "Getting Started"
  },
  {
    "name": "symfony-messenger-task.yaml",
    "path": "adapters/symfony-messenger-task.yaml",
    "content": "# Example: OSSA Task executed via Symfony Messenger\n# Demonstrates async task execution with queue-based processing\napiVersion: ossa/v0.3.0\nkind: Task\nmetadata:\n  name: send-email-symfony\n  version: 1.0.0\n  description: Send email using Symfony Mailer via Messenger\n  labels:\n    runtime: symfony\n    transport: messenger\n    domain: communication\n\nspec:\n  execution:\n    type: deterministic\n    runtime: symfony\n    entrypoint: \"App\\\\TaskHandler\\\\SendEmailHandler::execute\"\n    timeout_seconds: 30\n\n  capabilities:\n    - send_email\n    - render_template\n    - validate_email\n\n  input:\n    type: object\n    properties:\n      to:\n        type: string\n        format: email\n        description: Recipient email address\n      subject:\n        type: string\n        description: Email subject line\n      template:\n        type: string\n        description: Twig template name\n      variables:\n        type: object\n        description: Template variables\n        additionalProperties: true\n      attachments:\n        type: array\n        items:\n          type: object\n          properties:\n            filename:\n              type: string\n            content_type:\n              type: string\n            path:\n              type: string\n      priority:\n        type: string\n        enum: [low, normal, high]\n        default: normal\n    required:\n      - to\n      - subject\n      - template\n\n  output:\n    type: object\n    properties:\n      message_id:\n        type: string\n        description: Email message ID\n      sent_at:\n        type: string\n        format: date-time\n      status:\n        type: string\n        enum: [sent, queued, failed]\n      delivery_info:\n        type: object\n        properties:\n          transport:\n            type: string\n          queue_position:\n            type: integer\n\n  error_handling:\n    on_error: retry\n    retry:\n      max_attempts: 3\n      initial_delay_ms: 1000\n      backoff_strategy: exponential\n      retryable_errors:\n        - SMTP_TEMPORARY_ERROR\n        - CONNECTION_TIMEOUT\n        - RATE_LIMITED\n\n  observability:\n    logging:\n      level: info\n    metrics:\n      enabled: true\n      custom_labels:\n        email_type: \"${{ input.template }}\"\n        priority: \"${{ input.priority }}\"\n\n# Symfony-specific runtime bindings\nruntime:\n  type: symfony\n  bindings:\n    send_email:\n      service: \"@Symfony\\\\Component\\\\Mailer\\\\MailerInterface\"\n      method: \"send\"\n    render_template:\n      service: \"@Twig\\\\Environment\"\n      method: \"render\"\n    validate_email:\n      service: \"@Symfony\\\\Component\\\\Validator\\\\Validator\\\\ValidatorInterface\"\n      method: \"validate\"\n\n  # Messenger configuration\n  messenger:\n    transport: ossa_tasks\n    routing_key: email.send\n    priority: \"${{ input.priority }}\"\n    delay_ms: 0\n\n    # Message headers\n    headers:\n      X-OSSA-Task-Type: send-email\n      X-OSSA-Version: v0.3.0\n      X-Priority: \"${{ input.priority }}\"\n\n    # Retry configuration (overrides default)\n    retry:\n      max_retries: 3\n      delay: 1000\n      multiplier: 2\n      max_delay: 60000\n",
    "category": "Getting Started"
  },
  {
    "name": "symfony-messenger-workflow.yaml",
    "path": "adapters/symfony-messenger-workflow.yaml",
    "content": "# Example: OSSA Workflow executed via Symfony Messenger\n# Demonstrates multi-step workflow with async Task orchestration\napiVersion: ossa/v0.3.0\nkind: Workflow\nmetadata:\n  name: user-onboarding-symfony\n  version: 1.0.0\n  description: Complete user onboarding process with email verification\n  labels:\n    runtime: symfony\n    transport: messenger\n    domain: user-management\n\nspec:\n  triggers:\n    - type: event\n      source: symfony.event_dispatcher\n      event: user.registered\n    - type: api\n      endpoint: /api/onboarding/start\n      method: POST\n\n  inputs:\n    type: object\n    properties:\n      user_id:\n        type: string\n        format: uuid\n      email:\n        type: string\n        format: email\n      username:\n        type: string\n      registration_source:\n        type: string\n        enum: [web, mobile, api, oauth]\n        default: web\n    required:\n      - user_id\n      - email\n      - username\n\n  outputs:\n    type: object\n    properties:\n      onboarding_status:\n        type: string\n        enum: [completed, pending_verification, failed]\n      verification_token_sent:\n        type: boolean\n      welcome_email_sent:\n        type: boolean\n      profile_created:\n        type: boolean\n      total_steps_completed:\n        type: integer\n\n  steps:\n    # Step 1: Validate email address\n    - id: validate_email\n      kind: Task\n      name: Validate user email\n      inline:\n        execution:\n          type: deterministic\n          runtime: symfony\n          entrypoint: \"App\\\\TaskHandler\\\\EmailValidatorHandler::execute\"\n        input:\n          type: object\n          properties:\n            email:\n              type: string\n              format: email\n        output:\n          type: object\n          properties:\n            valid:\n              type: boolean\n            normalized_email:\n              type: string\n            domain_check:\n              type: boolean\n      input:\n        email: \"${{ workflow.input.email }}\"\n      timeout_seconds: 10\n      retry:\n        max_attempts: 2\n\n    # Step 2: Create user profile\n    - id: create_profile\n      kind: Task\n      name: Create user profile\n      inline:\n        execution:\n          type: deterministic\n          runtime: symfony\n          entrypoint: \"App\\\\TaskHandler\\\\ProfileCreatorHandler::execute\"\n        input:\n          type: object\n          properties:\n            user_id:\n              type: string\n            email:\n              type: string\n            username:\n              type: string\n        output:\n          type: object\n          properties:\n            profile_id:\n              type: string\n            success:\n              type: boolean\n      input:\n        user_id: \"${{ workflow.input.user_id }}\"\n        email: \"${{ steps.validate_email.output.normalized_email }}\"\n        username: \"${{ workflow.input.username }}\"\n      depends_on:\n        - validate_email\n      timeout_seconds: 30\n\n    # Step 3: Generate verification token\n    - id: generate_token\n      kind: Task\n      name: Generate email verification token\n      inline:\n        execution:\n          type: deterministic\n          runtime: symfony\n          entrypoint: \"App\\\\TaskHandler\\\\TokenGeneratorHandler::execute\"\n        input:\n          type: object\n          properties:\n            user_id:\n              type: string\n            expiry_hours:\n              type: integer\n        output:\n          type: object\n          properties:\n            token:\n              type: string\n            expires_at:\n              type: string\n              format: date-time\n      input:\n        user_id: \"${{ workflow.input.user_id }}\"\n        expiry_hours: 24\n      depends_on:\n        - create_profile\n\n    # Step 4: Send verification email\n    - id: send_verification_email\n      kind: Task\n      name: Send email verification\n      ref: ./symfony-messenger-task.yaml\n      input:\n        to: \"${{ steps.validate_email.output.normalized_email }}\"\n        subject: \"Verify your email address\"\n        template: \"email/verification\"\n        variables:\n          username: \"${{ workflow.input.username }}\"\n          verification_url: \"https://example.com/verify?token=${{ steps.generate_token.output.token }}\"\n          expires_at: \"${{ steps.generate_token.output.expires_at }}\"\n        priority: high\n      depends_on:\n        - generate_token\n      retry:\n        max_attempts: 3\n        backoff_strategy: exponential\n\n    # Step 5: Send welcome email (parallel with verification)\n    - id: send_welcome_email\n      kind: Task\n      name: Send welcome email\n      ref: ./symfony-messenger-task.yaml\n      input:\n        to: \"${{ steps.validate_email.output.normalized_email }}\"\n        subject: \"Welcome to Our Platform\"\n        template: \"email/welcome\"\n        variables:\n          username: \"${{ workflow.input.username }}\"\n          profile_url: \"https://example.com/profile/${{ workflow.input.user_id }}\"\n        priority: normal\n      depends_on:\n        - create_profile\n      # Runs in parallel with send_verification_email\n\n    # Step 6: Create initial preferences\n    - id: create_preferences\n      kind: Task\n      name: Initialize user preferences\n      inline:\n        execution:\n          type: deterministic\n          runtime: symfony\n          entrypoint: \"App\\\\TaskHandler\\\\PreferencesHandler::execute\"\n        input:\n          type: object\n          properties:\n            user_id:\n              type: string\n            defaults:\n              type: object\n        output:\n          type: object\n          properties:\n            preferences_id:\n              type: string\n            applied_defaults:\n              type: array\n      input:\n        user_id: \"${{ workflow.input.user_id }}\"\n        defaults:\n          language: en\n          timezone: UTC\n          notifications:\n            email: true\n            push: false\n          newsletter: true\n          theme: auto\n      depends_on:\n        - create_profile\n\n    # Step 7: Sync to external services\n    - id: sync_external\n      kind: Task\n      name: Sync to external services\n      inline:\n        execution:\n          type: deterministic\n          runtime: symfony\n          entrypoint: \"App\\\\TaskHandler\\\\ExternalSyncHandler::execute\"\n      input:\n        user_id: \"${{ workflow.input.user_id }}\"\n        services:\n          - analytics\n          - crm\n          - mailing_list\n        data:\n          email: \"${{ steps.validate_email.output.normalized_email }}\"\n          source: \"${{ workflow.input.registration_source }}\"\n      depends_on:\n        - create_preferences\n      # Optional step - failure doesn't fail workflow\n      error_handling:\n        on_error: continue\n\n    # Step 8: Track onboarding event\n    - id: track_event\n      kind: Task\n      name: Track onboarding analytics\n      inline:\n        execution:\n          type: deterministic\n          runtime: symfony\n          entrypoint: \"App\\\\TaskHandler\\\\AnalyticsHandler::execute\"\n      input:\n        event_name: \"user.onboarding.completed\"\n        user_id: \"${{ workflow.input.user_id }}\"\n        properties:\n          source: \"${{ workflow.input.registration_source }}\"\n          profile_created: \"${{ steps.create_profile.output.success }}\"\n          verification_sent: true\n          welcome_sent: true\n          preferences_set: true\n          external_synced: \"${{ steps.sync_external.status == 'completed' }}\"\n      depends_on:\n        - send_verification_email\n        - send_welcome_email\n        - sync_external\n\n  error_handling:\n    on_failure: compensate\n    compensation_steps:\n      - id: cleanup_profile\n        kind: Task\n        name: Remove incomplete profile\n        inline:\n          execution:\n            type: deterministic\n            runtime: symfony\n            entrypoint: \"App\\\\TaskHandler\\\\ProfileCleanupHandler::execute\"\n        input:\n          user_id: \"${{ workflow.input.user_id }}\"\n        condition: \"${{ steps.create_profile.status == 'completed' }}\"\n\n      - id: notify_admin\n        kind: Task\n        name: Notify admin of failed onboarding\n        ref: ./symfony-messenger-task.yaml\n        input:\n          to: admin@example.com\n          subject: \"User onboarding failed\"\n          template: \"admin/onboarding-failure\"\n          variables:\n            user_id: \"${{ workflow.input.user_id }}\"\n            email: \"${{ workflow.input.email }}\"\n            error: \"${{ workflow.error.message }}\"\n            failed_step: \"${{ workflow.error.step_id }}\"\n\n  timeout_seconds: 300\n\n  observability:\n    logging:\n      level: info\n      include_step_results: true\n    metrics:\n      enabled: true\n      custom_labels:\n        registration_source: \"${{ workflow.input.registration_source }}\"\n        workflow_type: onboarding\n    tracing:\n      enabled: true\n      sample_rate: 1.0\n\n# Symfony Messenger configuration for workflow\nruntime:\n  type: symfony\n  messenger:\n    transport: ossa_workflows\n    routing_key: workflow.onboarding\n    priority: high\n\n    # Step coordination settings\n    step_dispatch:\n      transport: ossa_tasks\n      parallel_execution: true  # Allow parallel step execution when possible\n      batch_size: 10\n\n    # Workflow state storage\n    state_store:\n      type: redis\n      key_prefix: \"ossa:workflow:\"\n      ttl_hours: 168  # 7 days\n\n    # Headers for all messages\n    headers:\n      X-OSSA-Workflow-Type: user-onboarding\n      X-OSSA-Version: v0.3.0\n\n  # Service bindings\n  bindings:\n    create_profile:\n      service: \"@App\\\\Service\\\\ProfileService\"\n      method: \"create\"\n    generate_token:\n      service: \"@App\\\\Service\\\\TokenService\"\n      method: \"generate\"\n    analytics:\n      service: \"@App\\\\Service\\\\AnalyticsService\"\n      method: \"track\"\n",
    "category": "Getting Started"
  },
  {
    "name": "code-review-workflow.yml",
    "path": "adk-integration/code-review-workflow.yml",
    "content": "# Example: ADK Code Review Workflow with OSSA Agents\n# This demonstrates how OSSA agents work with ADK orchestration patterns\n\napiVersion: ossa/v0.3.0\nkind: Workflow\nmetadata:\n  name: code-review-workflow\n  description: 'Multi-agent code review using ADK patterns'\n\nspec:\n  # ADK orchestration pattern\n  adk_pattern: sequential\n\n  # Agents involved in workflow\n  agents:\n    - name: code-analyzer\n      type: LlmAgent\n      ossa_type: worker\n      capabilities:\n        - code-analysis\n        - static-analysis\n      instruction: |\n        Analyze the provided code for:\n        - Code quality issues\n        - Potential bugs\n        - Performance concerns\n        - Security vulnerabilities\n        Store findings in {analysis_results}\n      output_key: analysis_results\n\n    - name: style-checker\n      type: LlmAgent\n      ossa_type: critic\n      capabilities:\n        - style-checking\n        - formatting\n      instruction: |\n        Check code style based on {analysis_results}:\n        - Naming conventions\n        - Code formatting\n        - Documentation completeness\n        Store style issues in {style_report}\n      output_key: style_report\n\n    - name: security-auditor\n      type: CustomAgent\n      custom_type: governor\n      ossa_type: governor\n      capabilities:\n        - security-scanning\n        - vulnerability-detection\n      policies:\n        - name: owasp-top-10\n          severity: high\n        - name: cwe-sans-25\n          severity: critical\n      instruction: |\n        Audit code for security issues using {analysis_results}\n        Apply OWASP and CWE policies\n        Store violations in {security_audit}\n      output_key: security_audit\n\n    - name: review-aggregator\n      type: WorkflowAgent\n      workflow_type: parallel\n      ossa_type: orchestrator\n      sub_agents:\n        - code-analyzer\n        - style-checker\n        - security-auditor\n      instruction: |\n        Aggregate all review results:\n        - {analysis_results}\n        - {style_report}  \n        - {security_audit}\n        Generate comprehensive review report\n      output_key: final_review\n\n  # Execution configuration\n  execution:\n    # Use ADK state management\n    state_management: adk_session\n\n    # Tool delegation\n    tool_delegation:\n      type: explicit\n      tools:\n        - name: git_operations\n          capabilities: [version-control]\n        - name: issue_tracker\n          capabilities: [issue-management]\n\n    # Conditional execution based on findings\n    conditions:\n      - agent: security-auditor\n        condition: \"session.state.analysis_results.severity > 'medium'\"\n      - agent: style-checker\n        condition: 'session.state.analysis_results.lines_of_code > 100'\n\n    # Loop configuration for iterative review\n    loop_options:\n      max_iterations: 3\n      break_condition: 'session.state.security_audit.violations.length == 0'\n\n  # ADK integration settings\n  adk_config:\n    # Model configuration\n    models:\n      default: gemini-2.0-flash\n      specialized:\n        security-auditor: gemini-2.0-pro\n\n    # Performance settings\n    performance:\n      parallel_execution: true\n      cache_session_state: true\n      state_persistence: redis\n\n    # Error handling\n    error_handling:\n      retry_count: 3\n      fallback_pattern: sequential\n# Example usage with ADK adapter:\n#\n# const adapter = new OSSAADKAdapter();\n# await adapter.loadAgent('.agents/code-analyzer');\n# await adapter.loadAgent('.agents/style-checker');\n# await adapter.loadAgent('.agents/security-auditor');\n# await adapter.loadAgent('.agents/review-aggregator');\n#\n# const result = await adapter.executeOrchestration(\n#   'sequential',\n#   ['code-analyzer', 'style-checker', 'security-auditor', 'review-aggregator'],\n#   { code: sourceCode },\n#   { conditions: [...], loop_options: {...} }\n# );\n",
    "category": "Integration Patterns"
  },
  {
    "name": "customer-support.yml",
    "path": "adk-integration/customer-support.yml",
    "content": "# Example: ADK Customer Support System with OSSA Agents\n# Demonstrates Coordinator and Dispatcher patterns\n\napiVersion: ossa/v0.3.0\nkind: Workflow\nmetadata:\n  name: customer-support-system\n  description: 'Multi-agent customer support with intelligent routing'\n\nspec:\n  # ADK Coordinator pattern for complex support tasks\n  adk_pattern: coordinator\n\n  agents:\n    # Coordinator agent\n    - name: support-coordinator\n      type: LlmAgent\n      ossa_type: orchestrator\n      model: gemini-2.0-pro\n      instruction: |\n        Analyze customer request and determine:\n        1. Request type (billing, technical, product, complaint)\n        2. Urgency level (low, medium, high, critical)\n        3. Required specialists\n        4. Delegation strategy\n\n        Route to appropriate agents based on analysis.\n        Store routing decision in {routing_plan}\n      output_key: routing_plan\n      capabilities:\n        - request-analysis\n        - intent-classification\n        - routing-decision\n\n    # Specialist agents\n    - name: billing-specialist\n      type: LlmAgent\n      ossa_type: worker\n      instruction: |\n        Handle billing-related inquiries:\n        - Payment issues\n        - Subscription changes\n        - Refund requests\n        - Invoice questions\n\n        Use {routing_plan} context\n        Store response in {billing_response}\n      output_key: billing_response\n      tools:\n        - database_query\n        - api_call\n      capabilities:\n        - billing-operations\n        - payment-processing\n\n    - name: technical-specialist\n      type: LlmAgent\n      ossa_type: worker\n      instruction: |\n        Resolve technical issues:\n        - Bug reports\n        - Feature questions\n        - Integration problems\n        - Performance issues\n\n        Reference {routing_plan} for context\n        Store solution in {technical_response}\n      output_key: technical_response\n      tools:\n        - api_call\n        - database_query\n      capabilities:\n        - technical-support\n        - troubleshooting\n\n    - name: product-specialist\n      type: LlmAgent\n      ossa_type: worker\n      instruction: |\n        Answer product questions:\n        - Feature explanations\n        - Best practices\n        - Use case guidance\n        - Product recommendations\n\n        Use {routing_plan} guidance\n        Store answer in {product_response}\n      output_key: product_response\n      capabilities:\n        - product-knowledge\n        - recommendation-engine\n\n    - name: escalation-handler\n      type: CustomAgent\n      custom_type: specialized\n      ossa_type: worker\n      instruction: |\n        Handle escalated issues:\n        - Complaints\n        - Complex problems\n        - VIP customers\n        - Legal matters\n\n        Review all previous responses\n        Store resolution in {escalation_response}\n      output_key: escalation_response\n      capabilities:\n        - escalation-management\n        - conflict-resolution\n\n    # Response aggregator\n    - name: response-synthesizer\n      type: WorkflowAgent\n      workflow_type: parallel\n      ossa_type: orchestrator\n      instruction: |\n        Synthesize all specialist responses:\n        - {billing_response}\n        - {technical_response}\n        - {product_response}\n        - {escalation_response}\n\n        Create unified customer response\n        Store in {final_response}\n      output_key: final_response\n      sub_agents:\n        - billing-specialist\n        - technical-specialist\n        - product-specialist\n        - escalation-handler\n\n  # Dispatcher configuration for routing\n  dispatcher_config:\n    routing_rules:\n      - pattern: 'billing|payment|invoice|refund'\n        agent: billing-specialist\n        priority: high\n\n      - pattern: 'bug|error|crash|slow|broken'\n        agent: technical-specialist\n        priority: critical\n\n      - pattern: 'how to|feature|can I|what is'\n        agent: product-specialist\n        priority: medium\n\n      - pattern: 'complaint|angry|frustrated|cancel'\n        agent: escalation-handler\n        priority: critical\n\n    fallback_agent: support-coordinator\n\n    # LLM-driven routing when rules don't match\n    llm_routing:\n      enabled: true\n      model: gemini-2.0-flash\n      instruction: |\n        Analyze request and select best agent:\n        - Consider request content\n        - Check customer history\n        - Evaluate urgency\n        - Match agent capabilities\n\n  # Coordination strategies\n  coordination:\n    strategy: adaptive # Changes based on request type\n\n    patterns:\n      simple_request:\n        pattern: dispatcher\n        condition: \"session.state.routing_plan.complexity === 'simple'\"\n\n      complex_request:\n        pattern: coordinator\n        condition: \"session.state.routing_plan.complexity === 'complex'\"\n\n      multi_issue:\n        pattern: parallel\n        condition: 'session.state.routing_plan.issue_count > 1'\n\n      escalated:\n        pattern: sequential\n        condition: 'session.state.routing_plan.requires_escalation === true'\n\n  # ADK communication patterns\n  communication:\n    # Shared session state\n    shared_state:\n      - customer_id\n      - request_history\n      - routing_plan\n      - urgency_level\n      - sentiment_score\n\n    # Agent handoff\n    handoff_config:\n      preserve_context: true\n      transfer_method: state_based # Via session.state\n      handoff_message: |\n        Transferring to {target_agent} because:\n        {handoff_reason}\n\n    # Callback mechanisms\n    callbacks:\n      on_routing_complete: log_routing_decision\n      on_response_ready: notify_customer\n      on_escalation: alert_supervisor\n\n  # Performance and optimization\n  adk_config:\n    performance:\n      # Agent pooling\n      agent_pool:\n        min_instances: 1\n        max_instances: 10\n        scale_based_on: request_volume\n\n      # Response caching\n      cache:\n        enabled: true\n        ttl: 3600\n        cache_key: 'request_hash'\n\n    # Quality assurance\n    quality:\n      # Response validation\n      validate_responses: true\n      min_confidence: 0.8\n\n      # Sentiment checking\n      check_sentiment: true\n      min_sentiment_score: 0.6\n\n    # Metrics and monitoring\n    metrics:\n      - response_time\n      - customer_satisfaction\n      - resolution_rate\n      - escalation_rate\n      - agent_utilization\n# Example usage with different patterns:\n#\n# 1. Simple request (Dispatcher):\n# const result = await adapter.executeOrchestration(\n#   'dispatcher',\n#   ['billing-specialist', 'technical-specialist', 'product-specialist'],\n#   { request: \"How do I update my payment method?\" },\n#   { router: customRouter }\n# );\n#\n# 2. Complex request (Coordinator):\n# const result = await adapter.executeOrchestration(\n#   'coordinator',\n#   ['support-coordinator', 'billing-specialist', 'technical-specialist', 'response-synthesizer'],\n#   { request: \"I have billing issues and the app keeps crashing\" }\n# );\n#\n# 3. Escalated issue (Sequential with conditions):\n# const result = await adapter.executeOrchestration(\n#   'sequential',\n#   ['support-coordinator', 'technical-specialist', 'escalation-handler', 'response-synthesizer'],\n#   { request: \"This is the 5th time I'm reporting this critical bug!\" }\n# );\n",
    "category": "Integration Patterns"
  },
  {
    "name": "data-pipeline.yml",
    "path": "adk-integration/data-pipeline.yml",
    "content": "# Example: ADK Data Processing Pipeline with OSSA Agents\n# Demonstrates LoopAgent and ConditionalAgent patterns\n\napiVersion: ossa/v0.3.0\nkind: Workflow\nmetadata:\n  name: data-processing-pipeline\n  description: 'Iterative data processing with conditional branches'\n\nspec:\n  # ADK Loop pattern for batch processing\n  adk_pattern: loop\n\n  agents:\n    - name: data-ingester\n      type: LlmAgent\n      ossa_type: worker\n      capabilities:\n        - data-ingestion\n        - format-conversion\n      instruction: |\n        Ingest data batch from source\n        Convert to standard format\n        Store in {raw_data}\n        Set {has_more_data} flag\n      output_key: raw_data\n      tools:\n        - api_call\n        - file_operation\n\n    - name: data-validator\n      type: LlmAgent\n      ossa_type: critic\n      capabilities:\n        - validation\n        - schema-checking\n      instruction: |\n        Validate {raw_data} against schema\n        Check data quality metrics\n        Store validation results in {validation_status}\n        Set {is_valid} flag\n      output_key: validation_status\n\n    - name: data-transformer\n      type: WorkflowAgent\n      workflow_type: conditional\n      ossa_type: orchestrator\n      instruction: |\n        Transform data based on {validation_status}:\n        - If valid: apply standard transformations\n        - If invalid: apply error corrections\n        Store in {transformed_data}\n      output_key: transformed_data\n      sub_agents:\n        - name: standard-transformer\n          condition: 'session.state.is_valid === true'\n        - name: error-corrector\n          condition: 'session.state.is_valid === false'\n\n    - name: data-enricher\n      type: CustomAgent\n      custom_type: specialized\n      ossa_type: worker\n      capabilities:\n        - data-enrichment\n        - ml-inference\n      instruction: |\n        Enrich {transformed_data} with:\n        - External API data\n        - ML model predictions\n        - Calculated metrics\n        Store in {enriched_data}\n      output_key: enriched_data\n\n    - name: data-loader\n      type: LlmAgent\n      ossa_type: worker\n      capabilities:\n        - database-operations\n        - data-persistence\n      instruction: |\n        Load {enriched_data} to target system\n        Update {batch_counter}\n        Log operation in {load_status}\n      output_key: load_status\n      tools:\n        - database_query\n\n  # Loop configuration\n  execution:\n    loop_config:\n      # Continue while more data exists\n      condition: 'session.state.has_more_data === true'\n      max_iterations: 100\n      batch_size: 1000\n\n      # Break conditions\n      break_conditions:\n        - 'session.state.error_count > 5'\n        - 'session.state.batch_counter >= session.state.total_batches'\n\n    # Conditional branches\n    conditional_config:\n      data-validator:\n        skip_if: 'session.state.skip_validation === true'\n\n      data-enricher:\n        execute_if: 'session.state.validation_status.quality_score > 0.8'\n\n      error-corrector:\n        execute_if: |\n          session.state.validation_status.errors.length > 0 &&\n          session.state.validation_status.errors.some(e => e.severity === 'critical')\n\n    # Parallel processing for sub-workflows\n    parallel_config:\n      enabled: true\n      max_workers: 5\n      distribute_by: 'session.state.raw_data.partition_key'\n\n  # ADK state management\n  adk_config:\n    state:\n      # Persistent state across iterations\n      persistent_keys:\n        - batch_counter\n        - total_processed\n        - error_count\n        - processing_metrics\n\n      # Temporary state (cleared each iteration)\n      temp_keys:\n        - raw_data\n        - validation_status\n        - transformed_data\n        - enriched_data\n\n    # Performance optimization\n    optimization:\n      cache_transformations: true\n      reuse_connections: true\n      batch_database_writes: true\n\n    # Error recovery\n    error_recovery:\n      checkpoint_frequency: 10 # Save state every 10 iterations\n      resume_on_failure: true\n      dead_letter_queue: true\n\n    # Monitoring\n    monitoring:\n      metrics:\n        - batches_processed\n        - records_transformed\n        - validation_failures\n        - enrichment_success_rate\n      alerts:\n        - condition: 'metrics.validation_failures > 10'\n          severity: warning\n        - condition: 'metrics.enrichment_success_rate < 0.95'\n          severity: critical\n# Example usage:\n#\n# const result = await adapter.executeOrchestration(\n#   'loop',\n#   ['data-ingester', 'data-validator', 'data-transformer', 'data-enricher', 'data-loader'],\n#   { source: 's3://data-bucket/input/' },\n#   {\n#     maxIterations: 100,\n#     condition: (state) => state.has_more_data,\n#     breakCondition: (result, state) => state.error_count > 5\n#   }\n# );\n",
    "category": "Integration Patterns"
  },
  {
    "name": "compliance-context-production.json",
    "path": "advanced/patterns/compliance-context-production.json",
    "content": "{\n  \"environment\": \"production\",\n  \"classification\": \"confidential\",\n  \"region\": \"us-east-1\",\n  \"industry\": \"financial-services\",\n  \"dataTypes\": [\n    \"financial-records\",\n    \"customer-data\",\n    \"transaction-logs\",\n    \"audit-trails\"\n  ],\n  \"regulatoryRequirements\": [\n    \"iso-42001\",\n    \"nist-ai-rmf\",\n    \"eu-ai-act\"\n  ],\n  \"complianceMetadata\": {\n    \"organization\": \"Enterprise Financial Corp\",\n    \"complianceOfficer\": \"compliance@enterprise.com\",\n    \"lastReview\": \"2024-01-15\",\n    \"nextReview\": \"2024-04-15\",\n    \"certifications\": [\n      \"ISO 27001:2022\",\n      \"SOC 2 Type II\",\n      \"PCI DSS Level 1\"\n    ]\n  },\n  \"enforcementPolicies\": {\n    \"productionDeployment\": {\n      \"minimumConformance\": \"gold\",\n      \"auditLogging\": \"mandatory\",\n      \"tlsRequired\": true,\n      \"humanOversight\": \"required\",\n      \"budgetLimits\": {\n        \"daily\": 100000,\n        \"monthly\": 2000000,\n        \"emergency\": 500000\n      }\n    },\n    \"stagingDeployment\": {\n      \"minimumConformance\": \"silver\",\n      \"auditLogging\": \"recommended\",\n      \"tlsRequired\": true,\n      \"humanOversight\": \"optional\"\n    },\n    \"developmentDeployment\": {\n      \"minimumConformance\": \"bronze\",\n      \"auditLogging\": \"optional\",\n      \"tlsRequired\": false,\n      \"humanOversight\": \"optional\"\n    }\n  }\n}",
    "category": "Production"
  },
  {
    "name": "model-router.ts",
    "path": "advanced/patterns/model-router.ts",
    "content": "/**\n * OSSA Model Router Pattern\n * =========================\n *\n * This example demonstrates the Model Router pattern for OSSA agents, which allows\n * dynamic selection of language models based on task requirements, cost constraints,\n * and performance needs.\n *\n * Key Features:\n * - Dynamic model selection based on task requirements\n * - Cost-aware routing\n * - Performance optimization\n * - Fallback strategies\n *\n * Directory Structure:\n * examples/advanced/patterns/\n *   ├── model-router.ts      # This file\n *   └── README.md            # Documentation\n *\n * Prerequisites:\n * - Node.js 18+\n * - TypeScript 5.0+\n * - Ollama running locally (for local models)\n * - API keys for cloud providers (if used)\n *\n * Usage:\n * 1. Install dependencies: `npm install @ossa/core dotenv`\n * 2. Start Ollama: `ollama serve`\n * 3. Pull models: `ollama pull llama3`\n * 4. Run: `npx ts-node model-router.ts`\n */\n\nimport { Agent, AgentConfig, AgentContext, AgentResponse } from '@ossa/core';\nimport dotenv from 'dotenv';\n\ndotenv.config();\n\n// Define model configurations\nconst MODEL_CONFIGS = {\n  llama3: {\n    provider: 'ollama',\n    model: 'llama3',\n    costPerToken: 0.000002,\n    avgLatencyMs: 1200,\n    maxTokens: 8192,\n    capabilities: ['text-generation', 'summarization', 'qna'],\n  },\n  mixtral: {\n    provider: 'ollama',\n    model: 'mixtral',\n    costPerToken: 0.000003,\n    avgLatencyMs: 1800,\n    maxTokens: 32000,\n    capabilities: ['text-generation', 'code', 'reasoning'],\n  },\n  'gpt-4': {\n    provider: 'openai',\n    model: 'gpt-4-turbo',\n    costPerToken: 0.00001,\n    avgLatencyMs: 2500,\n    maxTokens: 128000,\n    capabilities: ['text-generation', 'code', 'reasoning', 'vision'],\n  },\n  'claude-3-opus': {\n    provider: 'anthropic',\n    model: 'claude-3-opus-20240229',\n    costPerToken: 0.000015,\n    avgLatencyMs: 3000,\n    maxTokens: 200000,\n    capabilities: ['text-generation', 'analysis', 'summarization'],\n  },\n};\n\ntype ModelKey = keyof typeof MODEL_CONFIGS;\n\ninterface ModelRequest {\n  prompt: string;\n  context?: Record<string, any>;\n  requirements?: {\n    maxCostPerToken?: number;\n    maxLatencyMs?: number;\n    minCapabilities?: string[];\n    minContextLength?: number;\n  };\n}\n\nclass ModelRouterAgent extends Agent {\n  private models: Record<string, any> = MODEL_CONFIGS;\n\n  constructor() {\n    super({\n      name: 'model-router',\n      version: '1.0.0',\n      description: 'Intelligent model routing for OSSA agents',\n      capabilities: [\n        'model-routing',\n        'cost-optimization',\n        'performance-monitoring',\n      ],\n    });\n  }\n\n  /**\n   * Select the best model based on requirements\n   */\n  private selectModel(\n    requirements: ModelRequest['requirements'] = {}\n  ): ModelKey {\n    const {\n      maxCostPerToken = Infinity,\n      maxLatencyMs = 5000,\n      minCapabilities = [],\n      minContextLength = 0,\n    } = requirements;\n\n    // Filter models by requirements\n    const suitableModels = Object.entries(this.models)\n      .filter(([_, config]) => {\n        // Check cost constraints\n        if (config.costPerToken > maxCostPerToken) return false;\n\n        // Check latency constraints\n        if (config.avgLatencyMs > maxLatencyMs) return false;\n\n        // Check context length\n        if (config.maxTokens < minContextLength) return false;\n\n        // Check required capabilities\n        return minCapabilities.every((cap) =>\n          config.capabilities.includes(cap)\n        );\n      })\n      .sort((a, b) => {\n        // Prioritize lower cost, then lower latency\n        const costDiff = a[1].costPerToken - b[1].costPerToken;\n        if (costDiff !== 0) return costDiff;\n        return a[1].avgLatencyMs - b[1].avgLatencyMs;\n      });\n\n    if (suitableModels.length === 0) {\n      throw new Error('No suitable models found for the given requirements');\n    }\n\n    return suitableModels[0][0] as ModelKey;\n  }\n\n  /**\n   * Process a request using the best available model\n   */\n  async process(\n    request: ModelRequest,\n    context: AgentContext\n  ): Promise<AgentResponse> {\n    try {\n      // Select the best model\n      const modelKey = this.selectModel(request.requirements);\n      const modelConfig = this.models[modelKey];\n\n      this.logger.info(`Selected model: ${modelKey}`, { model: modelKey });\n\n      // Process the request with the selected model\n      const result = await this.callModel(modelKey, request.prompt, context);\n\n      return {\n        success: true,\n        data: {\n          response: result,\n          model: modelKey,\n          metadata: {\n            cost: request.prompt.length * modelConfig.costPerToken,\n            latency: modelConfig.avgLatencyMs,\n            provider: modelConfig.provider,\n          },\n        },\n      };\n    } catch (error) {\n      this.logger.error('Model routing failed', { error });\n      return {\n        success: false,\n        error: {\n          code: 'MODEL_ROUTING_ERROR',\n          message: error.message,\n          details: error.stack,\n        },\n      };\n    }\n  }\n\n  /**\n   * Call the actual model (implementation would vary by provider)\n   */\n  private async callModel(\n    modelKey: string,\n    prompt: string,\n    context: AgentContext\n  ): Promise<string> {\n    const model = this.models[modelKey];\n\n    // In a real implementation, this would call the actual model APIs\n    // This is a simplified example\n    switch (model.provider) {\n      case 'ollama':\n        return this.callOllama(model.model, prompt);\n      case 'openai':\n        return this.callOpenAI(model.model, prompt);\n      case 'anthropic':\n        return this.callAnthropic(model.model, prompt);\n      default:\n        throw new Error(`Unsupported provider: ${model.provider}`);\n    }\n  }\n\n  // Stub implementations for model providers\n  private async callOllama(model: string, prompt: string): Promise<string> {\n    // Implementation would call Ollama's API\n    return `Response from Ollama (${model}) for prompt: ${prompt.substring(0, 50)}...`;\n  }\n\n  private async callOpenAI(model: string, prompt: string): Promise<string> {\n    // Implementation would call OpenAI's API\n    return `Response from OpenAI (${model}) for prompt: ${prompt.substring(0, 50)}...`;\n  }\n\n  private async callAnthropic(model: string, prompt: string): Promise<string> {\n    // Implementation would call Anthropic's API\n    return `Response from Anthropic (${model}) for prompt: ${prompt.substring(0, 50)}...`;\n  }\n}\n\n// Example usage\nasync function main() {\n  const router = new ModelRouterAgent();\n\n  // Example 1: Fast, low-cost response\n  const response1 = await router.process(\n    {\n      prompt: 'Explain quantum computing in simple terms',\n      requirements: {\n        maxCostPerToken: 0.000005,\n        maxLatencyMs: 2000,\n        minCapabilities: ['text-generation'],\n      },\n    },\n    {}\n  );\n\n  console.log('Example 1 - Fast, low-cost response:');\n  console.log(response1);\n\n  // Example 2: Complex reasoning with higher budget\n  const response2 = await router.process(\n    {\n      prompt:\n        'Write a detailed analysis of the latest AI safety research papers',\n      requirements: {\n        maxCostPerToken: 0.00002,\n        maxLatencyMs: 10000,\n        minCapabilities: ['analysis', 'reasoning'],\n        minContextLength: 16000,\n      },\n    },\n    {}\n  );\n\n  console.log('\\nExample 2 - Complex analysis:');\n  console.log(response2);\n}\n\n// Run the example if this file is executed directly\nif (require.main === module) {\n  main().catch(console.error);\n}\n\nexport { ModelRouterAgent };\n",
    "category": "Advanced Patterns"
  },
  {
    "name": "smart-model-routing.ts",
    "path": "advanced/patterns/smart-model-routing.ts",
    "content": "/**\n * OSSA Smart Model Router\n * ========================\n *\n * This example demonstrates an advanced model routing pattern that dynamically selects\n * the most appropriate language model based on task requirements, cost constraints,\n * and performance needs.\n */\n\nimport { Agent, AgentContext, AgentResponse } from '@ossa/core';\nimport axios from 'axios';\nimport dotenv from 'dotenv';\n\ndotenv.config();\n\n// Types and Interfaces\ninterface ModelConfig {\n  provider: 'ollama' | 'openai' | 'anthropic';\n  model: string;\n  costPerToken: number;\n  avgLatencyMs: number;\n  maxTokens: number;\n  capabilities: string[];\n  baseUrl?: string;\n  apiKeyEnv?: string;\n}\n\ninterface ModelRequest {\n  prompt: string;\n  context?: Record<string, any>;\n  requirements?: {\n    maxCostPerToken?: number;\n    maxLatencyMs?: number;\n    minCapabilities?: string[];\n    minContextLength?: number;\n  };\n}\n\ntype ModelKey = keyof typeof MODEL_CONFIGS;\n\n// Configuration\nconst MODEL_CONFIGS: Record<string, ModelConfig> = {\n  llama3: {\n    provider: 'ollama',\n    model: 'llama3',\n    costPerToken: 0.000002,\n    avgLatencyMs: 1200,\n    maxTokens: 8192,\n    capabilities: ['text-generation', 'summarization', 'qna'],\n    baseUrl: process.env.OLLAMA_BASE_URL || 'http://localhost:11434',\n  },\n  mixtral: {\n    provider: 'ollama',\n    model: 'mixtral',\n    costPerToken: 0.000003,\n    avgLatencyMs: 1800,\n    maxTokens: 32000,\n    capabilities: ['text-generation', 'code', 'reasoning'],\n    baseUrl: process.env.OLLAMA_BASE_URL || 'http://localhost:11434',\n  },\n  'gpt-4': {\n    provider: 'openai',\n    model: 'gpt-4-turbo',\n    costPerToken: 0.00001,\n    avgLatencyMs: 2500,\n    maxTokens: 128000,\n    capabilities: ['text-generation', 'code', 'reasoning', 'vision'],\n    apiKeyEnv: 'OPENAI_API_KEY',\n  },\n  'claude-3-opus': {\n    provider: 'anthropic',\n    model: 'claude-3-opus-20240229',\n    costPerToken: 0.000015,\n    avgLatencyMs: 3000,\n    maxTokens: 200000,\n    capabilities: ['text-generation', 'analysis', 'summarization'],\n    apiKeyEnv: 'ANTHROPIC_API_KEY',\n  },\n};\n\nclass SmartModelRouter extends Agent {\n  private models: Record<string, ModelConfig> = MODEL_CONFIGS;\n  private http = axios.create();\n\n  constructor() {\n    super({\n      name: 'smart-model-router',\n      version: '1.0.0',\n      description: 'Intelligent model routing for OSSA agents',\n      capabilities: [\n        'model-routing',\n        'cost-optimization',\n        'performance-monitoring',\n        'fallback-handling',\n      ],\n    });\n  }\n\n  /**\n   * Process a request using the best available model\n   */\n  async process(\n    request: ModelRequest,\n    context: AgentContext = {}\n  ): Promise<AgentResponse> {\n    try {\n      // Select the best model based on requirements\n      const modelKey = this.selectModel(request.requirements);\n      const modelConfig = this.models[modelKey];\n\n      this.logger.info(`Routing to ${modelKey} (${modelConfig.provider})`);\n\n      // Process the request using the selected model\n      const startTime = Date.now();\n      const response = await this.routeToModel(modelKey, request, context);\n      const latency = Date.now() - startTime;\n\n      return {\n        success: true,\n        data: {\n          model: modelKey,\n          response,\n          metadata: {\n            provider: modelConfig.provider,\n            latency,\n            cost: this.calculateCost(\n              response.usage?.total_tokens || 0,\n              modelConfig\n            ),\n            tokens: response.usage?.total_tokens || 0,\n          },\n        },\n      };\n    } catch (error) {\n      this.logger.error('Error processing request:', error);\n      return {\n        success: false,\n        error: error instanceof Error ? error.message : 'Unknown error',\n      };\n    }\n  }\n\n  /**\n   * Select the best model based on requirements\n   */\n  private selectModel(\n    requirements: ModelRequest['requirements'] = {}\n  ): ModelKey {\n    const {\n      maxCostPerToken = Infinity,\n      maxLatencyMs = 5000,\n      minCapabilities = [],\n      minContextLength = 0,\n    } = requirements;\n\n    // Filter models by requirements\n    const suitableModels = Object.entries(this.models)\n      .filter(([_, config]) => {\n        // Check cost constraints\n        if (config.costPerToken > maxCostPerToken) return false;\n\n        // Check latency constraints\n        if (config.avgLatencyMs > maxLatencyMs) return false;\n\n        // Check context length\n        if (config.maxTokens < minContextLength) return false;\n\n        // Check API key availability for cloud providers\n        if (config.apiKeyEnv && !process.env[config.apiKeyEnv]) {\n          this.logger.warn(`Skipping ${config.model} - missing API key`);\n          return false;\n        }\n\n        // Check required capabilities\n        return minCapabilities.every((cap) =>\n          config.capabilities.includes(cap)\n        );\n      })\n      .sort((a, b) => {\n        // Prioritize lower cost, then lower latency\n        const costDiff = a[1].costPerToken - b[1].costPerToken;\n        if (costDiff !== 0) return costDiff;\n        return a[1].avgLatencyMs - b[1].avgLatencyMs;\n      });\n\n    if (suitableModels.length === 0) {\n      throw new Error('No suitable models found for the given requirements');\n    }\n\n    return suitableModels[0][0] as ModelKey;\n  }\n\n  /**\n   * Route the request to the appropriate model provider\n   */\n  private async routeToModel(\n    modelKey: string,\n    request: ModelRequest,\n    context: AgentContext = {}\n  ): Promise<any> {\n    const model = this.models[modelKey];\n\n    try {\n      switch (model.provider) {\n        case 'ollama':\n          return await this.callOllama(model, request);\n        case 'openai':\n          return await this.callOpenAI(model, request);\n        case 'anthropic':\n          return await this.callAnthropic(model, request);\n        default:\n          throw new Error(`Unsupported provider: ${model.provider}`);\n      }\n    } catch (error) {\n      this.logger.error(`Error calling ${model.provider}:`, error);\n      throw error;\n    }\n  }\n\n  /**\n   * Calculate cost based on token usage\n   */\n  private calculateCost(tokenCount: number, modelConfig: ModelConfig): number {\n    return (tokenCount * modelConfig.costPerToken) / 1000; // Convert to cost per 1k tokens\n  }\n\n  // Provider-specific implementations will be added in the next step\n  private async callOllama(\n    model: ModelConfig,\n    request: ModelRequest\n  ): Promise<any> {\n    throw new Error('Not implemented');\n  }\n\n  private async callOpenAI(\n    model: ModelConfig,\n    request: ModelRequest\n  ): Promise<any> {\n    throw new Error('Not implemented');\n  }\n\n  private async callAnthropic(\n    model: ModelConfig,\n    request: ModelRequest\n  ): Promise<any> {\n    throw new Error('Not implemented');\n  }\n}\n",
    "category": "Advanced Patterns"
  },
  {
    "name": "reasoning-agent.yaml",
    "path": "advanced/reasoning-agent.yaml",
    "content": "# OSSA v0.2.9 - Reasoning Agent Example\n# Demonstrates: reasoning strategies, prompt templates, knowledge graph\napiVersion: ossa/v0.3.0\nkind: Agent\nmetadata:\n  name: research-analyst\n  version: 1.0.0\n  description: Research analyst with ReAct reasoning, knowledge graph, and versioned prompts\n  labels:\n    domain: research\n    capability: analysis\n    reasoning: react\n\nspec:\n  taxonomy:\n    domain: research\n    subdomain: analysis\n    capability: synthesis\n\n  role: |\n    You are a research analyst specializing in synthesizing complex information.\n    Use the ReAct reasoning pattern: Thought → Action → Observation.\n\n  llm:\n    provider: anthropic\n    model: claude-sonnet-4-20250514\n    parameters:\n      temperature: 0.3\n      max_tokens: 4096\n\n  # NEW: Reasoning configuration\n  reasoning:\n    strategy: react\n    max_steps: 15\n    trace_enabled: true\n    export_format: otel\n    self_reflection:\n      enabled: true\n      trigger: on_uncertainty\n      threshold: 0.6\n\n  # NEW: Prompt management with versioning\n  prompts:\n    system:\n      template: prompts/research-system-v2.md\n      version: \"2.1.0\"\n      variables:\n        domain: \"market-research\"\n        output_format: \"structured-report\"\n    few_shot_examples:\n      - input: \"Analyze the competitive landscape for AI agents\"\n        output: |\n          Thought: I need to identify key players, their offerings, and market positioning.\n          Action: search_knowledge_graph for entities with type=AIVendor\n          Observation: Found 12 major vendors including OpenAI, Anthropic, Google...\n      - input: \"What are the emerging trends in agent frameworks?\"\n        output: |\n          Thought: I should look for recent publications and framework releases.\n          Action: query_research_db for papers published > 2024-01\n          Observation: 47 relevant papers found, clustering around multi-agent and RAG...\n\n  # NEW: Knowledge graph integration\n  knowledge_graph:\n    enabled: true\n    provider: neo4j\n    connection:\n      endpoint: bolt://kg.internal:7687\n      database: research_graph\n      credentials_ref: KG_CREDENTIALS\n    schema:\n      entity_types:\n        - Company\n        - Product\n        - Technology\n        - Publication\n        - Person\n      relationship_types:\n        - COMPETES_WITH\n        - DEVELOPS\n        - PUBLISHES\n        - CITES\n        - EMPLOYS\n    sync:\n      mode: real_time\n      batch_size: 50\n      interval: 30s\n\n  tools:\n    - name: search_knowledge_graph\n      description: Query the knowledge graph for entity relationships\n      source:\n        type: mcp\n        uri: mcp://kg-service/query\n      input:\n        type: object\n        required: [query]\n        properties:\n          query:\n            type: string\n            description: Cypher query or natural language search\n\n    - name: query_research_db\n      description: Search research papers and publications\n      source:\n        type: mcp\n        uri: mcp://research-service/search\n\n  autonomy:\n    level: assisted\n    escalation:\n      enabled: true\n      triggers:\n        - low_confidence\n        - external_data_required\n\n  observability:\n    tracing:\n      enabled: true\n      provider: otel\n      sampling_rate: 1.0\n    metrics:\n      enabled: true\n      custom:\n        - name: reasoning_steps_total\n          type: counter\n          description: Total reasoning steps executed\n        - name: kg_queries_total\n          type: counter\n          description: Knowledge graph queries executed\n    logging:\n      level: debug\n\n  constraints:\n    max_tokens_per_turn: 8000\n    max_turns: 20\n    timeout_seconds: 300\n",
    "category": "Advanced Patterns"
  },
  {
    "name": "hybrid-model-strategy.yaml",
    "path": "advanced/workflows/hybrid-model-strategy.yaml",
    "content": "# Hybrid Model Strategy: Fast Local Planning + Premium Development\n# Demonstrates using fast Ollama models for planning agents and Claude for development\n\napiVersion: ossa/v0.3.0\nkind: Workflow\nmetadata:\n  name: hybrid-development-workflow\n  description: \"Cost-optimized workflow using fast local models for planning and premium models for development\"\n\nspec:\n  # Planning Phase - Use Fast Local Models\n  agents:\n    # Fast planning agent using local Ollama\n    - name: project-planner\n      type: orchestrator\n      ossa_type: orchestrator\n      modelConfig:\n        provider: \"ollama\"\n        model: \"mistral:7b\"  # Fast 1-2 second responses\n        parameters:\n          temperature: 0.3\n          max_tokens: 2000\n        ollamaConfig:\n          baseUrl: \"http://localhost:11434\"\n          keepAlive: \"5m\"\n      capabilities:\n        - project-planning\n        - task-breakdown\n        - resource-estimation\n      instruction: |\n        You are a fast project planning agent. Quickly break down development tasks:\n        - Analyze requirements\n        - Create task breakdown structure\n        - Estimate effort and dependencies\n        - Identify risks and blockers\n        Store plan in {project_plan}\n      output_key: project_plan\n\n    # Fast requirement analyzer using local model\n    - name: requirements-analyzer\n      type: critic\n      ossa_type: critic\n      modelConfig:\n        provider: \"ollama\"\n        model: \"qwen2.5:7b\"  # Good for analysis, fast\n        parameters:\n          temperature: 0.2\n          max_tokens: 1500\n        ollamaConfig:\n          baseUrl: \"http://localhost:11434\"\n      capabilities:\n        - requirements-analysis\n        - user-story-validation\n        - acceptance-criteria\n      instruction: |\n        Quickly analyze requirements for clarity and completeness:\n        - Validate user stories\n        - Identify missing requirements\n        - Check for conflicts or ambiguities\n        Store analysis in {requirements_analysis}\n      output_key: requirements_analysis\n\n  # Development Phase - Use Premium Models\n    # Premium development agent using Claude Code\n    - name: senior-developer\n      type: worker\n      ossa_type: worker\n      modelConfig:\n        provider: \"anthropic\"\n        model: \"claude-3-5-sonnet-20241022\"\n        parameters:\n          temperature: 0.1  # Low temperature for precise code\n          max_tokens: 8000\n        anthropicConfig:\n          apiKey: \"${ANTHROPIC_API_KEY}\"\n          defaultHeaders:\n            \"anthropic-beta\": \"computer-use-2024-10-22\"\n      capabilities:\n        - code-generation\n        - architecture-design\n        - best-practices\n        - testing\n        - documentation\n      instruction: |\n        You are an expert senior developer using best practices:\n        - Write clean, maintainable code\n        - Follow SOLID principles\n        - Include comprehensive tests\n        - Add proper documentation\n        - Consider security and performance\n        Use {project_plan} and {requirements_analysis} as context\n      tools:\n        - file-operations\n        - git-operations\n        - test-runner\n        - linter\n      output_key: development_result\n\n    # Code review agent using Claude\n    - name: code-reviewer\n      type: critic\n      ossa_type: critic\n      modelConfig:\n        provider: \"anthropic\"\n        model: \"claude-3-5-sonnet-20241022\"\n        parameters:\n          temperature: 0.05  # Very low for consistent reviews\n          max_tokens: 6000\n      capabilities:\n        - code-review\n        - security-analysis\n        - performance-review\n        - maintainability-check\n      instruction: |\n        Perform thorough code review focusing on:\n        - Code quality and best practices\n        - Security vulnerabilities\n        - Performance issues\n        - Maintainability concerns\n        - Test coverage and quality\n        Review {development_result} and provide detailed feedback\n      output_key: code_review\n\n  # Optimization Phase - Use Local Models for Simple Tasks\n    # Documentation generator using local model\n    - name: doc-generator\n      type: worker\n      ossa_type: worker\n      modelConfig:\n        provider: \"ollama\"\n        model: \"codellama:7b\"  # Good for documentation\n        parameters:\n          temperature: 0.4\n          max_tokens: 3000\n      capabilities:\n        - documentation-generation\n        - api-docs\n        - readme-creation\n      instruction: |\n        Generate comprehensive documentation based on {development_result}:\n        - API documentation\n        - Usage examples\n        - Installation instructions\n        - Architecture overview\n      output_key: documentation\n\n  # Cost Optimization Configuration\n  costOptimization:\n    strategy: \"hybrid\"\n    budgetLimits:\n      planning_phase: 0.01    # $0.01 - use free local models\n      development_phase: 1.00  # $1.00 - premium models for quality\n      optimization_phase: 0.05 # $0.05 - local models for docs\n\n    fallbackStrategy:\n      # If premium models unavailable, use these alternatives\n      fallbacks:\n        \"claude-3-5-sonnet\": \"gpt-4o\"\n        \"gpt-4o\": \"gemini-2.0-flash\"\n        \"gemini-2.0-flash\": \"ollama:qwen2.5:7b\"\n\n  # Performance Targets\n  performance:\n    planning_phase:\n      target_latency: \"5s\"      # Fast local responses\n      cost_per_task: \"$0.00\"    # Free local inference\n    development_phase:\n      target_latency: \"30s\"     # Quality over speed\n      cost_per_task: \"$0.50\"    # Premium model investment\n    optimization_phase:\n      target_latency: \"10s\"     # Fast local processing\n      cost_per_task: \"$0.02\"    # Minimal cost\n\n  # Execution Flow\n  execution:\n    phases:\n      - name: planning\n        agents: [project-planner, requirements-analyzer]\n        execution_mode: parallel\n        budget_limit: 0.01\n\n      - name: development\n        agents: [senior-developer]\n        execution_mode: sequential\n        dependencies: [planning]\n        budget_limit: 1.00\n\n      - name: review\n        agents: [code-reviewer]\n        execution_mode: sequential\n        dependencies: [development]\n        budget_limit: 0.30\n\n      - name: documentation\n        agents: [doc-generator]\n        execution_mode: sequential\n        dependencies: [development]\n        budget_limit: 0.05\n\n    # Quality gates\n    quality_gates:\n      - phase: development\n        condition: \"code_review.score > 8.0\"\n        action: \"proceed\"\n      - phase: development\n        condition: \"code_review.security_issues > 0\"\n        action: \"retry_with_feedback\"\n\n---\n# Example Environment Configuration\n# .env file should contain:\n\n# Fast local models for planning\nOLLAMA_BASE_URL=http://localhost:11434\nPLANNING_MODEL=mistral:7b\n",
    "category": "Advanced Patterns"
  },
  {
    "name": "critic-agent.yaml",
    "path": "agent-manifests/critics/critic-agent.yaml",
    "content": "apiVersion: ossa/v0.3.0\nkind: Agent\nmetadata:\n  name: code-quality-critic\n  version: v1.0.0\n  description: 'Quality assurance agent for code review, testing, and continuous improvement'\n  author: 'quality-engineering-team'\n  labels:\n    environment: production\n    classification: internal\n    role: critic\n    complexity: standard\nspec:\n  type: critic\n  subtype: code-reviewer\n  capabilities:\n    domains:\n      - code-review\n      - quality-assessment\n      - testing-validation\n      - security-analysis\n      - performance-analysis\n      - documentation-review\n    operations:\n      - analyze-code\n      - review-changes\n      - assess-quality\n      - detect-issues\n      - suggest-improvements\n      - validate-tests\n    patterns:\n      - static-analysis\n      - dynamic-analysis\n      - peer-review\n      - automated-testing\n      - quality-gates\n      - continuous-feedback\n  protocols:\n    supported:\n      - name: rest\n        version: '1.1'\n        endpoint: 'https://critic.platform.com/api/v1'\n        authentication:\n          type: bearer-token\n          scopes: ['critic.review', 'code.analyze', 'quality.assess']\n        tls: true\n      - name: webhook\n        version: '1.0'\n        endpoint: 'https://critic.platform.com/webhooks/review'\n        authentication:\n          type: hmac-sha256\n      - name: grpc\n        version: '1.0'\n        endpoint: 'grpc://critic.platform.com:9443/CodeCritic'\n        authentication:\n          type: mutual-tls\n  analysis:\n    codeQuality:\n      complexity: true\n      maintainability: true\n      reliability: true\n      security: true\n      performance: true\n      testability: true\n    staticAnalysis:\n      syntaxChecking: true\n      typeChecking: true\n      styleChecking: true\n      securityScanning: true\n      dependencyAnalysis: true\n    supportedLanguages:\n      - javascript\n      - typescript\n      - python\n      - java\n      - go\n      - rust\n      - csharp\n    qualityMetrics:\n      cyclomaticComplexity: true\n      codeChurn: true\n      testCoverage: true\n      duplication: true\n      maintainabilityIndex: true\n  review:\n    automatedReview: true\n    humanReview: true\n    reviewCriteria:\n      functionality: true\n      readability: true\n      maintainability: true\n      performance: true\n      security: true\n      testCoverage: true\n    scoring:\n      scale: '0-100'\n      passThreshold: 70\n      categories:\n        - functionality\n        - quality\n        - security\n        - performance\n        - maintainability\n  feedback:\n    suggestions: true\n    improvements: true\n    bestPractices: true\n    patterns: true\n    antiPatterns: true\n    learningResources: true\n    priority:\n      - critical\n      - high\n      - medium\n      - low\n      - info\n  integration:\n    versionControl:\n      - git\n      - mercurial\n      - subversion\n    cicdPlatforms:\n      - gitlab\n      - github\n      - jenkins\n      - azure-devops\n    issueTracking:\n      - jira\n      - github-issues\n      - gitlab-issues\n  performance:\n    throughput:\n      reviewsPerHour: 50\n      linesOfCodePerMinute: 1000\n    latency:\n      analysisTime: 30000\n      reviewTime: 120000\n      feedbackTime: 5000\n      p95: 180000\n      p99: 300000\n  monitoring:\n    reviewMetrics: true\n    qualityTrends: true\n    performanceMetrics: true\n    errorTracking: true\n    alerting:\n      reviewFailureThreshold: 5\n      qualityDegradationThreshold: 10\n      performanceThreshold: 300000\n",
    "category": "Agent Types"
  },
  {
    "name": "governor-agent.yaml",
    "path": "agent-manifests/governors/governor-agent.yaml",
    "content": "apiVersion: ossa/v0.3.0\nkind: Agent\nmetadata:\n  name: policy-compliance-governor\n  version: v1.1.0\n  description: 'Governance agent enforcing policies, compliance, and security standards across systems'\n  author: 'governance-team'\n  labels:\n    environment: production\n    classification: internal\n    role: governor\n    complexity: enterprise\nspec:\n  type: governor\n  subtype: policy-enforcer\n  capabilities:\n    domains:\n      - policy-enforcement\n      - compliance-checking\n      - security-governance\n      - resource-management\n      - audit-tracking\n      - risk-assessment\n    operations:\n      - enforce-policies\n      - validate-compliance\n      - assess-risks\n      - audit-activities\n      - manage-permissions\n      - generate-reports\n    patterns:\n      - policy-as-code\n      - audit-trail\n      - role-based-access\n      - compliance-framework\n      - risk-matrix\n      - governance-workflow\n  protocols:\n    supported:\n      - name: rest\n        version: '1.1'\n        endpoint: 'https://governor.platform.com/api/v1'\n        authentication:\n          type: oauth2\n          scopes: ['governor.enforce', 'policies.validate', 'compliance.audit']\n        tls: true\n      - name: grpc\n        version: '1.0'\n        endpoint: 'grpc://governor.platform.com:9443/PolicyGovernor'\n        authentication:\n          type: mutual-tls\n      - name: webhook\n        version: '1.0'\n        endpoint: 'https://governor.platform.com/webhooks'\n        authentication:\n          type: hmac-sha256\n  governance:\n    policyEngine: 'open-policy-agent'\n    complianceFrameworks:\n      - soc2\n      - pci-dss\n      - gdpr\n      - hipaa\n      - iso27001\n    enforcementModes:\n      - advisory\n      - blocking\n      - logging\n    auditRetention: '7y'\n    riskAssessment:\n      frequency: 'weekly'\n      severity: ['low', 'medium', 'high', 'critical']\n      impact: ['minimal', 'moderate', 'significant', 'severe']\n  policies:\n    categories:\n      - security\n      - privacy\n      - operational\n      - financial\n      - regulatory\n    evaluation:\n      realtime: true\n      batch: true\n      scheduled: true\n    versioning:\n      enabled: true\n      approvalRequired: true\n      rollbackCapable: true\n  compliance:\n    continuousMonitoring: true\n    reportingFrequency: 'monthly'\n    evidenceCollection: true\n    controlMapping: true\n    attestation:\n      required: true\n      frequency: 'quarterly'\n      approvers: ['compliance-officer', 'security-lead']\n  security:\n    accessControl:\n      rbac: true\n      abac: true\n      mfa: required\n    encryption:\n      atRest: true\n      inTransit: true\n      keyRotation: '90d'\n    logging:\n      auditLogs: true\n      securityEvents: true\n      dataAccess: true\n  performance:\n    throughput:\n      policiesPerSecond: 100\n      validationsPerSecond: 500\n    latency:\n      policyEvaluation: 50\n      complianceCheck: 100\n      p95: 200\n      p99: 500\n  monitoring:\n    policyViolations: true\n    complianceStatus: true\n    riskMetrics: true\n    auditTrail: true\n    alerting:\n      policyViolationThreshold: 1\n      complianceFailureThreshold: 1\n      riskEscalationThreshold: 'high'\n",
    "category": "Agent Types"
  },
  {
    "name": "integrator-agent.yaml",
    "path": "agent-manifests/integrators/integrator-agent.yaml",
    "content": "apiVersion: ossa/v0.3.0\nkind: Agent\nmetadata:\n  name: multi-system-integrator\n  version: v1.4.0\n  description: 'Enterprise integration agent for connecting heterogeneous systems and APIs'\n  author: 'integration-team'\n  labels:\n    environment: production\n    classification: internal\n    role: integrator\n    complexity: enterprise\nspec:\n  type: integrator\n  subtype: api-connector\n  capabilities:\n    domains:\n      - api-integration\n      - data-synchronization\n      - protocol-translation\n      - message-routing\n      - schema-mapping\n      - event-streaming\n    operations:\n      - connect-systems\n      - transform-protocols\n      - map-schemas\n      - route-messages\n      - synchronize-data\n      - handle-failures\n    patterns:\n      - adapter-pattern\n      - message-broker\n      - event-sourcing\n      - saga-pattern\n      - circuit-breaker\n      - retry-with-backoff\n  protocols:\n    supported:\n      - name: rest\n        version: '1.1'\n        endpoint: 'https://integrator.platform.com/api/v1'\n        authentication:\n          type: oauth2\n          scopes: ['integrator.execute', 'systems.connect', 'data.transform']\n        tls: true\n      - name: graphql\n        version: '1.0'\n        endpoint: 'https://integrator.platform.com/graphql'\n        authentication:\n          type: bearer-token\n      - name: websocket\n        version: '1.0'\n        endpoint: 'wss://events.platform.com/integrator'\n        authentication:\n          type: jwt\n      - name: grpc\n        version: '1.0'\n        endpoint: 'grpc://integrator.platform.com:9443/SystemIntegrator'\n        authentication:\n          type: mutual-tls\n  integration:\n    maxConcurrentConnections: 50\n    maxSystemsPerIntegration: 20\n    connectionTimeout: 30000\n    syncInterval: 60000\n    retryPolicy:\n      maxAttempts: 5\n      backoffStrategy: exponential\n      baseDelay: 2000\n    errorHandling:\n      strategy: circuit-breaker\n      failureThreshold: 10\n      recoveryTimeout: 300000\n  transformation:\n    schemaValidation: true\n    dataMapping: true\n    protocolConversion: true\n    formatTranslation: true\n    supportedFormats:\n      - json\n      - xml\n      - avro\n      - protobuf\n      - csv\n  performance:\n    throughput:\n      messagesPerSecond: 500\n      maxBatchSize: 50\n    latency:\n      integrationOverhead: 25\n      transformationTime: 15\n      p95: 100\n      p99: 250\n  monitoring:\n    connectionHealth: true\n    transformationMetrics: true\n    errorTracking: true\n    performanceMetrics: true\n    alerting:\n      connectionFailureThreshold: 3\n      transformationErrorThreshold: 10\n      latencyThreshold: 500\n",
    "category": "Agent Types"
  },
  {
    "name": "judge-agent.yaml",
    "path": "agent-manifests/judges/judge-agent.yaml",
    "content": "apiVersion: ossa/v0.3.0\nkind: Agent\nmetadata:\n  name: decision-arbitration-judge\n  version: v1.0.0\n  description: 'Ultimate decision-making agent for conflict resolution and final arbitration'\n  author: 'architecture-council'\n  labels:\n    environment: production\n    classification: internal\n    role: judge\n    complexity: enterprise\nspec:\n  type: judge\n  subtype: decision-arbitrator\n  capabilities:\n    domains:\n      - decision-making\n      - conflict-resolution\n      - arbitration\n      - consensus-building\n      - priority-ranking\n      - resource-allocation\n    operations:\n      - arbitrate-conflicts\n      - make-decisions\n      - resolve-disputes\n      - prioritize-requests\n      - allocate-resources\n      - build-consensus\n    patterns:\n      - decision-tree\n      - weighted-scoring\n      - consensus-algorithm\n      - conflict-resolution\n      - priority-queue\n      - resource-optimization\n  protocols:\n    supported:\n      - name: rest\n        version: '1.1'\n        endpoint: 'https://judge.platform.com/api/v1'\n        authentication:\n          type: oauth2\n          scopes: ['judge.arbitrate', 'decisions.make', 'conflicts.resolve']\n        tls: true\n      - name: grpc\n        version: '1.0'\n        endpoint: 'grpc://judge.platform.com:9443/DecisionJudge'\n        authentication:\n          type: mutual-tls\n      - name: event-stream\n        version: '1.0'\n        endpoint: 'wss://events.platform.com/judge'\n        authentication:\n          type: jwt\n  arbitration:\n    decisionMaking:\n      algorithm: 'weighted-consensus'\n      votingSystem: 'ranked-choice'\n      quorumRequired: true\n      minimumParticipants: 3\n      timeoutPeriod: 300000\n    conflictResolution:\n      escalationLevels:\n        - automated\n        - peer-review\n        - expert-panel\n        - executive-decision\n      resolutionStrategies:\n        - compromise\n        - priority-based\n        - resource-optimal\n        - consensus-driven\n    criteria:\n      businessValue: 30\n      technicalFeasibility: 25\n      riskAssessment: 20\n      resourceRequirement: 15\n      timeToMarket: 10\n  decision:\n    factors:\n      - impact\n      - urgency\n      - complexity\n      - risk\n      - cost\n      - benefit\n      - feasibility\n      - alignment\n    scoringModel:\n      scale: '1-10'\n      weights:\n        strategic: 40\n        operational: 30\n        technical: 20\n        financial: 10\n    evidenceRequired:\n      dataPoints: true\n      stakeholderInput: true\n      expertOpinion: true\n      historicalContext: true\n      riskAssessment: true\n  governance:\n    authority:\n      scope: 'platform-wide'\n      limitations:\n        ['legal-compliance', 'budget-constraints', 'policy-boundaries']\n      escalationPath: 'executive-committee'\n    accountability:\n      decisionAudit: true\n      outcomeTracking: true\n      performanceReview: true\n      learningFeedback: true\n    transparency:\n      decisionLog: true\n      rationale: true\n      stakeholderNotification: true\n      appealProcess: true\n  consensus:\n    buildingMethods:\n      - facilitated-discussion\n      - structured-voting\n      - compromise-negotiation\n      - expert-mediation\n    participantRoles:\n      - stakeholder\n      - expert\n      - facilitator\n      - observer\n    agreements:\n      unanimous: preferred\n      majority: acceptable\n      executive: fallback\n  performance:\n    throughput:\n      decisionsPerDay: 20\n      conflictsPerWeek: 10\n    latency:\n      simpleDecision: 3600000\n      complexArbitration: 86400000\n      conflictResolution: 259200000\n      p95: 172800000\n      p99: 604800000\n  monitoring:\n    decisionQuality: true\n    outcomeTracking: true\n    stakeholderSatisfaction: true\n    processEfficiency: true\n    alerting:\n      escalationThreshold: 3\n      timeoutThreshold: 604800000\n      satisfactionThreshold: 70\n",
    "category": "Agent Types"
  },
  {
    "name": "monitor-agent.yaml",
    "path": "agent-manifests/monitors/monitor-agent.yaml",
    "content": "apiVersion: ossa/v0.3.0\nkind: Agent\nmetadata:\n  name: system-performance-monitor\n  version: v1.3.0\n  description: \"Real-time monitoring agent for system health, performance, and resource utilization\"\n  author: \"monitoring-team\"\n  labels:\n    environment: production\n    classification: internal\n    role: monitor\n    complexity: standard\nspec:\n  type: monitor\n  subtype: performance-monitor\n  capabilities:\n    domains:\n      - system-monitoring\n      - performance-tracking\n      - resource-monitoring\n      - health-checking\n      - alerting\n      - metrics-collection\n    operations:\n      - collect-metrics\n      - check-health\n      - detect-anomalies\n      - generate-alerts\n      - track-performance\n      - analyze-trends\n    patterns:\n      - observer-pattern\n      - event-driven\n      - time-series\n      - threshold-based\n      - anomaly-detection\n      - aggregation\n  protocols:\n    supported:\n      - name: rest\n        version: \"1.1\"\n        endpoint: \"https://monitor.platform.com/api/v1\"\n        authentication:\n          type: bearer-token\n          scopes: [\"monitor.read\", \"metrics.collect\", \"alerts.send\"]\n        tls: true\n      - name: prometheus\n        version: \"1.0\"\n        endpoint: \"http://monitor.platform.com:9090/metrics\"\n        authentication:\n          type: none\n      - name: websocket\n        version: \"1.0\"\n        endpoint: \"wss://events.platform.com/monitor\"\n        authentication:\n          type: jwt\n      - name: snmp\n        version: \"2c\"\n        endpoint: \"udp://devices.platform.com:161\"\n        authentication:\n          type: community-string\n  monitoring:\n    collectionInterval: 30000\n    retentionPeriod: \"30d\"\n    maxMetricsPerSecond: 10000\n    aggregationWindow: 300000\n    alertingEnabled: true\n    thresholds:\n      cpu:\n        warning: 70\n        critical: 90\n      memory:\n        warning: 80\n        critical: 95\n      disk:\n        warning: 85\n        critical: 95\n      network:\n        warning: 80\n        critical: 95\n  detection:\n    anomalyDetection: true\n    baselineWindow: \"7d\"\n    sensitivityLevel: medium\n    machinelearning: true\n    algorithms:\n      - statistical-analysis\n      - trend-detection\n      - seasonal-decomposition\n      - isolation-forest\n  alerting:\n    channels:\n      - email\n      - slack\n      - webhook\n      - sms\n    escalationPolicy:\n      - level: warning\n        delay: 300\n      - level: critical\n        delay: 60\n    suppressionRules:\n      - duplicateWindow: 3600\n      - maintenanceMode: true\n  performance:\n    throughput:\n      metricsPerSecond: 1000\n      maxConcurrentChecks: 100\n    latency:\n      collectionLatency: 10\n      alertingLatency: 5\n      p95: 50\n      p99: 100\n  monitoring:\n    selfMonitoring: true\n    healthChecks: true\n    performanceMetrics: true\n    errorTracking: true\n    alerting:\n      collectionFailureThreshold: 5\n      alertingFailureThreshold: 3\n      latencyThreshold: 1000",
    "category": "Agent Types"
  },
  {
    "name": "orchestrator-agent.yaml",
    "path": "agent-manifests/orchestrators/orchestrator-agent.yaml",
    "content": "# ============================================================================\n# OSSA Multi-Workflow Orchestrator Agent Manifest\n# ============================================================================\n# Purpose: Enterprise-grade orchestrator for managing complex multi-agent\n#          workflows across distributed systems\n#\n# Key Concepts:\n# - Orchestration: Central coordinator managing workflow execution and state\n# - Agent Coordination: Discovering, routing, and managing worker agents\n# - Dependency Management: Handling execution order and data flow between agents\n# - Failure Recovery: Implementing compensation, retry, and fallback strategies\n#\n# Related Examples:\n# - examples/openapi-extensions/orchestrator-agent-api.openapi.yml (API definition)\n# - examples/production/agent.yml (Worker agent pattern)\n# - examples/kagent/k8s-troubleshooter.ossa.yaml (Complex orchestration)\n#\n# OSSA Version: 0.1.9 (Orchestrator profile)\n# Conformance: Enterprise-level orchestration with high availability\n# ============================================================================\n\n# OSSA manifest version - defines the schema and features available\napiVersion: ossa/v0.3.0\n\n# Kind declares this as an Agent manifest (vs. Bridge, Tool, etc.)\nkind: Agent\n\n# ============================================================================\n# METADATA: Identity and classification for agent discovery\n# ============================================================================\nmetadata:\n  # Unique identifier within the agent ecosystem\n  name: multi-workflow-orchestrator\n\n  # Semantic version for compatibility tracking\n  version: v2.1.0\n\n  # Human-readable description for documentation and discovery\n  description: 'Enterprise orchestrator managing complex multi-agent workflows across distributed systems'\n\n  # Team or individual responsible for maintenance\n  author: 'platform-engineering-team'\n\n  # Labels enable filtering, routing, and policy enforcement\n  labels:\n    environment: production      # Deployment environment (dev/staging/production)\n    classification: internal     # Data classification level (public/internal/confidential/secret)\n    role: orchestrator          # Agent role in the ecosystem (orchestrator/worker/specialist/critic)\n    complexity: enterprise      # Complexity level (simple/moderate/enterprise)\n\n# ============================================================================\n# SPEC: Core agent configuration and capabilities\n# ============================================================================\nspec:\n  # Type defines the agent's primary role in multi-agent systems\n  # - orchestrator: Coordinates other agents and manages workflows\n  # - worker: Performs specific tasks delegated by orchestrators\n  # - specialist: Domain-specific expertise (e.g., code review, security)\n  # - critic: Evaluates and validates outputs from other agents\n  type: orchestrator\n\n  # Subtype provides fine-grained specialization\n  # - workflow-coordinator: Manages sequential and parallel workflows\n  # - agent-router: Routes requests to appropriate agents\n  # - resource-manager: Allocates compute/memory/token budgets\n  subtype: workflow-coordinator\n\n  # ============================================================================\n  # CAPABILITIES: What this orchestrator can do\n  # ============================================================================\n  capabilities:\n    # Domains: High-level problem spaces this agent operates in\n    domains:\n      - workflow-orchestration    # Design and execute multi-step workflows\n      - agent-coordination        # Discover, route, and manage agents\n      - resource-allocation       # Distribute compute/memory/tokens across agents\n      - dependency-management     # Handle execution order and data dependencies\n      - failure-recovery         # Implement retry, compensation, and fallback logic\n\n    # Operations: Specific actions this agent can perform\n    operations:\n      - orchestrate-workflows    # Create and execute workflow definitions\n      - coordinate-agents        # Manage agent lifecycle and communication\n      - manage-dependencies      # Resolve execution order based on data flow\n      - handle-failures         # Execute compensation transactions on failure\n      - scale-resources         # Dynamically allocate resources based on load\n      - monitor-execution       # Track progress, metrics, and health\n\n    # Patterns: Architectural patterns this orchestrator implements\n    patterns:\n      - saga-pattern           # Distributed transactions with compensation logic\n      - event-sourcing         # Track workflow state as event stream\n      - choreography           # Decentralized agent coordination via events\n      - orchestration          # Centralized workflow control and state\n      - circuit-breaker        # Prevent cascading failures via fault isolation\n\n  # ============================================================================\n  # PROTOCOLS: Communication methods for agent interaction\n  # ============================================================================\n  protocols:\n    supported:\n      # REST API: Synchronous request-response for workflow submission\n      - name: rest\n        version: '1.1'\n        endpoint: 'https://orchestrator.platform.com/api/v2'\n        authentication:\n          # OAuth2 for delegated authorization with scoped permissions\n          type: oauth2\n          scopes:\n            # orchestrator.execute: Submit and control workflows\n            # agents.coordinate: Discover and communicate with agents\n            # resources.manage: Allocate compute/memory/token budgets\n            ['orchestrator.execute', 'agents.coordinate', 'resources.manage']\n        # TLS 1.3 for encrypted transport\n        tls: true\n\n      # gRPC: High-performance RPC for agent-to-agent communication\n      - name: grpc\n        version: '1.0'\n        endpoint: 'grpc://orchestrator.platform.com:9443/WorkflowOrchestrator'\n        authentication:\n          # Mutual TLS for bidirectional authentication and encryption\n          type: mutual-tls\n\n      # Event Stream: Asynchronous updates for workflow state changes\n      - name: event-stream\n        version: '1.0'\n        endpoint: 'wss://events.platform.com/orchestrator'\n        authentication:\n          # JWT tokens for stateless WebSocket authentication\n          type: jwt\n\n  # ============================================================================\n  # COORDINATION: Multi-agent workflow management configuration\n  # ============================================================================\n  coordination:\n    # Maximum concurrent workflows this orchestrator can manage\n    # - Higher values increase throughput but require more memory\n    # - Should align with available resources and agent pool size\n    maxConcurrentWorkflows: 1000\n\n    # Maximum agents that can participate in a single workflow\n    # - Limits complexity and prevents resource exhaustion\n    # - Should consider coordination overhead (O(n²) for full mesh)\n    maxAgentsPerWorkflow: 50\n\n    # Maximum time (ms) a workflow can run before forced termination\n    # - Prevents runaway workflows from consuming resources\n    # - 3600000ms = 1 hour (should include all retries and compensation)\n    workflowTimeout: 3600000\n\n    # Retry policy for failed workflow steps\n    retryPolicy:\n      # Maximum retry attempts before marking step as failed\n      maxAttempts: 3\n\n      # Exponential backoff: delay = baseDelay * 2^(attempt - 1)\n      # - Attempt 1: 1000ms, Attempt 2: 2000ms, Attempt 3: 4000ms\n      # - Prevents thundering herd on transient failures\n      backoffStrategy: exponential\n      baseDelay: 1000\n\n    # Failure handling strategy for workflow execution\n    failureHandling:\n      # graceful-degradation: Continue workflow with partial results\n      # fail-fast: Immediately abort workflow on any failure\n      # best-effort: Try all steps even if some fail\n      strategy: graceful-degradation\n\n      # Enable fallback workflows when primary workflow fails\n      # - Provides alternative execution paths for critical workflows\n      # - Example: Use cached data if real-time API fails\n      fallbackWorkflows: true\n\n      # Enable compensation actions for saga pattern\n      # - Rollback completed steps when later steps fail\n      # - Example: Cancel payment if shipping address validation fails\n      compensationActions: true\n\n  # ============================================================================\n  # PERFORMANCE: Throughput, latency, and resource optimization\n  # ============================================================================\n  performance:\n    # Throughput targets for capacity planning\n    throughput:\n      # Target workflows processed per second (sustained load)\n      workflowsPerSecond: 50\n\n      # Maximum workflows executing simultaneously (burst capacity)\n      maxConcurrentExecutions: 500\n\n    # Latency targets for SLA monitoring\n    latency:\n      # Overhead added by orchestration layer (ms)\n      # - Includes workflow parsing, agent routing, result aggregation\n      orchestrationOverhead: 50\n\n      # Average latency for agent-to-agent coordination (ms)\n      # - Includes service discovery, health checks, message routing\n      coordinationLatency: 100\n\n      # 99th percentile end-to-end latency (ms)\n      # - Used for SLA enforcement and performance regression detection\n      p99: 2000\n\n  # ============================================================================\n  # MONITORING: Observability configuration for production operations\n  # ============================================================================\n  monitoring:\n    # Track workflow state transitions and execution history\n    # - Enables workflow replay and debugging\n    workflowTracking: true\n\n    # Periodic health checks for all managed agents\n    # - Automatically remove unhealthy agents from routing pool\n    agentHealthChecks: true\n\n    # Collect and expose performance metrics (Prometheus format)\n    # - Request rate, latency, error rate, resource utilization\n    performanceMetrics: true\n\n    # Alerting thresholds for operational issues\n    alerting:\n      # Trigger alert after N consecutive workflow failures\n      failureThreshold: 5\n\n      # Trigger alert when p99 latency exceeds threshold (ms)\n      latencyThreshold: 5000\n\n      # Trigger alert when resource utilization exceeds percentage\n      # - Applies to CPU, memory, token budget, agent pool\n      resourceThreshold: 90\n\n# ============================================================================\n# END OF MANIFEST\n# ============================================================================\n# Next Steps:\n# 1. Deploy using: kubectl apply -f orchestrator-agent.yaml\n# 2. Monitor via: /metrics endpoint (Prometheus format)\n# 3. Submit workflows via: POST /api/v2/workflows/execute\n# 4. View workflow status: GET /api/v2/workflows/{workflowId}\n#\n# Related Documentation:\n# - OSSA Spec: https://ossa.ai/spec\n# - Orchestration Patterns: https://microservices.io/patterns/data/saga.html\n# - Agent Coordination: https://ossa.ai/docs/orchestration\n# ============================================================================\n",
    "category": "Agent Types"
  },
  {
    "name": "sample-compliant-agent.yaml",
    "path": "agent-manifests/sample-compliant-agent.yaml",
    "content": "apiVersion: ossa/v0.3.0\nkind: Agent\nmetadata:\n  name: financial-data-processor\n  version: v1.2.3\n  description: 'Enterprise-grade financial data processing agent with full OSSA Gold compliance'\n  author: 'enterprise-financial-corp'\n  labels:\n    environment: production\n    classification: confidential\n    industry: financial-services\n    compliance: gold-level\nspec:\n  type: worker\n  subtype: data-processor\n  capabilities:\n    domains:\n      - data-processing\n      - financial-analysis\n      - compliance-validation\n      - audit-trail-generation\n    operations:\n      - process-transactions\n      - validate-compliance\n      - generate-reports\n      - audit-logging\n    inputFormats:\n      - application/json\n      - text/csv\n      - application/xml\n    outputFormats:\n      - application/json\n      - application/pdf\n      - text/csv\n  protocols:\n    supported:\n      - name: rest\n        version: '1.1'\n        endpoint: 'https://api.enterprise.com/agents/financial-processor'\n        authentication:\n          type: oauth2\n          scopes: ['agent.execute', 'data.read', 'audit.write']\n        tls: true\n        timeout: 30000\n      - name: grpc\n        version: '1.0'\n        endpoint: 'grpc://secure.enterprise.com:9443/FinancialProcessor'\n        authentication:\n          type: mutual-tls\n        tls: true\n        timeout: 30000\n      - name: mcp\n        version: '0.1.0'\n        endpoint: 'mcp://internal.enterprise.com:8080/financial-processor'\n        authentication:\n          type: api-key\n        tls: true\n        timeout: 15000\n    preferred: rest\n  conformance:\n    level: gold\n    auditLogging: true\n    feedbackLoop: true\n    propsTokens: true\n    learningSignals: true\n    features:\n      - continuous-monitoring\n      - automated-compliance\n      - real-time-audit\n      - human-oversight-integration\n  performance:\n    throughput:\n      requestsPerSecond: 100\n      concurrentRequests: 50\n      batchSize: 1000\n    latency:\n      p50: 150\n      p95: 500\n      p99: 1000\n      timeout: 30000\n    reliability:\n      availability: 99.95\n      errorRate: 0.01\n      mttr: 300\n  budgets:\n    tokens:\n      default: 5000\n      maximum: 50000\n      emergency: 100000\n    cost:\n      hourly: 10.50\n      daily: 252.00\n      monthly: 7560.00\n    resources:\n      cpu: '2000m'\n      memory: '4Gi'\n      storage: '10Gi'\n  security:\n    encryption:\n      atRest: true\n      inTransit: true\n      algorithms: ['AES-256-GCM', 'RSA-4096']\n    access:\n      authentication: required\n      authorization: rbac\n      auditLevel: comprehensive\n    compliance:\n      frameworks:\n        - iso-42001\n        - nist-ai-rmf\n        - eu-ai-act\n        - pci-dss\n        - sox\n      certifications:\n        - iso-27001\n        - soc2-type2\n      dataProtection:\n        - gdpr\n        - ccpa\n        - pii-handling\n  monitoring:\n    healthCheck:\n      endpoint: '/health'\n      interval: 30\n      timeout: 5\n    metrics:\n      endpoint: '/metrics'\n      format: prometheus\n      retention: '7d'\n    logging:\n      level: info\n      format: structured\n      destination: enterprise-audit-log\n      retention: '2y'\n  governance:\n    approvals:\n      deployment: ['security-officer', 'compliance-manager']\n      updates: ['technical-lead', 'compliance-manager']\n      retirement: ['security-officer', 'data-officer', 'compliance-manager']\n    policies:\n      - financial-data-policy-v2.1\n      - enterprise-security-policy-v3.0\n      - ai-governance-policy-v1.5\n    documentation:\n      - https://docs.enterprise.com/agents/financial-processor\n      - https://compliance.enterprise.com/agent-certifications/fp-v1.2.3\n      - https://security.enterprise.com/risk-assessments/fp-2024-q1\n",
    "category": "Agent Types"
  },
  {
    "name": "worker-agent.yaml",
    "path": "agent-manifests/workers/worker-agent.yaml",
    "content": "apiVersion: ossa/v0.3.0\nkind: Agent\nmetadata:\n  name: data-processing-worker\n  version: v1.2.0\n  description: 'High-performance worker agent for distributed data processing tasks'\n  author: 'data-engineering-team'\n  labels:\n    environment: production\n    classification: internal\n    role: worker\n    complexity: standard\nspec:\n  type: worker\n  subtype: data-processor\n  capabilities:\n    domains:\n      - data-processing\n      - stream-analytics\n      - batch-processing\n      - file-operations\n      - database-operations\n    operations:\n      - process-records\n      - transform-data\n      - validate-input\n      - generate-output\n      - handle-errors\n      - report-progress\n    patterns:\n      - pipeline-processing\n      - error-recovery\n      - checkpoint-resume\n      - rate-limiting\n      - batching\n  protocols:\n    supported:\n      - name: rest\n        version: '1.1'\n        endpoint: 'https://worker.platform.com/api/v1'\n        authentication:\n          type: bearer-token\n          scopes: ['worker.execute', 'data.read', 'data.write']\n        tls: true\n      - name: message-queue\n        version: '1.0'\n        endpoint: 'amqp://queue.platform.com:5672/workers'\n        authentication:\n          type: sasl\n      - name: grpc\n        version: '1.0'\n        endpoint: 'grpc://worker.platform.com:9090/DataProcessor'\n        authentication:\n          type: mutual-tls\n  processing:\n    maxConcurrentTasks: 10\n    maxMemoryUsage: '2Gi'\n    maxCpuUsage: '1000m'\n    timeout: 300000\n    retryPolicy:\n      maxAttempts: 3\n      backoffStrategy: exponential\n      baseDelay: 1000\n    errorHandling:\n      strategy: dead-letter-queue\n      maxFailures: 5\n  performance:\n    throughput:\n      recordsPerSecond: 1000\n      maxBatchSize: 100\n    latency:\n      processingTime: 50\n      p95: 200\n      p99: 500\n  monitoring:\n    healthChecks: true\n    performanceMetrics: true\n    errorTracking: true\n    alerting:\n      errorThreshold: 5\n      latencyThreshold: 1000\n      memoryThreshold: 80\n",
    "category": "Agent Types"
  },
  {
    "name": "README.ts",
    "path": "agent-mesh/README.ts",
    "content": "/**\n * Agent Mesh Communication Layer\n *\n * A comprehensive TypeScript implementation of the OSSA Agent-to-Agent (A2A) protocol\n * for inter-agent communication.\n *\n * ## Features\n *\n * - **Service Discovery**: Registry-based, broadcast, and multicast discovery mechanisms\n * - **Message Routing**: Direct, broadcast, topic-based, and request/response patterns\n * - **Multiple Transports**: HTTP, gRPC, WebSocket, MQTT support\n * - **Reliability**: Automatic retry, circuit breaker, and dead letter queue\n * - **Observability**: Built-in support for tracing, metrics, and logging\n * - **Security**: mTLS, bearer tokens, OIDC authentication\n * - **Type Safety**: Full TypeScript type definitions\n *\n * ## Architecture\n *\n * The agent mesh consists of several key components:\n *\n * 1. **Discovery Service**: Manages agent registration and discovery\n * 2. **Message Router**: Routes messages based on rules and patterns\n * 3. **Subscription Manager**: Manages channel subscriptions\n * 4. **Transport Layer**: Abstracts communication mechanisms\n * 5. **Agent Mesh Client**: Main API for agent-to-agent communication\n *\n * ## Quick Start\n *\n * ```typescript\n * import {\n *   AgentMeshClientBuilder,\n *   DiscoveryService,\n *   InMemoryAgentRegistry,\n * } from '@bluefly/openstandardagents/mesh';\n *\n * // 1. Create discovery service\n * const registry = new InMemoryAgentRegistry();\n * const discovery = new DiscoveryService(registry);\n *\n * // 2. Define your agent\n * const agent = {\n *   uri: 'agent://team/my-agent',\n *   name: 'My Agent',\n *   version: '1.0.0',\n *   ossaVersion: '0.3.1',\n *   capabilities: ['task-execution'],\n *   endpoints: { http: 'http://localhost:8080' },\n *   transport: ['http'],\n *   authentication: ['bearer'],\n *   encryption: { tlsRequired: true, minTlsVersion: '1.3' },\n * };\n *\n * // 3. Register agent\n * await discovery.registerSelf(agent);\n *\n * // 4. Create mesh client\n * const client = new AgentMeshClientBuilder()\n *   .withLocalAgent(agent)\n *   .withDiscovery(discovery)\n *   .build();\n *\n * // 5. Start communicating!\n * await client.publish('events.channel', { data: 'value' });\n * ```\n *\n * ## Examples\n *\n * Run the examples to see the agent mesh in action:\n *\n * ```bash\n * tsx examples/agent-mesh/basic-usage.ts\n * ```\n *\n * ## API Reference\n *\n * ### AgentMeshClient\n *\n * Main client for agent-to-agent communication.\n *\n * **Methods:**\n *\n * - `send(to, payload, options?)` - Send a message\n * - `request(to, payload, options?)` - Send request and wait for response\n * - `publish(channel, payload, options?)` - Publish event to topic\n * - `broadcast(namespace, payload, options?)` - Broadcast to all agents in namespace\n * - `subscribe(subscription, handler)` - Subscribe to channel\n * - `unsubscribe(channel, handler)` - Unsubscribe from channel\n * - `registerCommand(command, handler)` - Register command handler\n * - `invokeCommand(agentUri, commandName, input)` - Invoke command on another agent\n * - `handleMessage(message)` - Handle incoming message\n * - `getStats()` - Get routing statistics\n * - `close()` - Close the client\n *\n * ### DiscoveryService\n *\n * Manages agent discovery and registration.\n *\n * **Methods:**\n *\n * - `registerSelf(agentCard, heartbeatIntervalMs?)` - Register this agent\n * - `unregisterSelf()` - Unregister this agent\n * - `discoverByCapability(capability)` - Find agents by capability\n * - `discoverByUri(uri)` - Find agent by URI\n * - `listAgents()` - List all registered agents\n * - `findHealthyAgents()` - Find healthy agents only\n * - `isAgentAvailable(uri)` - Check if agent is available\n *\n * ## Message Patterns\n *\n * ### 1. Publish/Subscribe\n *\n * ```typescript\n * // Publisher\n * await client.publish('security.vulnerabilities', {\n *   vulnerability_id: 'vuln-001',\n *   severity: 'critical',\n * });\n *\n * // Subscriber\n * client.subscribe(\n *   {\n *     channel: 'security.vulnerabilities',\n *     handler: 'handleVulnerability',\n *     filter: {\n *       fields: { severity: ['high', 'critical'] }\n *     }\n *   },\n *   async (message) => {\n *     console.log('Received:', message.payload);\n *   }\n * );\n * ```\n *\n * ### 2. Request/Response\n *\n * ```typescript\n * // Requester\n * const response = await client.request(\n *   'agent://team/analyzer',\n *   { action: 'analyze', data: 'sample' },\n *   { timeoutMs: 30000 }\n * );\n *\n * // Responder (command handler)\n * client.registerCommand(\n *   {\n *     name: 'analyze',\n *     inputSchema: { type: 'object' },\n *   },\n *   async (input) => {\n *     // Process and return result\n *     return { result: 'success' };\n *   }\n * );\n * ```\n *\n * ### 3. Broadcast\n *\n * ```typescript\n * // Broadcast to all agents in namespace\n * await client.broadcast('workers', {\n *   event: 'shutdown',\n *   reason: 'maintenance',\n * });\n * ```\n *\n * ### 4. Direct Messaging\n *\n * ```typescript\n * // Send message directly to specific agent\n * await client.send('agent://team/specific-agent', {\n *   message: 'Hello!',\n * });\n * ```\n *\n * ## Routing Rules\n *\n * Define routing rules to control message flow:\n *\n * ```typescript\n * import { DefaultMessageRouter } from '@bluefly/openstandardagents/mesh';\n *\n * const router = new DefaultMessageRouter();\n *\n * router.addRule({\n *   source: 'agent://security/scanner',\n *   channel: 'security.vulnerabilities',\n *   targets: [\n *     'agent://compliance/auditor',\n *     'agent://monitoring/alerter',\n *   ],\n *   filter: {\n *     fields: { severity: ['critical', 'high'] }\n *   },\n *   priority: 'high',\n * });\n * ```\n *\n * ## Reliability Configuration\n *\n * Configure retry, circuit breaker, and dead letter queue:\n *\n * ```typescript\n * const client = new AgentMeshClientBuilder()\n *   .withLocalAgent(agent)\n *   .withDiscovery(discovery)\n *   .withReliability({\n *     deliveryGuarantee: 'at-least-once',\n *     retry: {\n *       maxAttempts: 3,\n *       backoff: 'exponential',\n *       initialDelayMs: 1000,\n *       maxDelayMs: 30000,\n *       multiplier: 2,\n *     },\n *     dlq: {\n *       enabled: true,\n *       channel: 'messaging.dlq',\n *       retentionDays: 30,\n *     },\n *   })\n *   .build();\n * ```\n *\n * ## Observability\n *\n * The agent mesh includes built-in observability features:\n *\n * - **Tracing**: W3C Trace Context propagation\n * - **Metrics**: Routing statistics and performance metrics\n * - **Logging**: Structured logging for all operations\n *\n * ```typescript\n * // Enable statistics\n * const client = new AgentMeshClientBuilder()\n *   .withLocalAgent(agent)\n *   .withDiscovery(discovery)\n *   .enableStats()\n *   .build();\n *\n * // Get statistics\n * const stats = client.getStats();\n * console.log('Total messages:', stats.totalMessages);\n * console.log('Average routing time:', stats.averageRoutingTimeMs);\n * console.log('Errors:', stats.routingErrors);\n * ```\n *\n * ## Advanced Topics\n *\n * ### Custom Transport\n *\n * Implement custom transport for different protocols:\n *\n * ```typescript\n * import { Transport, MessageEnvelope } from '@bluefly/openstandardagents/mesh';\n *\n * class MyCustomTransport implements Transport {\n *   async send(endpoint: string, message: MessageEnvelope): Promise<void> {\n *     // Custom implementation\n *   }\n *\n *   async close(): Promise<void> {\n *     // Cleanup\n *   }\n * }\n *\n * const client = new AgentMeshClientBuilder()\n *   .withLocalAgent(agent)\n *   .withDiscovery(discovery)\n *   .withTransport(new MyCustomTransport())\n *   .build();\n * ```\n *\n * ### Message Filtering\n *\n * Use filters to control which messages are processed:\n *\n * ```typescript\n * client.subscribe(\n *   {\n *     channel: 'security.*',  // Wildcard subscription\n *     handler: 'handleSecurity',\n *     filter: {\n *       fields: {\n *         severity: ['critical', 'high'],\n *         environment: 'production',\n *       },\n *       expression: \"severity == 'critical'\",\n *     },\n *   },\n *   async (message) => {\n *     // Only receives critical production messages\n *   }\n * );\n * ```\n *\n * ## Specification Compliance\n *\n * This implementation follows:\n *\n * - OSSA v0.3.1 Messaging Specification\n * - OSSA v0.2.9 A2A Protocol\n * - W3C Trace Context standard\n * - CloudEvents specification (message envelope)\n *\n * ## License\n *\n * Apache-2.0\n */\n\nexport {};\n",
    "category": "Getting Started"
  },
  {
    "name": "basic-usage.ts",
    "path": "agent-mesh/basic-usage.ts",
    "content": "/**\n * Agent Mesh - Basic Usage Example\n *\n * This example demonstrates how to set up and use the agent mesh communication layer\n * for inter-agent communication following the OSSA A2A protocol.\n */\n\nimport {\n  AgentMeshClientBuilder,\n  DiscoveryService,\n  InMemoryAgentRegistry,\n  AgentCard,\n  MessageEnvelope,\n} from '../../src/mesh/index.js';\n\n/**\n * Example 1: Setting up a simple agent with pub/sub messaging\n */\nasync function examplePubSub() {\n  console.log('\\n=== Example 1: Pub/Sub Messaging ===\\n');\n\n  // Create shared discovery service\n  const registry = new InMemoryAgentRegistry();\n  const discovery = new DiscoveryService(registry);\n\n  // Define security scanner agent\n  const securityAgent: AgentCard = {\n    uri: 'agent://security/scanner',\n    name: 'Security Scanner',\n    version: '1.0.0',\n    ossaVersion: '0.3.1',\n    capabilities: ['vulnerability-scanning', 'secret-detection'],\n    endpoints: {\n      http: 'http://localhost:8080',\n    },\n    transport: ['http'],\n    authentication: ['bearer'],\n    encryption: {\n      tlsRequired: true,\n      minTlsVersion: '1.3',\n    },\n  };\n\n  // Define monitoring agent\n  const monitoringAgent: AgentCard = {\n    uri: 'agent://observability/monitor',\n    name: 'Monitoring Agent',\n    version: '1.0.0',\n    ossaVersion: '0.3.1',\n    capabilities: ['metrics-analysis', 'anomaly-detection'],\n    endpoints: {\n      http: 'http://localhost:8081',\n    },\n    transport: ['http'],\n    authentication: ['bearer'],\n    encryption: {\n      tlsRequired: true,\n      minTlsVersion: '1.3',\n    },\n  };\n\n  // Register agents\n  await discovery.registerSelf(securityAgent);\n\n  // Create mesh client for security agent\n  const securityClient = new AgentMeshClientBuilder()\n    .withLocalAgent(securityAgent)\n    .withDiscovery(discovery)\n    .enableStats()\n    .build();\n\n  // Create mesh client for monitoring agent\n  const monitoringClient = new AgentMeshClientBuilder()\n    .withLocalAgent(monitoringAgent)\n    .withDiscovery(discovery)\n    .enableStats()\n    .build();\n\n  // Subscribe to security vulnerabilities\n  monitoringClient.subscribe(\n    {\n      channel: 'security.vulnerabilities',\n      handler: 'handleVulnerability',\n      priority: 'high',\n    },\n    async (message: MessageEnvelope) => {\n      console.log('📊 Monitoring agent received vulnerability:');\n      console.log(JSON.stringify(message.payload, null, 2));\n    }\n  );\n\n  // Publish a vulnerability event\n  console.log('🔍 Security agent publishing vulnerability...\\n');\n  await securityClient.publish('security.vulnerabilities', {\n    vulnerability_id: 'vuln-2024-001',\n    severity: 'critical',\n    cve_id: 'CVE-2024-1234',\n    affected_package: 'lodash@4.17.20',\n    remediation: 'Update to lodash@4.17.21',\n  });\n\n  // Give time for message to be processed\n  await new Promise((resolve) => setTimeout(resolve, 100));\n\n  // Cleanup\n  await securityClient.close();\n  await monitoringClient.close();\n  discovery.destroy();\n}\n\n/**\n * Example 2: Request/Response pattern\n */\nasync function exampleRequestResponse() {\n  console.log('\\n=== Example 2: Request/Response Pattern ===\\n');\n\n  // Create shared discovery service\n  const registry = new InMemoryAgentRegistry();\n  const discovery = new DiscoveryService(registry);\n\n  // Define code analyzer agent\n  const analyzerAgent: AgentCard = {\n    uri: 'agent://code/analyzer',\n    name: 'Code Analyzer',\n    version: '1.0.0',\n    ossaVersion: '0.3.1',\n    capabilities: ['code-analysis', 'security-scanning'],\n    endpoints: {\n      http: 'http://localhost:8082',\n    },\n    transport: ['http'],\n    authentication: ['bearer'],\n    encryption: {\n      tlsRequired: true,\n      minTlsVersion: '1.3',\n    },\n  };\n\n  // Define orchestrator agent\n  const orchestratorAgent: AgentCard = {\n    uri: 'agent://orchestrator/main',\n    name: 'Orchestrator',\n    version: '1.0.0',\n    ossaVersion: '0.3.1',\n    capabilities: ['workflow-orchestration'],\n    endpoints: {\n      http: 'http://localhost:8083',\n    },\n    transport: ['http'],\n    authentication: ['bearer'],\n    encryption: {\n      tlsRequired: true,\n      minTlsVersion: '1.3',\n    },\n  };\n\n  // Register agents\n  await discovery.registerSelf(analyzerAgent);\n\n  // Create mesh clients\n  const analyzerClient = new AgentMeshClientBuilder()\n    .withLocalAgent(analyzerAgent)\n    .withDiscovery(discovery)\n    .build();\n\n  const orchestratorClient = new AgentMeshClientBuilder()\n    .withLocalAgent(orchestratorAgent)\n    .withDiscovery(discovery)\n    .build();\n\n  // Register command handler on analyzer\n  analyzerClient.registerCommand(\n    {\n      name: 'analyze_code',\n      inputSchema: {\n        type: 'object',\n        properties: {\n          repository: { type: 'string' },\n          branch: { type: 'string' },\n        },\n        required: ['repository'],\n      },\n      outputSchema: {\n        type: 'object',\n        properties: {\n          issues: { type: 'array' },\n          quality_score: { type: 'number' },\n        },\n      },\n      timeoutSeconds: 60,\n    },\n    async (input: { repository: string; branch?: string }) => {\n      console.log(`🔍 Analyzing code from ${input.repository}...\\n`);\n      // Simulate analysis\n      return {\n        issues: [\n          { type: 'security', severity: 'medium', message: 'Potential SQL injection' },\n          { type: 'style', severity: 'low', message: 'Line too long' },\n        ],\n        quality_score: 87,\n      };\n    }\n  );\n\n  // Invoke command from orchestrator\n  console.log('📞 Orchestrator invoking code analysis...\\n');\n  const result = await orchestratorClient.invokeCommand(\n    'agent://code/analyzer',\n    'analyze_code',\n    {\n      repository: 'https://github.com/org/repo',\n      branch: 'main',\n    }\n  );\n\n  console.log('✅ Analysis result:');\n  console.log(JSON.stringify(result, null, 2));\n\n  // Cleanup\n  await analyzerClient.close();\n  await orchestratorClient.close();\n  discovery.destroy();\n}\n\n/**\n * Example 3: Workflow with multiple agents\n */\nasync function exampleWorkflow() {\n  console.log('\\n=== Example 3: Multi-Agent Workflow ===\\n');\n\n  // Create shared discovery service\n  const registry = new InMemoryAgentRegistry();\n  const discovery = new DiscoveryService(registry);\n\n  // Define agents\n  const validatorAgent: AgentCard = {\n    uri: 'agent://validation/config',\n    name: 'Config Validator',\n    version: '1.0.0',\n    ossaVersion: '0.3.1',\n    capabilities: ['kubernetes-validation', 'helm-linting'],\n    endpoints: { http: 'http://localhost:8084' },\n    transport: ['http'],\n    authentication: ['bearer'],\n    encryption: { tlsRequired: true, minTlsVersion: '1.3' },\n  };\n\n  const deployerAgent: AgentCard = {\n    uri: 'agent://deployment/deployer',\n    name: 'Deployer',\n    version: '1.0.0',\n    ossaVersion: '0.3.1',\n    capabilities: ['kubernetes-deployment'],\n    endpoints: { http: 'http://localhost:8085' },\n    transport: ['http'],\n    authentication: ['bearer'],\n    encryption: { tlsRequired: true, minTlsVersion: '1.3' },\n  };\n\n  const monitorAgent: AgentCard = {\n    uri: 'agent://observability/monitor',\n    name: 'Monitor',\n    version: '1.0.0',\n    ossaVersion: '0.3.1',\n    capabilities: ['metrics-monitoring'],\n    endpoints: { http: 'http://localhost:8086' },\n    transport: ['http'],\n    authentication: ['bearer'],\n    encryption: { tlsRequired: true, minTlsVersion: '1.3' },\n  };\n\n  // Register all agents\n  await discovery.registerSelf(validatorAgent);\n\n  // Create mesh clients\n  const validatorClient = new AgentMeshClientBuilder()\n    .withLocalAgent(validatorAgent)\n    .withDiscovery(discovery)\n    .build();\n\n  const deployerClient = new AgentMeshClientBuilder()\n    .withLocalAgent(deployerAgent)\n    .withDiscovery(discovery)\n    .build();\n\n  const monitorClient = new AgentMeshClientBuilder()\n    .withLocalAgent(monitorAgent)\n    .withDiscovery(discovery)\n    .build();\n\n  // Subscribe to deployment events\n  deployerClient.subscribe(\n    {\n      channel: 'deployment.validated',\n      handler: 'handleValidated',\n    },\n    async (message: MessageEnvelope) => {\n      console.log('🚀 Deployer: Configuration validated, proceeding with deployment...');\n      await deployerClient.publish('deployment.started', {\n        app: message.payload,\n        timestamp: new Date().toISOString(),\n      });\n    }\n  );\n\n  monitorClient.subscribe(\n    {\n      channel: 'deployment.started',\n      handler: 'handleDeployment',\n    },\n    async (message: MessageEnvelope) => {\n      console.log('📊 Monitor: Deployment started, setting up monitoring...');\n      console.log(JSON.stringify(message.payload, null, 2));\n    }\n  );\n\n  // Start workflow\n  console.log('1️⃣ Validator: Validating configuration...\\n');\n  await validatorClient.publish('deployment.validated', {\n    app: 'my-application',\n    version: 'v1.2.3',\n    namespace: 'production',\n  });\n\n  // Give time for workflow to complete\n  await new Promise((resolve) => setTimeout(resolve, 100));\n\n  // Cleanup\n  await validatorClient.close();\n  await deployerClient.close();\n  await monitorClient.close();\n  discovery.destroy();\n}\n\n/**\n * Example 4: Broadcast messaging\n */\nasync function exampleBroadcast() {\n  console.log('\\n=== Example 4: Broadcast Messaging ===\\n');\n\n  // Create shared discovery service\n  const registry = new InMemoryAgentRegistry();\n  const discovery = new DiscoveryService(registry);\n\n  // Define orchestrator\n  const orchestrator: AgentCard = {\n    uri: 'agent://orchestrator/main',\n    name: 'Orchestrator',\n    version: '1.0.0',\n    ossaVersion: '0.3.1',\n    capabilities: ['workflow-orchestration'],\n    endpoints: { http: 'http://localhost:9000' },\n    transport: ['http'],\n    authentication: ['bearer'],\n    encryption: { tlsRequired: true, minTlsVersion: '1.3' },\n  };\n\n  // Define workers\n  const worker1: AgentCard = {\n    uri: 'agent://workers/worker-1',\n    name: 'Worker 1',\n    version: '1.0.0',\n    ossaVersion: '0.3.1',\n    capabilities: ['task-execution'],\n    endpoints: { http: 'http://localhost:9001' },\n    transport: ['http'],\n    authentication: ['bearer'],\n    encryption: { tlsRequired: true, minTlsVersion: '1.3' },\n  };\n\n  const worker2: AgentCard = {\n    uri: 'agent://workers/worker-2',\n    name: 'Worker 2',\n    version: '1.0.0',\n    ossaVersion: '0.3.1',\n    capabilities: ['task-execution'],\n    endpoints: { http: 'http://localhost:9002' },\n    transport: ['http'],\n    authentication: ['bearer'],\n    encryption: { tlsRequired: true, minTlsVersion: '1.3' },\n  };\n\n  // Register agents\n  await discovery.registerSelf(orchestrator);\n\n  // Create clients\n  const orchestratorClient = new AgentMeshClientBuilder()\n    .withLocalAgent(orchestrator)\n    .withDiscovery(discovery)\n    .build();\n\n  const worker1Client = new AgentMeshClientBuilder()\n    .withLocalAgent(worker1)\n    .withDiscovery(discovery)\n    .build();\n\n  const worker2Client = new AgentMeshClientBuilder()\n    .withLocalAgent(worker2)\n    .withDiscovery(discovery)\n    .build();\n\n  // Workers subscribe to broadcast\n  worker1Client.subscribe(\n    {\n      channel: 'workers',\n      handler: 'handleBroadcast',\n    },\n    async (message: MessageEnvelope) => {\n      console.log('👷 Worker 1 received broadcast:', message.payload);\n    }\n  );\n\n  worker2Client.subscribe(\n    {\n      channel: 'workers',\n      handler: 'handleBroadcast',\n    },\n    async (message: MessageEnvelope) => {\n      console.log('👷 Worker 2 received broadcast:', message.payload);\n    }\n  );\n\n  // Broadcast message to all workers\n  console.log('📣 Orchestrator broadcasting to all workers...\\n');\n  await orchestratorClient.broadcast('workers', {\n    event: 'shutdown_initiated',\n    reason: 'maintenance',\n    scheduled_time: new Date(Date.now() + 3600000).toISOString(),\n  });\n\n  // Give time for broadcast to be processed\n  await new Promise((resolve) => setTimeout(resolve, 100));\n\n  // Cleanup\n  await orchestratorClient.close();\n  await worker1Client.close();\n  await worker2Client.close();\n  discovery.destroy();\n}\n\n/**\n * Run all examples\n */\nasync function main() {\n  try {\n    await examplePubSub();\n    await exampleRequestResponse();\n    await exampleWorkflow();\n    await exampleBroadcast();\n\n    console.log('\\n✅ All examples completed successfully!\\n');\n  } catch (error) {\n    console.error('❌ Error running examples:', error);\n    process.exit(1);\n  }\n}\n\n// Run examples if this file is executed directly\nif (import.meta.url === `file://${process.argv[1]}`) {\n  main();\n}\n",
    "category": "Getting Started"
  },
  {
    "name": "code-agent.ossa.json",
    "path": "agents-md/code-agent.ossa.json",
    "content": "{\n  \"apiVersion\": \"ossa/v0.2.9\",\n  \"kind\": \"Agent\",\n  \"metadata\": {\n    \"name\": \"code-assistant\",\n    \"version\": \"1.0.0\",\n    \"description\": \"AI coding agent with agents.md repository guidance\",\n    \"labels\": {\n      \"domain\": \"development\",\n      \"framework\": \"agents-md\"\n    }\n  },\n  \"spec\": {\n    \"role\": \"You are an expert software developer. Follow the project's coding standards and conventions. Write clean, maintainable code with proper tests.\",\n    \"llm\": {\n      \"provider\": \"openai\",\n      \"model\": \"gpt-4o\",\n      \"temperature\": 0.2\n    },\n    \"tools\": [\n      {\n        \"type\": \"mcp\",\n        \"name\": \"filesystem\",\n        \"server\": \"filesystem\",\n        \"capabilities\": [\n          { \"name\": \"read_file\" },\n          { \"name\": \"write_file\" },\n          { \"name\": \"list_directory\" }\n        ]\n      },\n      {\n        \"type\": \"mcp\",\n        \"name\": \"git\",\n        \"server\": \"git\",\n        \"capabilities\": [\n          { \"name\": \"status\" },\n          { \"name\": \"diff\" },\n          { \"name\": \"commit\" }\n        ]\n      }\n    ],\n    \"constraints\": {\n      \"performance\": {\n        \"maxLatencySeconds\": 30,\n        \"timeoutSeconds\": 120\n      }\n    },\n    \"autonomy\": {\n      \"level\": \"supervised\",\n      \"approval_required\": true,\n      \"allowed_actions\": [\"read\", \"write\", \"test\"],\n      \"blocked_actions\": [\"deploy\", \"delete\"]\n    }\n  },\n  \"extensions\": {\n    \"agents_md\": {\n      \"enabled\": true,\n      \"generate\": true,\n      \"output_path\": \"AGENTS.md\",\n      \"sections\": {\n        \"dev_environment\": {\n          \"enabled\": true,\n          \"source\": \"spec.tools\",\n          \"append\": \"- Use `pnpm` for package management\\n- Run `pnpm dev` to start development server\"\n        },\n        \"testing\": {\n          \"enabled\": true,\n          \"custom\": \"Run `pnpm test` before committing.\\nEnsure all tests pass and coverage is maintained.\\nUse Jest for unit tests and Playwright for E2E.\"\n        },\n        \"pr_instructions\": {\n          \"enabled\": true,\n          \"source\": \"spec.autonomy\",\n          \"custom\": \"- Use conventional commits format\\n- Include tests for new features\\n- Update documentation as needed\\n- Request review from at least one team member\"\n        },\n        \"code_style\": {\n          \"enabled\": true,\n          \"custom\": \"- TypeScript strict mode enabled\\n- ESLint + Prettier for formatting\\n- Prefer functional programming patterns\\n- Use descriptive variable names\"\n        }\n      },\n      \"sync\": {\n        \"on_manifest_change\": true,\n        \"include_comments\": true\n      },\n      \"mapping\": {\n        \"tools_to_dev_environment\": true,\n        \"constraints_to_testing\": true,\n        \"autonomy_to_pr_instructions\": true\n      },\n      \"cursor_integration\": true\n    },\n    \"cursor\": {\n      \"enabled\": true,\n      \"agent_type\": \"composer\",\n      \"workspace_config\": {\n        \"context_files\": [\"src/**/*.ts\", \"tests/**/*.ts\"],\n        \"ignore_patterns\": [\"node_modules/**\", \"dist/**\"]\n      }\n    }\n  }\n}\n",
    "category": "Getting Started"
  },
  {
    "name": "monorepo-agent.ossa.yaml",
    "path": "agents-md/monorepo-agent.ossa.yaml",
    "content": "# OSSA Agent Manifest with agents.md Extension\n# Demonstrates monorepo support with nested AGENTS.md files\napiVersion: ossa/v0.3.0\nkind: Agent\nmetadata:\n  name: monorepo-assistant\n  version: 1.0.0\n  description: Multi-package monorepo coding agent with nested agents.md support\n  labels:\n    domain: development\n    framework: agents-md\n    architecture: monorepo\n\nspec:\n  role: |\n    You are an expert developer working on a monorepo containing multiple packages.\n    Each package has its own conventions and testing requirements.\n    Always check the local AGENTS.md file in the current directory for package-specific guidance.\n\n  llm:\n    provider: anthropic\n    model: claude-3-5-sonnet-20241022\n    temperature: 0.1\n\n  tools:\n    - type: mcp\n      name: filesystem\n      server: filesystem\n      capabilities:\n        - name: read_file\n        - name: write_file\n        - name: search_files\n    - type: mcp\n      name: git\n      server: git\n      capabilities:\n        - name: status\n        - name: diff\n        - name: log\n    - type: http\n      name: npm-registry\n      endpoint: https://registry.npmjs.org\n      capabilities:\n        - name: search_packages\n\n  constraints:\n    cost:\n      maxTokensPerDay: 100000\n      maxTokensPerRequest: 8000\n    performance:\n      maxLatencySeconds: 60\n      timeoutSeconds: 180\n\n  autonomy:\n    level: autonomous\n    approval_required: false\n    allowed_actions:\n      - read\n      - write\n      - test\n      - lint\n      - format\n    blocked_actions:\n      - publish\n      - deploy\n      - delete_branch\n\nextensions:\n  agents_md:\n    enabled: true\n    generate: true\n    output_path: AGENTS.md\n\n    sections:\n      dev_environment:\n        enabled: true\n        title: \"Development Environment\"\n        custom: |\n          - This is a pnpm workspace monorepo\n          - Run `pnpm install` from root to install all dependencies\n          - Use `pnpm -F <package>` to run commands in specific packages\n          - Turborepo is used for task orchestration\n\n      testing:\n        enabled: true\n        title: \"Testing Requirements\"\n        custom: |\n          - Run `pnpm test` to execute all tests\n          - Run `pnpm -F <package> test` for package-specific tests\n          - Coverage threshold is 80% for all packages\n          - E2E tests are in `apps/web/e2e/`\n\n      pr_instructions:\n        enabled: true\n        title: \"Pull Request Guidelines\"\n        custom: |\n          - Use conventional commits: `feat:`, `fix:`, `chore:`, etc.\n          - PRs must pass CI checks before merge\n          - Changesets are required for publishable packages\n          - Run `pnpm changeset` to create a changeset\n\n      code_style:\n        enabled: true\n        custom: |\n          - TypeScript strict mode in all packages\n          - Biome for linting and formatting\n          - Run `pnpm lint` and `pnpm format` before committing\n\n      custom:\n        - title: \"Package Structure\"\n          content: |\n            - `apps/` - Application packages (web, api, cli)\n            - `packages/` - Shared library packages\n            - `tooling/` - Build and development tools\n\n    sync:\n      on_manifest_change: true\n      include_comments: true\n      watch: false\n\n    mapping:\n      tools_to_dev_environment: true\n      constraints_to_testing: true\n      autonomy_to_pr_instructions: true\n\n    # Nested AGENTS.md files for each package\n    nested_files:\n      - path: apps/web\n        inherit: true\n        sections:\n          dev_environment:\n            custom: |\n              - Next.js 14 application\n              - Run `pnpm -F web dev` to start dev server\n              - Uses App Router and Server Components\n          testing:\n            custom: |\n              - Playwright for E2E tests\n              - React Testing Library for component tests\n              - Run `pnpm -F web test:e2e` for E2E\n\n      - path: apps/api\n        inherit: true\n        sections:\n          dev_environment:\n            custom: |\n              - Hono API server\n              - Run `pnpm -F api dev` to start\n              - OpenAPI spec in `openapi.yaml`\n          testing:\n            custom: |\n              - Vitest for unit tests\n              - Integration tests require Docker\n              - Run `docker-compose up -d` first\n\n      - path: packages/ui\n        inherit: true\n        sections:\n          dev_environment:\n            custom: |\n              - Shared React component library\n              - Run `pnpm -F ui storybook` for component preview\n              - Uses Radix UI primitives\n          testing:\n            custom: |\n              - Storybook visual tests\n              - Run `pnpm -F ui test:visual`\n\n  cursor:\n    enabled: true\n    agent_type: composer\n    workspace_config:\n      context_files:\n        - \"**/*.ts\"\n        - \"**/*.tsx\"\n        - \"**/package.json\"\n      ignore_patterns:\n        - \"**/node_modules/**\"\n        - \"**/dist/**\"\n        - \"**/.turbo/**\"\n",
    "category": "Getting Started"
  },
  {
    "name": "architecture-healer-enterprise.yaml",
    "path": "agents/architecture-healer-enterprise.yaml",
    "content": "apiVersion: ossa/v0.3.0\nkind: Agent\nmetadata:\n  name: architecture-healer-enterprise\n  description: Enterprise architecture healer for microservices\n  labels:\n    tier: healer\n    domain: architecture\nspec:\n  model:\n    provider: openai\n    name: gpt-4-turbo\n  \n  capabilities:\n    - architecture_analysis\n    - dependency_mapping\n    - pattern_detection\n    - refactoring_suggestions\n    - diagram_generation\n  \n  tools:\n    - name: analyze_dependencies\n      description: Map service dependencies and detect cycles\n      action: |\n        # Parse package.json, go.mod, requirements.txt\n        # Build dependency graph\n        # Detect circular dependencies\n        # Identify unused dependencies\n        madge --circular --extensions ts,js src/\n    \n    - name: detect_anti_patterns\n      description: Scan for architectural anti-patterns\n      patterns:\n        - god_object\n        - circular_dependency\n        - tight_coupling\n        - missing_abstraction\n        - duplicate_code\n        - magic_numbers\n        - hardcoded_config\n    \n    - name: validate_layer_boundaries\n      description: Ensure clean architecture layers\n      layers:\n        - name: presentation\n          allowed_deps: [application]\n        - name: application\n          allowed_deps: [domain, infrastructure]\n        - name: domain\n          allowed_deps: []\n        - name: infrastructure\n          allowed_deps: [domain]\n    \n    - name: check_api_consistency\n      description: Validate API design consistency\n      checks:\n        - rest_conventions\n        - versioning_strategy\n        - error_response_format\n        - pagination_pattern\n        - authentication_method\n    \n    - name: generate_architecture_diagram\n      description: Auto-generate C4 diagrams from code\n      action: |\n        # Parse code structure\n        # Generate PlantUML/Mermaid\n        # Update docs/architecture/\n        structurizr-cli export -workspace workspace.dsl -format plantuml\n  \n  healing_rules:\n    - name: fix-circular-dependencies\n      condition: circular_dependency_detected\n      actions:\n        - suggest_dependency_inversion\n        - create_interface_abstraction\n        - generate_refactoring_pr\n    \n    - name: enforce-layer-boundaries\n      condition: layer_violation_detected\n      actions:\n        - move_code_to_correct_layer\n        - create_adapter_interface\n        - update_imports\n    \n    - name: standardize-api-patterns\n      condition: api_inconsistency_detected\n      actions:\n        - generate_openapi_spec\n        - create_api_client\n        - update_documentation\n    \n    - name: reduce-coupling\n      condition: high_coupling_detected\n      actions:\n        - introduce_event_bus\n        - create_facade_pattern\n        - extract_shared_interface\n    \n    - name: update-architecture-docs\n      condition: code_structure_changed\n      actions:\n        - regenerate_diagrams\n        - update_adr\n        - notify_architects\n  \n  analysis:\n    metrics:\n      - name: coupling_score\n        threshold: 0.3\n        action: alert_if_exceeded\n      - name: cohesion_score\n        threshold: 0.7\n        action: alert_if_below\n      - name: cyclomatic_complexity\n        threshold: 10\n        action: suggest_refactoring\n      - name: dependency_depth\n        threshold: 5\n        action: flatten_hierarchy\n    \n    reports:\n      - type: architecture_health\n        schedule: weekly\n        recipients: [architects, tech-leads]\n      - type: technical_debt\n        schedule: monthly\n        format: markdown\n        output: docs/architecture/debt-report.md\n  \n  integrations:\n    - name: sonarqube\n      url: https://sonar.example.com\n      project_key: my-project\n      quality_gate: strict\n    \n    - name: archunit\n      rules: architecture-rules.java\n      fail_on_violation: true\n    \n    - name: dependency-cruiser\n      config: .dependency-cruiser.js\n      output: dependency-graph.svg\n",
    "category": "Getting Started"
  },
  {
    "name": "dependency-healer-npm.yaml",
    "path": "agents/dependency-healer-npm.yaml",
    "content": "apiVersion: ossa/v0.3.0\nkind: Agent\nmetadata:\n  name: dependency-healer-npm\n  description: NPM dependency healer with security focus\nspec:\n  model:\n    provider: openai\n    name: gpt-4-turbo\n  \n  tools:\n    - name: audit_dependencies\n      description: Security audit of all dependencies\n      action: |\n        npm audit --json | jq '.vulnerabilities'\n    \n    - name: check_outdated\n      description: Find outdated packages\n      action: |\n        npm outdated --json\n    \n    - name: detect_unused\n      description: Find unused dependencies\n      action: |\n        depcheck --json\n    \n    - name: analyze_bundle_size\n      description: Check dependency impact on bundle\n      action: |\n        npm-why package-name\n        webpack-bundle-analyzer stats.json\n  \n  healing_rules:\n    - name: fix-critical-vulnerabilities\n      condition: critical_vulnerability_detected\n      priority: immediate\n      actions:\n        - update_to_patched_version\n        - create_security_pr\n        - notify_security_team\n    \n    - name: update-minor-versions\n      condition: minor_version_available\n      priority: normal\n      actions:\n        - test_compatibility\n        - update_if_tests_pass\n        - create_update_pr\n    \n    - name: remove-unused-deps\n      condition: unused_dependency_detected\n      priority: low\n      actions:\n        - verify_not_used\n        - remove_from_package_json\n        - run_tests\n    \n    - name: deduplicate-deps\n      condition: duplicate_versions_detected\n      actions:\n        - run_npm_dedupe\n        - verify_functionality\n        - commit_lockfile\n  \n  policies:\n    security:\n      max_vulnerability_age_days: 7\n      allowed_severity: [low, moderate]\n      blocked_packages:\n        - event-stream  # Known malicious\n        - flatmap-stream\n    \n    updates:\n      auto_update: [patch]\n      manual_review: [minor, major]\n      test_before_merge: true\n    \n    bundle:\n      max_size_mb: 5\n      warn_on_large_deps: true\n      size_threshold_kb: 500\n",
    "category": "Getting Started"
  },
  {
    "name": "spec-healer-openapi.yaml",
    "path": "agents/spec-healer-openapi.yaml",
    "content": "apiVersion: ossa/v0.3.0\nkind: Agent\nmetadata:\n  name: spec-healer-openapi\n  description: OpenAPI specification healer and validator\nspec:\n  model:\n    provider: anthropic\n    name: claude-3-5-sonnet-20241022\n  \n  tools:\n    - name: validate_openapi\n      description: Validate OpenAPI spec against standards\n      action: |\n        openapi-validator spec/openapi.yaml --errors-only\n    \n    - name: detect_breaking_changes\n      description: Compare specs and detect breaking changes\n      action: |\n        oasdiff breaking spec/v1.yaml spec/v2.yaml\n    \n    - name: generate_examples\n      description: Auto-generate request/response examples\n      action: |\n        openapi-examples-generator spec/openapi.yaml\n    \n    - name: sync_with_code\n      description: Ensure spec matches implementation\n      action: |\n        # Extract routes from code\n        # Compare with spec paths\n        # Flag mismatches\n        spectral lint spec/openapi.yaml --ruleset .spectral.yaml\n  \n  healing_rules:\n    - name: fix-missing-examples\n      condition: schema_without_examples\n      actions:\n        - generate_realistic_examples\n        - add_to_spec\n    \n    - name: fix-inconsistent-naming\n      condition: inconsistent_parameter_names\n      actions:\n        - standardize_to_camelCase\n        - update_all_references\n    \n    - name: add-missing-descriptions\n      condition: endpoint_without_description\n      actions:\n        - infer_from_code_comments\n        - generate_description\n    \n    - name: fix-security-definitions\n      condition: missing_security_schemes\n      actions:\n        - add_oauth2_flow\n        - add_api_key_header\n        - document_scopes\n",
    "category": "OpenAPI Extensions"
  },
  {
    "name": "wiki-healer-production.yaml",
    "path": "agents/wiki-healer-production.yaml",
    "content": "apiVersion: ossa/v0.3.0\nkind: Agent\nmetadata:\n  name: wiki-healer-production\n  description: Production wiki healer with comprehensive checks\n  labels:\n    tier: healer\n    domain: documentation\nspec:\n  model:\n    provider: anthropic\n    name: claude-3-5-sonnet-20241022\n  \n  capabilities:\n    - file_operations\n    - git_operations\n    - markdown_parsing\n    - link_validation\n    - content_analysis\n  \n  tools:\n    - name: check_broken_links\n      description: Scan wiki for broken internal/external links\n      action: |\n        find docs/ -name \"*.md\" -exec grep -H \"](http\" {} \\; | \\\n        while read line; do\n          url=$(echo \"$line\" | grep -oP '(?<=\\()http[^)]+')\n          curl -s -o /dev/null -w \"%{http_code}\" \"$url\"\n        done\n    \n    - name: validate_frontmatter\n      description: Ensure all wiki pages have valid frontmatter\n      action: |\n        for file in docs/**/*.md; do\n          if ! head -n 5 \"$file\" | grep -q \"^---$\"; then\n            echo \"Missing frontmatter: $file\"\n          fi\n        done\n    \n    - name: check_orphaned_pages\n      description: Find pages not linked from anywhere\n      action: |\n        all_pages=$(find docs/ -name \"*.md\")\n        for page in $all_pages; do\n          basename=$(basename \"$page\")\n          if ! grep -r \"$basename\" docs/ --exclude=\"$page\" > /dev/null; then\n            echo \"Orphaned: $page\"\n          fi\n        done\n    \n    - name: fix_markdown_formatting\n      description: Auto-fix common markdown issues\n      action: |\n        # Fix heading hierarchy\n        # Fix list indentation\n        # Fix code block fences\n        # Fix table formatting\n        prettier --write \"docs/**/*.md\"\n    \n    - name: update_table_of_contents\n      description: Regenerate TOC for changed pages\n      action: |\n        for file in $(git diff --name-only HEAD~1 docs/**/*.md); do\n          markdown-toc -i \"$file\"\n        done\n    \n    - name: check_image_references\n      description: Validate all image references exist\n      action: |\n        grep -r \"!\\[.*\\](\" docs/ | while read line; do\n          img=$(echo \"$line\" | grep -oP '(?<=\\().*?(?=\\))')\n          if [[ ! -f \"docs/$img\" ]]; then\n            echo \"Missing image: $img in $line\"\n          fi\n        done\n  \n  triggers:\n    - event: wiki.page.created\n      action: validate_and_enhance\n    - event: wiki.page.updated\n      action: check_and_fix\n    - event: schedule.daily\n      action: comprehensive_audit\n  \n  healing_rules:\n    - name: fix-broken-links\n      condition: broken_links_detected\n      actions:\n        - update_links_to_latest\n        - create_redirects\n        - notify_page_owners\n    \n    - name: fix-orphaned-pages\n      condition: orphaned_pages_found\n      actions:\n        - add_to_index\n        - suggest_parent_pages\n        - create_category_links\n    \n    - name: fix-formatting\n      condition: markdown_errors_detected\n      actions:\n        - auto_format\n        - fix_heading_hierarchy\n        - standardize_code_blocks\n    \n    - name: update-stale-content\n      condition: page_not_updated_90_days\n      actions:\n        - flag_for_review\n        - notify_maintainers\n        - add_stale_warning\n  \n  observability:\n    metrics:\n      - name: pages_healed\n        type: counter\n      - name: broken_links_fixed\n        type: counter\n      - name: orphaned_pages_linked\n        type: counter\n      - name: healing_duration_ms\n        type: histogram\n    \n    activity_stream:\n      enabled: true\n      track:\n        - healing.started\n        - healing.completed\n        - issue.detected\n        - issue.fixed\n",
    "category": "Getting Started"
  },
  {
    "name": "anthropic-adapter-example.ts",
    "path": "anthropic-adapter-example.ts",
    "content": "/**\n * Anthropic Adapter Usage Example\n * Demonstrates how to use the AnthropicAdapter with OSSA manifests\n */\n\nimport { AnthropicAdapter } from '../src/services/runtime/anthropic.adapter.js';\nimport type { OssaManifest } from '../src/services/runtime/anthropic.adapter.js';\n\n// Example 1: Basic Chat Agent (No Tools)\nasync function basicChatExample() {\n  console.log('\\n=== Basic Chat Example ===\\n');\n\n  const manifest: OssaManifest = {\n    apiVersion: 'ossa/v0.3.0',\n    kind: 'Agent',\n    metadata: {\n      name: 'basic-chat-agent',\n      version: '1.0.0',\n      description: 'A simple conversational agent',\n    },\n    spec: {\n      role: 'You are a helpful AI assistant that provides clear and concise answers.',\n      llm: {\n        provider: 'anthropic',\n        model: 'claude-3-5-sonnet-20241022',\n        temperature: 0.7,\n        maxTokens: 1024,\n      },\n    },\n  };\n\n  const adapter = new AnthropicAdapter(manifest);\n  adapter.initialize();\n\n  const response = await adapter.chat('What are the three laws of robotics?', {\n    verbose: true,\n  });\n\n  console.log('\\nResponse:', response);\n  console.log('\\nAgent Info:', adapter.getAgentInfo());\n}\n\n// Example 2: Agent with Tools\nasync function toolCallingExample() {\n  console.log('\\n=== Tool Calling Example ===\\n');\n\n  const manifest: OssaManifest = {\n    apiVersion: 'ossa/v0.3.0',\n    kind: 'Agent',\n    metadata: {\n      name: 'weather-agent',\n      version: '1.0.0',\n      description: 'Weather information agent',\n    },\n    spec: {\n      role: 'You are a helpful weather assistant. Use the get_weather tool to provide current weather information.',\n      llm: {\n        provider: 'anthropic',\n        model: 'claude-3-5-sonnet-20241022',\n        temperature: 0.5,\n        maxTokens: 2048,\n      },\n    },\n    extensions: {\n      anthropic: {\n        tools: [\n          {\n            name: 'get_weather',\n            description: 'Get the current weather for a given location',\n            input_schema: {\n              type: 'object',\n              properties: {\n                location: {\n                  type: 'string',\n                  description: 'The city and state, e.g. San Francisco, CA',\n                },\n                unit: {\n                  type: 'string',\n                  enum: ['celsius', 'fahrenheit'],\n                  description: 'The temperature unit',\n                },\n              },\n              required: ['location'],\n            },\n          },\n          {\n            name: 'get_forecast',\n            description: 'Get the weather forecast for the next few days',\n            input_schema: {\n              type: 'object',\n              properties: {\n                location: {\n                  type: 'string',\n                  description: 'The city and state, e.g. San Francisco, CA',\n                },\n                days: {\n                  type: 'number',\n                  description: 'Number of days to forecast (1-7)',\n                },\n              },\n              required: ['location', 'days'],\n            },\n          },\n        ],\n      },\n    },\n  };\n\n  const adapter = new AnthropicAdapter(manifest);\n  adapter.initialize();\n\n  // Register tool handlers\n  adapter.registerToolHandler('get_weather', async (args) => {\n    const location = args.location as string;\n    const unit = (args.unit as string) || 'fahrenheit';\n\n    // Simulate API call\n    return JSON.stringify({\n      location,\n      temperature: unit === 'celsius' ? 22 : 72,\n      unit,\n      conditions: 'Partly cloudy',\n      humidity: 65,\n      wind_speed: 10,\n    });\n  });\n\n  adapter.registerToolHandler('get_forecast', async (args) => {\n    const location = args.location as string;\n    const days = args.days as number;\n\n    // Simulate API call\n    const forecast = Array.from({ length: days }, (_, i) => ({\n      day: i + 1,\n      high: 75 + i,\n      low: 55 + i,\n      conditions: i % 2 === 0 ? 'Sunny' : 'Partly cloudy',\n    }));\n\n    return JSON.stringify({\n      location,\n      forecast,\n    });\n  });\n\n  const response = await adapter.chat(\n    \"What's the weather like in San Francisco, and what's the forecast for the next 3 days?\",\n    {\n      verbose: true,\n      maxTurns: 5,\n    }\n  );\n\n  console.log('\\nFinal Response:', response);\n}\n\n// Example 3: Streaming Response\nasync function streamingExample() {\n  console.log('\\n=== Streaming Example ===\\n');\n\n  const manifest: OssaManifest = {\n    apiVersion: 'ossa/v0.3.0',\n    kind: 'Agent',\n    metadata: {\n      name: 'streaming-agent',\n      version: '1.0.0',\n    },\n    spec: {\n      role: 'You are a helpful AI assistant. Provide detailed, thoughtful responses.',\n    },\n    extensions: {\n      anthropic: {\n        model: 'claude-3-5-sonnet-20241022',\n        max_tokens: 1024,\n        temperature: 0.7,\n      },\n    },\n  };\n\n  const adapter = new AnthropicAdapter(manifest);\n  adapter.initialize();\n\n  console.log('User: Explain how neural networks work in simple terms.\\n');\n  console.log('Assistant: ');\n\n  const stream = adapter.chatStream(\n    'Explain how neural networks work in simple terms.'\n  );\n\n  for await (const chunk of stream) {\n    process.stdout.write(chunk);\n  }\n\n  console.log('\\n');\n}\n\n// Example 4: Multi-turn Conversation\nasync function conversationExample() {\n  console.log('\\n=== Multi-turn Conversation Example ===\\n');\n\n  const manifest: OssaManifest = {\n    apiVersion: 'ossa/v0.3.0',\n    kind: 'Agent',\n    metadata: {\n      name: 'conversation-agent',\n      version: '1.0.0',\n    },\n    spec: {\n      role: 'You are a knowledgeable AI tutor. Help students learn by asking questions and providing explanations.',\n      llm: {\n        provider: 'anthropic',\n        model: 'claude-3-haiku-20250320', // Using Haiku for faster responses\n        temperature: 0.8,\n        maxTokens: 512,\n      },\n    },\n  };\n\n  const adapter = new AnthropicAdapter(manifest);\n  adapter.initialize();\n\n  const questions = [\n    \"What is the Pythagorean theorem?\",\n    \"Can you give me an example?\",\n    \"How is it used in real life?\",\n  ];\n\n  for (const question of questions) {\n    console.log(`\\nUser: ${question}`);\n    const response = await adapter.chat(question);\n    console.log(`Assistant: ${response}`);\n  }\n\n  console.log('\\nConversation History:');\n  console.log(JSON.stringify(adapter.getConversationHistory(), null, 2));\n}\n\n// Example 5: Using Different Claude Models\nasync function modelComparisonExample() {\n  console.log('\\n=== Model Comparison Example ===\\n');\n\n  const models = [\n    { name: 'Claude 3.5 Sonnet', id: 'claude-3-5-sonnet-20241022' },\n    { name: 'Claude 3 Opus', id: 'claude-3-opus-20240229' },\n    { name: 'Claude 3 Haiku', id: 'claude-3-haiku-20250320' },\n  ];\n\n  const prompt = 'Write a haiku about artificial intelligence.';\n\n  for (const model of models) {\n    console.log(`\\n--- ${model.name} ---`);\n\n    const manifest: OssaManifest = {\n      apiVersion: 'ossa/v0.3.0',\n      kind: 'Agent',\n      metadata: {\n        name: `${model.id}-agent`,\n        version: '1.0.0',\n      },\n      spec: {\n        role: 'You are a creative poet.',\n      },\n      extensions: {\n        anthropic: {\n          model: model.id,\n          max_tokens: 256,\n          temperature: 0.9,\n        },\n      },\n    };\n\n    const adapter = new AnthropicAdapter(manifest);\n    adapter.initialize();\n\n    const response = await adapter.chat(prompt);\n    console.log(response);\n  }\n}\n\n// Example 6: Error Handling\nasync function errorHandlingExample() {\n  console.log('\\n=== Error Handling Example ===\\n');\n\n  const manifest: OssaManifest = {\n    apiVersion: 'ossa/v0.3.0',\n    kind: 'Agent',\n    metadata: {\n      name: 'error-demo-agent',\n      version: '1.0.0',\n    },\n    spec: {\n      role: 'You are a helpful assistant.',\n    },\n    extensions: {\n      anthropic: {\n        tools: [\n          {\n            name: 'risky_operation',\n            description: 'An operation that might fail',\n            input_schema: {\n              type: 'object',\n              properties: {\n                action: {\n                  type: 'string',\n                  description: 'The action to perform',\n                },\n              },\n              required: ['action'],\n            },\n          },\n        ],\n      },\n    },\n  };\n\n  const adapter = new AnthropicAdapter(manifest);\n  adapter.initialize();\n\n  // Register a tool that throws an error\n  adapter.registerToolHandler('risky_operation', async (args) => {\n    if (args.action === 'fail') {\n      throw new Error('Operation failed intentionally');\n    }\n    return JSON.stringify({ success: true, action: args.action });\n  });\n\n  try {\n    const response = await adapter.chat(\n      'Please perform a risky operation with action \"fail\"',\n      { verbose: true }\n    );\n    console.log('\\nResponse:', response);\n  } catch (error) {\n    console.error('\\nCaught error:', error);\n  }\n}\n\n// Run examples\nasync function main() {\n  // Check if API key is set\n  if (!process.env.ANTHROPIC_API_KEY) {\n    console.error('Error: ANTHROPIC_API_KEY environment variable not set');\n    console.log('\\nPlease set your API key:');\n    console.log('  export ANTHROPIC_API_KEY=your-key-here');\n    process.exit(1);\n  }\n\n  try {\n    // Run examples (comment out any you don't want to run)\n    await basicChatExample();\n    // await toolCallingExample();\n    // await streamingExample();\n    // await conversationExample();\n    // await modelComparisonExample();\n    // await errorHandlingExample();\n  } catch (error) {\n    console.error('Error running examples:', error);\n    process.exit(1);\n  }\n}\n\n// Run if executed directly\nif (import.meta.url === `file://${process.argv[1]}`) {\n  main();\n}\n\nexport {\n  basicChatExample,\n  toolCallingExample,\n  streamingExample,\n  conversationExample,\n  modelComparisonExample,\n  errorHandlingExample,\n};\n",
    "category": "Getting Started"
  },
  {
    "name": "anthropic-simple.ts",
    "path": "anthropic-simple.ts",
    "content": "#!/usr/bin/env node\n/**\n * Simple Anthropic Adapter Example\n * Demonstrates the absolute minimum needed to use the adapter\n */\n\nimport { AnthropicAdapter } from '../src/services/runtime/anthropic.adapter.js';\n\nasync function main() {\n  // Check API key\n  if (!process.env.ANTHROPIC_API_KEY) {\n    console.error('Error: ANTHROPIC_API_KEY environment variable not set');\n    console.log('\\nSet it with:');\n    console.log('  export ANTHROPIC_API_KEY=your-key-here');\n    process.exit(1);\n  }\n\n  // Create manifest\n  const manifest = {\n    apiVersion: 'ossa/v0.3.0',\n    kind: 'Agent',\n    metadata: {\n      name: 'simple-assistant',\n      version: '1.0.0',\n    },\n    spec: {\n      role: 'You are a helpful AI assistant.',\n    },\n  };\n\n  // Create adapter\n  console.log('Creating Anthropic adapter...');\n  const adapter = new AnthropicAdapter(manifest);\n\n  // Show agent info\n  const info = adapter.getAgentInfo();\n  console.log('\\nAgent Info:');\n  console.log(`  Name: ${info.name}`);\n  console.log(`  Model: ${info.model}`);\n  console.log(`  Provider: ${info.provider}`);\n  console.log(`  Tools: ${info.tools.length}`);\n\n  // Initialize\n  adapter.initialize();\n\n  // Simple chat\n  console.log('\\n--- Chat Example ---');\n  console.log('User: Hello, who are you?');\n\n  const response1 = await adapter.chat('Hello, who are you?');\n  console.log(`Assistant: ${response1}`);\n\n  // Follow-up (conversation history maintained)\n  console.log('\\nUser: What can you help me with?');\n\n  const response2 = await adapter.chat('What can you help me with?');\n  console.log(`Assistant: ${response2}`);\n\n  // Show conversation history\n  console.log('\\n--- Conversation History ---');\n  const history = adapter.getConversationHistory();\n  console.log(`Total messages: ${history.length}`);\n\n  console.log('\\n✅ Done!');\n}\n\nmain().catch((error) => {\n  console.error('Error:', error.message);\n  process.exit(1);\n});\n",
    "category": "Getting Started"
  },
  {
    "name": "claude-assistant.ossa.json",
    "path": "anthropic/claude-assistant.ossa.json",
    "content": "{\n  \"apiVersion\": \"ossa/v0.2.9\",\n  \"kind\": \"Agent\",\n  \"metadata\": {\n    \"name\": \"claude-assistant\",\n    \"version\": \"1.0.0\",\n    \"description\": \"Anthropic Claude API assistant agent\"\n  },\n  \"spec\": {\n    \"role\": \"You are a helpful, harmless, and honest AI assistant.\",\n    \"llm\": {\n      \"provider\": \"anthropic\",\n      \"model\": \"claude-3-5-sonnet-20241022\",\n      \"temperature\": 1.0\n    },\n    \"tools\": []\n  },\n  \"extensions\": {\n    \"anthropic\": {\n      \"enabled\": true,\n      \"model\": \"claude-3-5-sonnet-20241022\",\n      \"system\": \"You are a helpful, harmless, and honest AI assistant.\",\n      \"max_tokens\": 4096,\n      \"temperature\": 1.0,\n      \"tools\": [\n        {\n          \"name\": \"calculator\",\n          \"description\": \"Perform mathematical calculations\",\n          \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n              \"expression\": {\n                \"type\": \"string\",\n                \"description\": \"Mathematical expression to evaluate\"\n              }\n            },\n            \"required\": [\n              \"expression\"\n            ]\n          }\n        }\n      ],\n      \"streaming\": false\n    }\n  }\n}",
    "category": "Framework Integration"
  }
]